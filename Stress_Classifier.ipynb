{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQ+KkC/j0NcFCS0L+jTXGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anish2105/Stress-Classifer/blob/main/Stress_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Class Stress Detector Using RNN**"
      ],
      "metadata": {
        "id": "kVkbvyMfQHZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "from keras.layers import Dropout\n",
        "from nltk.tokenize import TweetTokenizer\n"
      ],
      "metadata": {
        "id": "HAZgX3YKQT4b"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/dreaddit_StressAnalysis - Sheet1.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "UElAwbXIWswS",
        "outputId": "26d93cd6-6430-41cd-87bb-794e4d75b8b3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id      subreddit post_id sentence_range  \\\n",
              "0    896  relationships  7nu7as       [50, 55]   \n",
              "1  19059        anxiety  680i6d        (5, 10)   \n",
              "2   7977           ptsd  8eeu1t        (5, 10)   \n",
              "3   1214           ptsd  8d28vu         [2, 7]   \n",
              "4   1965  relationships  7r1e85       [23, 28]   \n",
              "\n",
              "                                                text  label  confidence  \\\n",
              "0  Its like that, if you want or not.“ ME: I have...      0         0.8   \n",
              "1  I man the front desk and my title is HR Custom...      0         1.0   \n",
              "2  We'd be saving so much money with this new hou...      1         1.0   \n",
              "3  My ex used to shoot back with \"Do you want me ...      1         0.5   \n",
              "4  I haven’t said anything to him yet because I’m...      0         0.8   \n",
              "\n",
              "   social_timestamp  social_karma  syntax_ari  ...  lex_dal_min_pleasantness  \\\n",
              "0        1514980773            22   -1.238793  ...                    1.0000   \n",
              "1        1493348050             5    7.684583  ...                    1.4000   \n",
              "2        1524516630            10    2.360408  ...                    1.1429   \n",
              "3        1524018289             5    5.997000  ...                    1.0000   \n",
              "4        1516200171           138    4.649418  ...                    1.1250   \n",
              "\n",
              "   lex_dal_min_activation  lex_dal_min_imagery  lex_dal_avg_activation  \\\n",
              "0                  1.2000                  1.0                 1.65864   \n",
              "1                  1.1250                  1.0                 1.69133   \n",
              "2                  1.0000                  1.0                 1.70974   \n",
              "3                  1.3000                  1.0                 1.72615   \n",
              "4                  1.1429                  1.0                 1.75642   \n",
              "\n",
              "   lex_dal_avg_imagery  lex_dal_avg_pleasantness  social_upvote_ratio  \\\n",
              "0              1.32245                   1.80264                 0.63   \n",
              "1              1.69180                   1.97249                 1.00   \n",
              "2              1.52985                   1.86108                 1.00   \n",
              "3              1.52000                   1.84909                 1.00   \n",
              "4              1.43582                   1.91725                 0.84   \n",
              "\n",
              "   social_num_comments  syntax_fk_grade  sentiment  \n",
              "0                   62        -0.148707   0.000000  \n",
              "1                    2         7.398222  -0.065909  \n",
              "2                    8         3.149288  -0.036818  \n",
              "3                    7         6.606000  -0.066667  \n",
              "4                   70         4.801869   0.141667  \n",
              "\n",
              "[5 rows x 116 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f44a0b0c-f46e-48e9-b246-226fc411b6c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>post_id</th>\n",
              "      <th>sentence_range</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>confidence</th>\n",
              "      <th>social_timestamp</th>\n",
              "      <th>social_karma</th>\n",
              "      <th>syntax_ari</th>\n",
              "      <th>...</th>\n",
              "      <th>lex_dal_min_pleasantness</th>\n",
              "      <th>lex_dal_min_activation</th>\n",
              "      <th>lex_dal_min_imagery</th>\n",
              "      <th>lex_dal_avg_activation</th>\n",
              "      <th>lex_dal_avg_imagery</th>\n",
              "      <th>lex_dal_avg_pleasantness</th>\n",
              "      <th>social_upvote_ratio</th>\n",
              "      <th>social_num_comments</th>\n",
              "      <th>syntax_fk_grade</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>896</td>\n",
              "      <td>relationships</td>\n",
              "      <td>7nu7as</td>\n",
              "      <td>[50, 55]</td>\n",
              "      <td>Its like that, if you want or not.“ ME: I have...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1514980773</td>\n",
              "      <td>22</td>\n",
              "      <td>-1.238793</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.2000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.65864</td>\n",
              "      <td>1.32245</td>\n",
              "      <td>1.80264</td>\n",
              "      <td>0.63</td>\n",
              "      <td>62</td>\n",
              "      <td>-0.148707</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19059</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>680i6d</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>I man the front desk and my title is HR Custom...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1493348050</td>\n",
              "      <td>5</td>\n",
              "      <td>7.684583</td>\n",
              "      <td>...</td>\n",
              "      <td>1.4000</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.69133</td>\n",
              "      <td>1.69180</td>\n",
              "      <td>1.97249</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "      <td>7.398222</td>\n",
              "      <td>-0.065909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7977</td>\n",
              "      <td>ptsd</td>\n",
              "      <td>8eeu1t</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>We'd be saving so much money with this new hou...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1524516630</td>\n",
              "      <td>10</td>\n",
              "      <td>2.360408</td>\n",
              "      <td>...</td>\n",
              "      <td>1.1429</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.70974</td>\n",
              "      <td>1.52985</td>\n",
              "      <td>1.86108</td>\n",
              "      <td>1.00</td>\n",
              "      <td>8</td>\n",
              "      <td>3.149288</td>\n",
              "      <td>-0.036818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1214</td>\n",
              "      <td>ptsd</td>\n",
              "      <td>8d28vu</td>\n",
              "      <td>[2, 7]</td>\n",
              "      <td>My ex used to shoot back with \"Do you want me ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1524018289</td>\n",
              "      <td>5</td>\n",
              "      <td>5.997000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.3000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.72615</td>\n",
              "      <td>1.52000</td>\n",
              "      <td>1.84909</td>\n",
              "      <td>1.00</td>\n",
              "      <td>7</td>\n",
              "      <td>6.606000</td>\n",
              "      <td>-0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1965</td>\n",
              "      <td>relationships</td>\n",
              "      <td>7r1e85</td>\n",
              "      <td>[23, 28]</td>\n",
              "      <td>I haven’t said anything to him yet because I’m...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1516200171</td>\n",
              "      <td>138</td>\n",
              "      <td>4.649418</td>\n",
              "      <td>...</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>1.1429</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.75642</td>\n",
              "      <td>1.43582</td>\n",
              "      <td>1.91725</td>\n",
              "      <td>0.84</td>\n",
              "      <td>70</td>\n",
              "      <td>4.801869</td>\n",
              "      <td>0.141667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 116 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f44a0b0c-f46e-48e9-b246-226fc411b6c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f44a0b0c-f46e-48e9-b246-226fc411b6c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f44a0b0c-f46e-48e9-b246-226fc411b6c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['subreddit' , 'text']]"
      ],
      "metadata": {
        "id": "dgU2xma_XGpi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4rpjESesXW4d",
        "outputId": "4b3ff058-4f24-4a95-cd9c-ad3f64de16c3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       subreddit                                               text\n",
              "0  relationships  Its like that, if you want or not.“ ME: I have...\n",
              "1        anxiety  I man the front desk and my title is HR Custom...\n",
              "2           ptsd  We'd be saving so much money with this new hou...\n",
              "3           ptsd  My ex used to shoot back with \"Do you want me ...\n",
              "4  relationships  I haven’t said anything to him yet because I’m..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08a40435-82a9-4374-b538-cc9ab2b4904c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relationships</td>\n",
              "      <td>Its like that, if you want or not.“ ME: I have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>I man the front desk and my title is HR Custom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>We'd be saving so much money with this new hou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>My ex used to shoot back with \"Do you want me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relationships</td>\n",
              "      <td>I haven’t said anything to him yet because I’m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08a40435-82a9-4374-b538-cc9ab2b4904c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08a40435-82a9-4374-b538-cc9ab2b4904c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08a40435-82a9-4374-b538-cc9ab2b4904c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = len(data['subreddit'].unique())\n",
        "unique_values "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1tLSyDvX2PA",
        "outputId": "9d12c914-fe3a-4565-9ed2-007c74fa47c8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].astype('str')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MLW_D4ZYnqP",
        "outputId": "3eecc632-0f8a-4a6b-c50d-3fad769ecf43"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-2b34dc1dca25>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].astype('str')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrpqZu40Y0dn",
        "outputId": "5adb046b-1d80-4bb7-ce8b-206ac7e0a937"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subreddit    0\n",
              "text         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].str.lower()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "_-d-AGdrY-3X",
        "outputId": "d1704728-60a6-4694-befc-b2fec29a8dc9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-c88097a19625>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].str.lower()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       subreddit                                               text\n",
              "0  relationships  its like that, if you want or not.“ me: i have...\n",
              "1        anxiety  i man the front desk and my title is hr custom...\n",
              "2           ptsd  we'd be saving so much money with this new hou...\n",
              "3           ptsd  my ex used to shoot back with \"do you want me ...\n",
              "4  relationships  i haven’t said anything to him yet because i’m..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07758c7c-f7a7-41f4-9b03-a9906ee6b155\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relationships</td>\n",
              "      <td>its like that, if you want or not.“ me: i have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>i man the front desk and my title is hr custom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>we'd be saving so much money with this new hou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>my ex used to shoot back with \"do you want me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relationships</td>\n",
              "      <td>i haven’t said anything to him yet because i’m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07758c7c-f7a7-41f4-9b03-a9906ee6b155')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07758c7c-f7a7-41f4-9b03-a9906ee6b155 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07758c7c-f7a7-41f4-9b03-a9906ee6b155');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'][35]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "jzNZRAZzZJfP",
        "outputId": "17eeac3b-a5d2-4551-e83e-47fc1c46f79d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we are down to less than $100 for another week and 4 days. her weight watchers is due, and she is sad we may have to cancel. i am already doing what i can, and anything seemingly extra goes towards our 3 kids which we love dearly. i started a gofundme. i am looking for $100 so i can give her money towards weight watchers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removal of @ and User names**"
      ],
      "metadata": {
        "id": "BZZzbFJdaKLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tknzr = TweetTokenizer(strip_handles=True)\n",
        "\n",
        "for a in range(len(data['text'])):\n",
        "\n",
        "  result = tknzr.tokenize(data['text'][a])\n",
        "  res=\" \".join(result)\n",
        "  data['text'][a]=res\n",
        "print(\"\\nTokenize a twitter text:\")\n",
        "print(data['text'][10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O3QjFzCZzVm",
        "outputId": "d31b9313-8ec9-4a94-90e3-c028d1c87a73"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-ae51779103b3>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'][a]=res\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenize a twitter text:\n",
            "i've always hated nail files . somehow that's a part of this . god . i'm confused by it all . it's a feeling to recall it that i've carried my whole life but never understood like a cloud .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Punctuations**"
      ],
      "metadata": {
        "id": "Cbp37hEOaZ74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "punct_to_remove = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "  return text.translate(str.maketrans('','',punct_to_remove))\n",
        "\n",
        "data['text'] = data['text'].apply(lambda text:remove_punctuation(text))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "RM90dzU1aSX8",
        "outputId": "2e50f3ce-c897-49db-9ea5-0d795d9ecab8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-c2d87b989dc8>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda text:remove_punctuation(text))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       subreddit                                               text\n",
              "0  relationships  its like that  if you want or not  “ me  i hav...\n",
              "1        anxiety  i man the front desk and my title is hr custom...\n",
              "2           ptsd  wed be saving so much money with this new hous...\n",
              "3           ptsd  my ex used to shoot back with  do you want me ...\n",
              "4  relationships  i haven ’ t said anything to him yet because i..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ef08d4c-ab35-453e-9ca7-3e1acd62e7b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relationships</td>\n",
              "      <td>its like that  if you want or not  “ me  i hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>i man the front desk and my title is hr custom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>wed be saving so much money with this new hous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>my ex used to shoot back with  do you want me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relationships</td>\n",
              "      <td>i haven ’ t said anything to him yet because i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ef08d4c-ab35-453e-9ca7-3e1acd62e7b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ef08d4c-ab35-453e-9ca7-3e1acd62e7b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ef08d4c-ab35-453e-9ca7-3e1acd62e7b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_special(text):\n",
        "    rem = ''\n",
        "    for i in text:\n",
        "        if i.isalnum():\n",
        "            rem = rem + i\n",
        "        else:\n",
        "            rem = rem + ' '\n",
        "    return rem\n",
        "data.text = data.text.apply(is_special)\n",
        "data.text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "JWshSQp86qON",
        "outputId": "64daa6ea-9fd6-4072-c65b-1d6e1a279946"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-f71d68ad4a15>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.text = data.text.apply(is_special)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'its like that  if you want or not    me  i have no problem  if it takes longer  but you asked my friend for help and let him wait for one hour and then you haven   t prepared anything  thats not what you asked for  instead of 3 hours  he helped you for 10 hours till 5am '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Labeling the target fields**"
      ],
      "metadata": {
        "id": "N8C9MsP1cFiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df = pd.get_dummies(data = data , columns = ['subreddit'])\n",
        "encoded_df"
      ],
      "metadata": {
        "id": "GLQrJqx3f4JU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52e56434-6027-40b3-b666-a6022818810f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  \\\n",
              "0    its like that  if you want or not    me  i hav...   \n",
              "1    i man the front desk and my title is hr custom...   \n",
              "2    wed be saving so much money with this new hous...   \n",
              "3    my ex used to shoot back with  do you want me ...   \n",
              "4    i haven   t said anything to him yet because i...   \n",
              "..                                                 ...   \n",
              "710  i have horrible vivid nightmares every night  ...   \n",
              "711  also i cant think about both of them without g...   \n",
              "712  furthermore  i told him before we got really s...   \n",
              "713  heres the link to my amazon wish list where th...   \n",
              "714  how can i keep us protected  they have already...   \n",
              "\n",
              "     subreddit_almosthomeless  subreddit_anxiety  subreddit_assistance  \\\n",
              "0                           0                  0                     0   \n",
              "1                           0                  1                     0   \n",
              "2                           0                  0                     0   \n",
              "3                           0                  0                     0   \n",
              "4                           0                  0                     0   \n",
              "..                        ...                ...                   ...   \n",
              "710                         0                  0                     0   \n",
              "711                         0                  0                     0   \n",
              "712                         0                  0                     0   \n",
              "713                         0                  0                     1   \n",
              "714                         0                  0                     1   \n",
              "\n",
              "     subreddit_domesticviolence  subreddit_food_pantry  subreddit_homeless  \\\n",
              "0                             0                      0                   0   \n",
              "1                             0                      0                   0   \n",
              "2                             0                      0                   0   \n",
              "3                             0                      0                   0   \n",
              "4                             0                      0                   0   \n",
              "..                          ...                    ...                 ...   \n",
              "710                           0                      0                   0   \n",
              "711                           0                      0                   0   \n",
              "712                           0                      0                   0   \n",
              "713                           0                      0                   0   \n",
              "714                           0                      0                   0   \n",
              "\n",
              "     subreddit_ptsd  subreddit_relationships  subreddit_stress  \\\n",
              "0                 0                        1                 0   \n",
              "1                 0                        0                 0   \n",
              "2                 1                        0                 0   \n",
              "3                 1                        0                 0   \n",
              "4                 0                        1                 0   \n",
              "..              ...                      ...               ...   \n",
              "710               1                        0                 0   \n",
              "711               0                        1                 0   \n",
              "712               0                        1                 0   \n",
              "713               0                        0                 0   \n",
              "714               0                        0                 0   \n",
              "\n",
              "     subreddit_survivorsofabuse  \n",
              "0                             0  \n",
              "1                             0  \n",
              "2                             0  \n",
              "3                             0  \n",
              "4                             0  \n",
              "..                          ...  \n",
              "710                           0  \n",
              "711                           0  \n",
              "712                           0  \n",
              "713                           0  \n",
              "714                           0  \n",
              "\n",
              "[715 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-605f14e6-0421-41d5-8edb-b37ba514df77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>subreddit_almosthomeless</th>\n",
              "      <th>subreddit_anxiety</th>\n",
              "      <th>subreddit_assistance</th>\n",
              "      <th>subreddit_domesticviolence</th>\n",
              "      <th>subreddit_food_pantry</th>\n",
              "      <th>subreddit_homeless</th>\n",
              "      <th>subreddit_ptsd</th>\n",
              "      <th>subreddit_relationships</th>\n",
              "      <th>subreddit_stress</th>\n",
              "      <th>subreddit_survivorsofabuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>its like that  if you want or not    me  i hav...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i man the front desk and my title is hr custom...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wed be saving so much money with this new hous...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my ex used to shoot back with  do you want me ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i haven   t said anything to him yet because i...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>i have horrible vivid nightmares every night  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>also i cant think about both of them without g...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>furthermore  i told him before we got really s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>heres the link to my amazon wish list where th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>how can i keep us protected  they have already...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-605f14e6-0421-41d5-8edb-b37ba514df77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-605f14e6-0421-41d5-8edb-b37ba514df77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-605f14e6-0421-41d5-8edb-b37ba514df77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Renaming column names into a shortforms**"
      ],
      "metadata": {
        "id": "LbYNhHso3H1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_names = ['text','almosthomeless', 'anxiety', 'assistance', 'domesticviolence',\n",
        "       'food_pantry', 'homeless', 'ptsd', 'relationships', 'stress',\n",
        "       'survivorsofabuse']\n",
        "encoded_df.columns = new_column_names"
      ],
      "metadata": {
        "id": "LsbIqOH51b6X"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1jzm0ZSa1vxA",
        "outputId": "bbf5cd18-f355-409c-ef61-109dccc845db"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  almosthomeless  \\\n",
              "0    its like that  if you want or not    me  i hav...               0   \n",
              "1    i man the front desk and my title is hr custom...               0   \n",
              "2    wed be saving so much money with this new hous...               0   \n",
              "3    my ex used to shoot back with  do you want me ...               0   \n",
              "4    i haven   t said anything to him yet because i...               0   \n",
              "..                                                 ...             ...   \n",
              "710  i have horrible vivid nightmares every night  ...               0   \n",
              "711  also i cant think about both of them without g...               0   \n",
              "712  furthermore  i told him before we got really s...               0   \n",
              "713  heres the link to my amazon wish list where th...               0   \n",
              "714  how can i keep us protected  they have already...               0   \n",
              "\n",
              "     anxiety  assistance  domesticviolence  food_pantry  homeless  ptsd  \\\n",
              "0          0           0                 0            0         0     0   \n",
              "1          1           0                 0            0         0     0   \n",
              "2          0           0                 0            0         0     1   \n",
              "3          0           0                 0            0         0     1   \n",
              "4          0           0                 0            0         0     0   \n",
              "..       ...         ...               ...          ...       ...   ...   \n",
              "710        0           0                 0            0         0     1   \n",
              "711        0           0                 0            0         0     0   \n",
              "712        0           0                 0            0         0     0   \n",
              "713        0           1                 0            0         0     0   \n",
              "714        0           1                 0            0         0     0   \n",
              "\n",
              "     relationships  stress  survivorsofabuse  \n",
              "0                1       0                 0  \n",
              "1                0       0                 0  \n",
              "2                0       0                 0  \n",
              "3                0       0                 0  \n",
              "4                1       0                 0  \n",
              "..             ...     ...               ...  \n",
              "710              0       0                 0  \n",
              "711              1       0                 0  \n",
              "712              1       0                 0  \n",
              "713              0       0                 0  \n",
              "714              0       0                 0  \n",
              "\n",
              "[715 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-277a684a-4ee5-49cf-bdf9-857c5c0e5717\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>almosthomeless</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>assistance</th>\n",
              "      <th>domesticviolence</th>\n",
              "      <th>food_pantry</th>\n",
              "      <th>homeless</th>\n",
              "      <th>ptsd</th>\n",
              "      <th>relationships</th>\n",
              "      <th>stress</th>\n",
              "      <th>survivorsofabuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>its like that  if you want or not    me  i hav...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i man the front desk and my title is hr custom...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wed be saving so much money with this new hous...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my ex used to shoot back with  do you want me ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i haven   t said anything to him yet because i...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>i have horrible vivid nightmares every night  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>also i cant think about both of them without g...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>furthermore  i told him before we got really s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>heres the link to my amazon wish list where th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>how can i keep us protected  they have already...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-277a684a-4ee5-49cf-bdf9-857c5c0e5717')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-277a684a-4ee5-49cf-bdf9-857c5c0e5717 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-277a684a-4ee5-49cf-bdf9-857c5c0e5717');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing libaries**"
      ],
      "metadata": {
        "id": "a-3CKEUe3Vy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# np.random.seed(1)\n",
        "# tf.set_random_seed(2)\n",
        "\n",
        "import pandas as pd\n",
        "import keras\n",
        "# from tqdm import tqdm\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import f1_score, classification_report, log_loss\n",
        "\n",
        "# !pip install keras_preprocessing\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# from keras_preprocessing.sequence import pad_sequences\n",
        "# from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional, Flatten\n",
        "from keras.layers import Dropout, Conv1D, GlobalMaxPool1D, GRU, GlobalAvgPool1D\n",
        "# from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "3WcsDlXS1vOX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhah61I33YRE",
        "outputId": "d2f7a1b5-5485-4623-f84b-06d666de53dc"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_stopwords(text):\n",
        "  return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
        "\n",
        "encoded_df['text'] = encoded_df['text'].apply(lambda text : cleaning_stopwords(text))\n",
        "encoded_df['text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhHp6VX030db",
        "outputId": "04555b49-b4df-4633-e682-0585c0cce7a4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    like want problem takes longer asked friend he...\n",
              "1    man front desk title hr customer service repre...\n",
              "2    wed saving much money new housr expensive city...\n",
              "3    ex used shoot back want go time matter almost ...\n",
              "4    said anything yet sure someone would take hear...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmentization**"
      ],
      "metadata": {
        "id": "DIn2yri54H-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lm = nltk.WordNetLemmatizer()\n",
        "def lemmatizer_on_text(data):\n",
        "    text = [lm.lemmatize(word) for word in data]\n",
        "    return data\n",
        "encoded_df['text'] = encoded_df['text'].apply(lambda x: lemmatizer_on_text(x))\n",
        "encoded_df['text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtmvICi74HhW",
        "outputId": "039a47b5-af2a-42fb-f518-502eed501a72"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    like want problem takes longer asked friend he...\n",
              "1    man front desk title hr customer service repre...\n",
              "2    wed saving much money new housr expensive city...\n",
              "3    ex used shoot back want go time matter almost ...\n",
              "4    said anything yet sure someone would take hear...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = encoded_df['text']\n",
        "y = encoded_df.iloc[: , 1:]"
      ],
      "metadata": {
        "id": "PKJJgMku33Z7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "i6mfIp-X4fwv",
        "outputId": "d34b8b61-8cd9-4cfe-f0d2-e7f43ef417a8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     almosthomeless  anxiety  assistance  domesticviolence  food_pantry  \\\n",
              "0                 0        0           0                 0            0   \n",
              "1                 0        1           0                 0            0   \n",
              "2                 0        0           0                 0            0   \n",
              "3                 0        0           0                 0            0   \n",
              "4                 0        0           0                 0            0   \n",
              "..              ...      ...         ...               ...          ...   \n",
              "710               0        0           0                 0            0   \n",
              "711               0        0           0                 0            0   \n",
              "712               0        0           0                 0            0   \n",
              "713               0        0           1                 0            0   \n",
              "714               0        0           1                 0            0   \n",
              "\n",
              "     homeless  ptsd  relationships  stress  survivorsofabuse  \n",
              "0           0     0              1       0                 0  \n",
              "1           0     0              0       0                 0  \n",
              "2           0     1              0       0                 0  \n",
              "3           0     1              0       0                 0  \n",
              "4           0     0              1       0                 0  \n",
              "..        ...   ...            ...     ...               ...  \n",
              "710         0     1              0       0                 0  \n",
              "711         0     0              1       0                 0  \n",
              "712         0     0              1       0                 0  \n",
              "713         0     0              0       0                 0  \n",
              "714         0     0              0       0                 0  \n",
              "\n",
              "[715 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-130f6435-a39d-4de8-b9a7-2b94601aea47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>almosthomeless</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>assistance</th>\n",
              "      <th>domesticviolence</th>\n",
              "      <th>food_pantry</th>\n",
              "      <th>homeless</th>\n",
              "      <th>ptsd</th>\n",
              "      <th>relationships</th>\n",
              "      <th>stress</th>\n",
              "      <th>survivorsofabuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-130f6435-a39d-4de8-b9a7-2b94601aea47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-130f6435-a39d-4de8-b9a7-2b94601aea47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-130f6435-a39d-4de8-b9a7-2b94601aea47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train,y_test = train_test_split(x, y,random_state = 42, test_size=0.1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW2vyBBs4hVC",
        "outputId": "55eb096e-4b0c-40f5-ce2f-767730ae67bb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(643,)\n",
            "(72,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sahPpKtS8au_",
        "outputId": "5d92ab98-9575-40e1-9583-0bda6693eac5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(643, 10)\n",
            "(72, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5bKnWVZ8g5p",
        "outputId": "158b8961-7e1a-408a-c555-3d7d6d5b8ecd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120    url learn disabilities like read post url talk...\n",
              "570    wanted believed said would talk toe days later...\n",
              "39     server encourages happiness improving glamoriz...\n",
              "294    anyone dealt urinary retention side effect lex...\n",
              "666    cw mentions selfharm suicide feel overwhelmed ...\n",
              "                             ...                        \n",
              "286    best friend nearly 20 years dealing anxiety ar...\n",
              "617    bad situation stuck nashville friends family m...\n",
              "664    probably know created political survey last we...\n",
              "399    get intrusive memories really hard get head so...\n",
              "698    im last year secondary school mocks doesnt mea...\n",
              "Name: text, Length: 72, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Sequencing**"
      ],
      "metadata": {
        "id": "wja91rd48pSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(lower = False)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_text_vec = tokenizer.texts_to_sequences(X_train)\n",
        "tokenizer.fit_on_texts(X_test)\n",
        "test_text_vec = tokenizer.texts_to_sequences(X_test)\n",
        "test_text_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_gg5v6h8loo",
        "outputId": "77d0b1bb-a180-4586-e25b-b3efafd6800c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[172,\n",
              "  794,\n",
              "  2173,\n",
              "  2,\n",
              "  287,\n",
              "  155,\n",
              "  172,\n",
              "  50,\n",
              "  5429,\n",
              "  9,\n",
              "  154,\n",
              "  479,\n",
              "  289,\n",
              "  36,\n",
              "  84,\n",
              "  66,\n",
              "  954,\n",
              "  43,\n",
              "  211,\n",
              "  204,\n",
              "  6,\n",
              "  287],\n",
              " [96,\n",
              "  888,\n",
              "  47,\n",
              "  7,\n",
              "  50,\n",
              "  953,\n",
              "  70,\n",
              "  191,\n",
              "  232,\n",
              "  30,\n",
              "  5430,\n",
              "  2583,\n",
              "  685,\n",
              "  286,\n",
              "  953,\n",
              "  358,\n",
              "  1,\n",
              "  5431,\n",
              "  2756,\n",
              "  8,\n",
              "  11,\n",
              "  5,\n",
              "  187,\n",
              "  4,\n",
              "  75,\n",
              "  953,\n",
              "  1688,\n",
              "  726,\n",
              "  26,\n",
              "  8,\n",
              "  5],\n",
              " [5432,\n",
              "  5433,\n",
              "  2722,\n",
              "  1863,\n",
              "  5434,\n",
              "  152,\n",
              "  1766,\n",
              "  2717,\n",
              "  18,\n",
              "  1055,\n",
              "  5435,\n",
              "  800,\n",
              "  31,\n",
              "  505,\n",
              "  152,\n",
              "  1766,\n",
              "  5436,\n",
              "  63,\n",
              "  505,\n",
              "  13,\n",
              "  16,\n",
              "  1891,\n",
              "  2113,\n",
              "  907,\n",
              "  520,\n",
              "  50,\n",
              "  18,\n",
              "  361,\n",
              "  716,\n",
              "  34,\n",
              "  120,\n",
              "  1784,\n",
              "  430,\n",
              "  172],\n",
              " [41,\n",
              "  1681,\n",
              "  2808,\n",
              "  2809,\n",
              "  455,\n",
              "  1362,\n",
              "  1133,\n",
              "  10,\n",
              "  204,\n",
              "  1133,\n",
              "  2,\n",
              "  134,\n",
              "  135,\n",
              "  100,\n",
              "  45,\n",
              "  366,\n",
              "  387,\n",
              "  1407,\n",
              "  11,\n",
              "  57,\n",
              "  90,\n",
              "  444,\n",
              "  115,\n",
              "  963,\n",
              "  5437,\n",
              "  19,\n",
              "  197,\n",
              "  2,\n",
              "  602,\n",
              "  2763,\n",
              "  17,\n",
              "  769,\n",
              "  116,\n",
              "  17,\n",
              "  303,\n",
              "  2,\n",
              "  51,\n",
              "  547,\n",
              "  5438,\n",
              "  373,\n",
              "  11,\n",
              "  104,\n",
              "  544,\n",
              "  288,\n",
              "  771,\n",
              "  43,\n",
              "  141,\n",
              "  862,\n",
              "  1456,\n",
              "  2808,\n",
              "  2809,\n",
              "  38,\n",
              "  455,\n",
              "  971,\n",
              "  1133],\n",
              " [5439,\n",
              "  1999,\n",
              "  2270,\n",
              "  710,\n",
              "  4,\n",
              "  1046,\n",
              "  677,\n",
              "  117,\n",
              "  263,\n",
              "  456,\n",
              "  607,\n",
              "  90,\n",
              "  2810,\n",
              "  949,\n",
              "  147,\n",
              "  3,\n",
              "  5440,\n",
              "  677,\n",
              "  544,\n",
              "  5441,\n",
              "  69,\n",
              "  5442,\n",
              "  107,\n",
              "  71,\n",
              "  1841,\n",
              "  5443,\n",
              "  3,\n",
              "  20,\n",
              "  50,\n",
              "  396,\n",
              "  5444,\n",
              "  643,\n",
              "  333,\n",
              "  14,\n",
              "  117],\n",
              " [174,\n",
              "  1099,\n",
              "  48,\n",
              "  339,\n",
              "  352,\n",
              "  5445,\n",
              "  6,\n",
              "  48,\n",
              "  1998,\n",
              "  1722,\n",
              "  5446,\n",
              "  401,\n",
              "  562,\n",
              "  5447,\n",
              "  2442,\n",
              "  700,\n",
              "  2568,\n",
              "  5448,\n",
              "  16],\n",
              " [42,\n",
              "  11,\n",
              "  75,\n",
              "  1105,\n",
              "  161,\n",
              "  5449,\n",
              "  2738,\n",
              "  520,\n",
              "  116,\n",
              "  161,\n",
              "  498,\n",
              "  687,\n",
              "  756,\n",
              "  1791,\n",
              "  11,\n",
              "  38,\n",
              "  127,\n",
              "  62,\n",
              "  5450,\n",
              "  269,\n",
              "  1418,\n",
              "  22,\n",
              "  1847,\n",
              "  5451,\n",
              "  209,\n",
              "  65,\n",
              "  356,\n",
              "  5452,\n",
              "  269,\n",
              "  43,\n",
              "  153,\n",
              "  299,\n",
              "  110,\n",
              "  1366,\n",
              "  446,\n",
              "  50,\n",
              "  1022,\n",
              "  9,\n",
              "  9,\n",
              "  12,\n",
              "  354,\n",
              "  901,\n",
              "  194,\n",
              "  5453,\n",
              "  137,\n",
              "  30,\n",
              "  1791,\n",
              "  520,\n",
              "  126,\n",
              "  5454,\n",
              "  2785,\n",
              "  412,\n",
              "  5455,\n",
              "  9,\n",
              "  49,\n",
              "  28],\n",
              " [530,\n",
              "  495,\n",
              "  61,\n",
              "  303,\n",
              "  2089,\n",
              "  814,\n",
              "  2698,\n",
              "  392,\n",
              "  43,\n",
              "  1320,\n",
              "  9,\n",
              "  292,\n",
              "  5456,\n",
              "  743,\n",
              "  239,\n",
              "  774,\n",
              "  205,\n",
              "  40,\n",
              "  45,\n",
              "  2572,\n",
              "  347,\n",
              "  1240,\n",
              "  504,\n",
              "  306,\n",
              "  24,\n",
              "  309,\n",
              "  368,\n",
              "  968,\n",
              "  76,\n",
              "  5457,\n",
              "  19,\n",
              "  2400,\n",
              "  22,\n",
              "  996,\n",
              "  1648,\n",
              "  134,\n",
              "  101,\n",
              "  125,\n",
              "  2811,\n",
              "  19,\n",
              "  252,\n",
              "  154,\n",
              "  297],\n",
              " [20,\n",
              "  266,\n",
              "  65,\n",
              "  8,\n",
              "  162,\n",
              "  102,\n",
              "  15,\n",
              "  41,\n",
              "  15,\n",
              "  11,\n",
              "  103,\n",
              "  166,\n",
              "  7,\n",
              "  5458,\n",
              "  812,\n",
              "  20,\n",
              "  11,\n",
              "  1178,\n",
              "  136,\n",
              "  54,\n",
              "  493,\n",
              "  521,\n",
              "  296,\n",
              "  201,\n",
              "  544,\n",
              "  159,\n",
              "  130,\n",
              "  186,\n",
              "  117,\n",
              "  263,\n",
              "  10,\n",
              "  136,\n",
              "  16,\n",
              "  2,\n",
              "  5459,\n",
              "  451,\n",
              "  199,\n",
              "  11,\n",
              "  190,\n",
              "  5460,\n",
              "  34],\n",
              " [282,\n",
              "  307,\n",
              "  320,\n",
              "  8,\n",
              "  17,\n",
              "  12,\n",
              "  251,\n",
              "  89,\n",
              "  389,\n",
              "  55,\n",
              "  21,\n",
              "  207,\n",
              "  30,\n",
              "  146,\n",
              "  69,\n",
              "  302,\n",
              "  23,\n",
              "  106,\n",
              "  208,\n",
              "  5461,\n",
              "  29,\n",
              "  416,\n",
              "  48,\n",
              "  139,\n",
              "  1803,\n",
              "  44,\n",
              "  35,\n",
              "  207,\n",
              "  240,\n",
              "  1086,\n",
              "  295,\n",
              "  5462,\n",
              "  66,\n",
              "  1361,\n",
              "  78],\n",
              " [36,\n",
              "  5463,\n",
              "  355,\n",
              "  797,\n",
              "  5464,\n",
              "  30,\n",
              "  601,\n",
              "  28,\n",
              "  5465,\n",
              "  913,\n",
              "  5466,\n",
              "  2799,\n",
              "  65,\n",
              "  87,\n",
              "  963,\n",
              "  229,\n",
              "  29,\n",
              "  74,\n",
              "  37,\n",
              "  82,\n",
              "  2676,\n",
              "  7,\n",
              "  140,\n",
              "  33,\n",
              "  88,\n",
              "  87,\n",
              "  641,\n",
              "  32,\n",
              "  36,\n",
              "  1398,\n",
              "  65,\n",
              "  36,\n",
              "  1405,\n",
              "  5467,\n",
              "  1673,\n",
              "  1672,\n",
              "  1125,\n",
              "  149,\n",
              "  243,\n",
              "  514],\n",
              " [6,\n",
              "  44,\n",
              "  720,\n",
              "  515,\n",
              "  1847,\n",
              "  14,\n",
              "  9,\n",
              "  84,\n",
              "  730,\n",
              "  5468,\n",
              "  8,\n",
              "  36,\n",
              "  402,\n",
              "  1231,\n",
              "  1780,\n",
              "  113,\n",
              "  157,\n",
              "  49,\n",
              "  515,\n",
              "  27,\n",
              "  394,\n",
              "  100,\n",
              "  182,\n",
              "  23,\n",
              "  9,\n",
              "  1315,\n",
              "  1366,\n",
              "  1620,\n",
              "  1843,\n",
              "  5469,\n",
              "  236,\n",
              "  5470,\n",
              "  34,\n",
              "  5471,\n",
              "  34,\n",
              "  5472,\n",
              "  5473,\n",
              "  34,\n",
              "  68,\n",
              "  5474,\n",
              "  1337,\n",
              "  82],\n",
              " [2788,\n",
              "  1507,\n",
              "  99,\n",
              "  111,\n",
              "  223,\n",
              "  526,\n",
              "  19,\n",
              "  256,\n",
              "  692,\n",
              "  5475,\n",
              "  193,\n",
              "  2701,\n",
              "  28,\n",
              "  5476,\n",
              "  502,\n",
              "  358,\n",
              "  205,\n",
              "  22,\n",
              "  258,\n",
              "  179,\n",
              "  49,\n",
              "  488,\n",
              "  402,\n",
              "  36,\n",
              "  106,\n",
              "  49,\n",
              "  35,\n",
              "  49,\n",
              "  1006],\n",
              " [349,\n",
              "  809,\n",
              "  807,\n",
              "  1025,\n",
              "  20,\n",
              "  2534,\n",
              "  1009,\n",
              "  743,\n",
              "  239,\n",
              "  376,\n",
              "  119,\n",
              "  226,\n",
              "  75,\n",
              "  963,\n",
              "  838,\n",
              "  838,\n",
              "  5477,\n",
              "  5478,\n",
              "  13,\n",
              "  5479,\n",
              "  67,\n",
              "  9,\n",
              "  34,\n",
              "  772,\n",
              "  633,\n",
              "  1306,\n",
              "  76,\n",
              "  226,\n",
              "  76,\n",
              "  2672,\n",
              "  397,\n",
              "  68,\n",
              "  37,\n",
              "  130,\n",
              "  208,\n",
              "  1314,\n",
              "  1314,\n",
              "  7,\n",
              "  39,\n",
              "  163,\n",
              "  104,\n",
              "  1922,\n",
              "  786,\n",
              "  104,\n",
              "  1269,\n",
              "  980,\n",
              "  5480,\n",
              "  547,\n",
              "  470,\n",
              "  1314,\n",
              "  1121,\n",
              "  651,\n",
              "  75,\n",
              "  1836,\n",
              "  822,\n",
              "  347,\n",
              "  44,\n",
              "  1395,\n",
              "  438,\n",
              "  283,\n",
              "  651,\n",
              "  110,\n",
              "  498,\n",
              "  487,\n",
              "  148,\n",
              "  219,\n",
              "  577,\n",
              "  438,\n",
              "  283,\n",
              "  651,\n",
              "  333,\n",
              "  78,\n",
              "  822,\n",
              "  918,\n",
              "  104,\n",
              "  161,\n",
              "  178,\n",
              "  10,\n",
              "  888,\n",
              "  496,\n",
              "  25,\n",
              "  31,\n",
              "  80,\n",
              "  78,\n",
              "  54,\n",
              "  529,\n",
              "  2481,\n",
              "  588,\n",
              "  795,\n",
              "  2528,\n",
              "  178],\n",
              " [35,\n",
              "  60,\n",
              "  101,\n",
              "  136,\n",
              "  2811,\n",
              "  636,\n",
              "  147,\n",
              "  40,\n",
              "  13,\n",
              "  168,\n",
              "  37,\n",
              "  60,\n",
              "  5481,\n",
              "  37,\n",
              "  911,\n",
              "  208,\n",
              "  5482,\n",
              "  2812,\n",
              "  220,\n",
              "  5483,\n",
              "  122,\n",
              "  487,\n",
              "  1847,\n",
              "  941,\n",
              "  577,\n",
              "  528,\n",
              "  5484,\n",
              "  271,\n",
              "  373,\n",
              "  191,\n",
              "  2812,\n",
              "  915,\n",
              "  259,\n",
              "  5485,\n",
              "  5486,\n",
              "  202,\n",
              "  5487,\n",
              "  612,\n",
              "  1420,\n",
              "  940,\n",
              "  25,\n",
              "  1661,\n",
              "  1420],\n",
              " [1576,\n",
              "  362,\n",
              "  351,\n",
              "  31,\n",
              "  119,\n",
              "  6,\n",
              "  9,\n",
              "  39,\n",
              "  73,\n",
              "  568,\n",
              "  1269,\n",
              "  159,\n",
              "  19,\n",
              "  1471,\n",
              "  21,\n",
              "  86,\n",
              "  5488,\n",
              "  109,\n",
              "  82,\n",
              "  92,\n",
              "  96,\n",
              "  241,\n",
              "  5489,\n",
              "  225,\n",
              "  947,\n",
              "  4,\n",
              "  1142,\n",
              "  66,\n",
              "  92,\n",
              "  525,\n",
              "  407,\n",
              "  2705,\n",
              "  110,\n",
              "  30,\n",
              "  51,\n",
              "  225,\n",
              "  152,\n",
              "  1474,\n",
              "  55,\n",
              "  410,\n",
              "  260,\n",
              "  1681,\n",
              "  360,\n",
              "  4,\n",
              "  422],\n",
              " [81,\n",
              "  35,\n",
              "  77,\n",
              "  10,\n",
              "  82,\n",
              "  9,\n",
              "  1016,\n",
              "  425,\n",
              "  42,\n",
              "  66,\n",
              "  1082,\n",
              "  92,\n",
              "  5,\n",
              "  14,\n",
              "  3,\n",
              "  94,\n",
              "  2783,\n",
              "  5490,\n",
              "  1630,\n",
              "  188,\n",
              "  61,\n",
              "  279,\n",
              "  81,\n",
              "  382,\n",
              "  81,\n",
              "  382,\n",
              "  5491],\n",
              " [322,\n",
              "  345,\n",
              "  21,\n",
              "  589,\n",
              "  8,\n",
              "  11,\n",
              "  5,\n",
              "  1,\n",
              "  479,\n",
              "  52,\n",
              "  8,\n",
              "  11,\n",
              "  5,\n",
              "  1,\n",
              "  266,\n",
              "  4,\n",
              "  1441,\n",
              "  1018,\n",
              "  66,\n",
              "  52,\n",
              "  1,\n",
              "  274,\n",
              "  5492,\n",
              "  479,\n",
              "  626,\n",
              "  107,\n",
              "  340,\n",
              "  301,\n",
              "  1440],\n",
              " [25,\n",
              "  20,\n",
              "  36,\n",
              "  118,\n",
              "  84,\n",
              "  277,\n",
              "  573,\n",
              "  50,\n",
              "  133,\n",
              "  489,\n",
              "  115,\n",
              "  258,\n",
              "  179,\n",
              "  270,\n",
              "  37,\n",
              "  13,\n",
              "  1121,\n",
              "  49,\n",
              "  824,\n",
              "  824,\n",
              "  1121,\n",
              "  49,\n",
              "  199,\n",
              "  53,\n",
              "  43,\n",
              "  246,\n",
              "  38,\n",
              "  68,\n",
              "  5493,\n",
              "  905,\n",
              "  2787,\n",
              "  119,\n",
              "  5494],\n",
              " [99,\n",
              "  339,\n",
              "  23,\n",
              "  161,\n",
              "  99,\n",
              "  566,\n",
              "  630,\n",
              "  213,\n",
              "  101,\n",
              "  356,\n",
              "  1343,\n",
              "  39,\n",
              "  1885,\n",
              "  190,\n",
              "  664,\n",
              "  25,\n",
              "  328,\n",
              "  5495,\n",
              "  16,\n",
              "  5496,\n",
              "  934,\n",
              "  439,\n",
              "  5497,\n",
              "  338,\n",
              "  7,\n",
              "  36,\n",
              "  198,\n",
              "  43,\n",
              "  5498,\n",
              "  1008,\n",
              "  5499,\n",
              "  5500,\n",
              "  5501,\n",
              "  2399],\n",
              " [25,\n",
              "  5502,\n",
              "  364,\n",
              "  394,\n",
              "  2,\n",
              "  5503,\n",
              "  5504,\n",
              "  5505,\n",
              "  5506,\n",
              "  5507,\n",
              "  1437,\n",
              "  33,\n",
              "  76,\n",
              "  334,\n",
              "  56,\n",
              "  204,\n",
              "  2547,\n",
              "  1029,\n",
              "  313,\n",
              "  5508,\n",
              "  752,\n",
              "  56,\n",
              "  5509,\n",
              "  61,\n",
              "  451,\n",
              "  442,\n",
              "  25,\n",
              "  259,\n",
              "  171,\n",
              "  90,\n",
              "  139,\n",
              "  1364,\n",
              "  13,\n",
              "  6,\n",
              "  105,\n",
              "  404,\n",
              "  5510,\n",
              "  476,\n",
              "  187,\n",
              "  91,\n",
              "  814,\n",
              "  5511,\n",
              "  178,\n",
              "  21,\n",
              "  232,\n",
              "  30,\n",
              "  5512,\n",
              "  1437,\n",
              "  125,\n",
              "  2777,\n",
              "  1047,\n",
              "  1432,\n",
              "  227,\n",
              "  178,\n",
              "  1694,\n",
              "  814,\n",
              "  27,\n",
              "  2578],\n",
              " [440,\n",
              "  406,\n",
              "  299,\n",
              "  96,\n",
              "  50,\n",
              "  11,\n",
              "  10,\n",
              "  166,\n",
              "  5513,\n",
              "  5514,\n",
              "  5515,\n",
              "  891,\n",
              "  796,\n",
              "  2083,\n",
              "  8,\n",
              "  1416,\n",
              "  29,\n",
              "  2443,\n",
              "  90,\n",
              "  5516,\n",
              "  121,\n",
              "  133,\n",
              "  980,\n",
              "  5517,\n",
              "  5518,\n",
              "  440,\n",
              "  75,\n",
              "  212,\n",
              "  1420],\n",
              " [10,\n",
              "  636,\n",
              "  113,\n",
              "  969,\n",
              "  51,\n",
              "  6,\n",
              "  46,\n",
              "  514,\n",
              "  338,\n",
              "  1606,\n",
              "  619,\n",
              "  30,\n",
              "  268,\n",
              "  2792,\n",
              "  656,\n",
              "  5519,\n",
              "  242,\n",
              "  161,\n",
              "  419,\n",
              "  314,\n",
              "  5520,\n",
              "  20,\n",
              "  750,\n",
              "  159,\n",
              "  93,\n",
              "  5521,\n",
              "  190,\n",
              "  64,\n",
              "  5522,\n",
              "  715,\n",
              "  84,\n",
              "  1406,\n",
              "  7,\n",
              "  310,\n",
              "  65,\n",
              "  11,\n",
              "  121,\n",
              "  323,\n",
              "  1066,\n",
              "  61,\n",
              "  427,\n",
              "  553,\n",
              "  242,\n",
              "  230,\n",
              "  2433,\n",
              "  311],\n",
              " [374,\n",
              "  160,\n",
              "  81,\n",
              "  318,\n",
              "  1300,\n",
              "  8,\n",
              "  78,\n",
              "  151,\n",
              "  2,\n",
              "  6,\n",
              "  923,\n",
              "  142,\n",
              "  31,\n",
              "  10,\n",
              "  9,\n",
              "  524,\n",
              "  1812,\n",
              "  44,\n",
              "  261,\n",
              "  99,\n",
              "  158,\n",
              "  143,\n",
              "  356,\n",
              "  1039,\n",
              "  11,\n",
              "  1418,\n",
              "  415,\n",
              "  135,\n",
              "  643,\n",
              "  303,\n",
              "  780,\n",
              "  627,\n",
              "  6,\n",
              "  517,\n",
              "  1,\n",
              "  209,\n",
              "  2662,\n",
              "  731,\n",
              "  49,\n",
              "  36,\n",
              "  1701,\n",
              "  532,\n",
              "  1,\n",
              "  428,\n",
              "  1333,\n",
              "  183,\n",
              "  12,\n",
              "  6,\n",
              "  8,\n",
              "  12,\n",
              "  108,\n",
              "  16,\n",
              "  910,\n",
              "  19,\n",
              "  3,\n",
              "  431],\n",
              " [2046,\n",
              "  388,\n",
              "  1801,\n",
              "  67,\n",
              "  7,\n",
              "  664,\n",
              "  597,\n",
              "  99,\n",
              "  47,\n",
              "  372,\n",
              "  157,\n",
              "  597,\n",
              "  255,\n",
              "  5523,\n",
              "  2,\n",
              "  11,\n",
              "  285,\n",
              "  5524,\n",
              "  2042,\n",
              "  1455,\n",
              "  160,\n",
              "  1455,\n",
              "  394,\n",
              "  2,\n",
              "  255,\n",
              "  157,\n",
              "  93,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  255,\n",
              "  8,\n",
              "  36,\n",
              "  2719,\n",
              "  2587,\n",
              "  2,\n",
              "  6,\n",
              "  238,\n",
              "  81,\n",
              "  157,\n",
              "  308,\n",
              "  162,\n",
              "  290,\n",
              "  4,\n",
              "  2,\n",
              "  81,\n",
              "  620,\n",
              "  3,\n",
              "  5525,\n",
              "  5526],\n",
              " [574,\n",
              "  5527,\n",
              "  5528,\n",
              "  7,\n",
              "  98,\n",
              "  21,\n",
              "  5529,\n",
              "  899,\n",
              "  69,\n",
              "  27,\n",
              "  130,\n",
              "  64,\n",
              "  258,\n",
              "  179,\n",
              "  2759,\n",
              "  69,\n",
              "  719,\n",
              "  450,\n",
              "  87,\n",
              "  64,\n",
              "  218,\n",
              "  69,\n",
              "  158,\n",
              "  1176,\n",
              "  1217],\n",
              " [35,\n",
              "  16,\n",
              "  35,\n",
              "  111,\n",
              "  5530,\n",
              "  711,\n",
              "  364,\n",
              "  215,\n",
              "  1795,\n",
              "  132,\n",
              "  52,\n",
              "  126,\n",
              "  155,\n",
              "  606,\n",
              "  3,\n",
              "  861,\n",
              "  40,\n",
              "  93,\n",
              "  12,\n",
              "  474,\n",
              "  766,\n",
              "  324,\n",
              "  106,\n",
              "  5531,\n",
              "  350,\n",
              "  1112,\n",
              "  2806,\n",
              "  237,\n",
              "  5532,\n",
              "  5533,\n",
              "  5534,\n",
              "  5535,\n",
              "  228,\n",
              "  350,\n",
              "  1781,\n",
              "  875,\n",
              "  5536,\n",
              "  414,\n",
              "  22,\n",
              "  929,\n",
              "  215,\n",
              "  429,\n",
              "  626,\n",
              "  5537,\n",
              "  142,\n",
              "  5538,\n",
              "  387,\n",
              "  93,\n",
              "  5539],\n",
              " [3,\n",
              "  296,\n",
              "  5540,\n",
              "  672,\n",
              "  714,\n",
              "  1388,\n",
              "  271,\n",
              "  419,\n",
              "  72,\n",
              "  1842,\n",
              "  34,\n",
              "  15,\n",
              "  296,\n",
              "  487,\n",
              "  520,\n",
              "  388,\n",
              "  2694,\n",
              "  1211,\n",
              "  1141,\n",
              "  5541,\n",
              "  5542],\n",
              " [71,\n",
              "  184,\n",
              "  144,\n",
              "  8,\n",
              "  36,\n",
              "  107,\n",
              "  37,\n",
              "  36,\n",
              "  523,\n",
              "  628,\n",
              "  860,\n",
              "  434,\n",
              "  170,\n",
              "  321,\n",
              "  25,\n",
              "  196,\n",
              "  162,\n",
              "  18,\n",
              "  523,\n",
              "  997,\n",
              "  36,\n",
              "  1418,\n",
              "  6,\n",
              "  18,\n",
              "  71,\n",
              "  306,\n",
              "  1475,\n",
              "  16,\n",
              "  324,\n",
              "  258,\n",
              "  179,\n",
              "  246,\n",
              "  14,\n",
              "  263,\n",
              "  5543,\n",
              "  635,\n",
              "  37,\n",
              "  37,\n",
              "  647,\n",
              "  5,\n",
              "  1404,\n",
              "  81,\n",
              "  53,\n",
              "  873,\n",
              "  291,\n",
              "  2563,\n",
              "  68,\n",
              "  267,\n",
              "  33],\n",
              " [2241,\n",
              "  107,\n",
              "  1523,\n",
              "  205,\n",
              "  5544,\n",
              "  478,\n",
              "  10,\n",
              "  230,\n",
              "  2535,\n",
              "  7,\n",
              "  91,\n",
              "  59,\n",
              "  67,\n",
              "  197,\n",
              "  212,\n",
              "  2488,\n",
              "  343,\n",
              "  248,\n",
              "  5545,\n",
              "  20,\n",
              "  46,\n",
              "  639,\n",
              "  447,\n",
              "  898,\n",
              "  125,\n",
              "  84,\n",
              "  592,\n",
              "  5546,\n",
              "  1138,\n",
              "  805,\n",
              "  1271,\n",
              "  425,\n",
              "  21,\n",
              "  30,\n",
              "  453,\n",
              "  195,\n",
              "  5547,\n",
              "  51,\n",
              "  6,\n",
              "  36],\n",
              " [9,\n",
              "  64,\n",
              "  1,\n",
              "  479,\n",
              "  5548,\n",
              "  2317,\n",
              "  89,\n",
              "  31,\n",
              "  1817,\n",
              "  24,\n",
              "  5549,\n",
              "  802,\n",
              "  2805,\n",
              "  4,\n",
              "  2,\n",
              "  303,\n",
              "  94,\n",
              "  1347,\n",
              "  311,\n",
              "  14,\n",
              "  227,\n",
              "  5550,\n",
              "  664,\n",
              "  6,\n",
              "  1683,\n",
              "  451,\n",
              "  23,\n",
              "  4,\n",
              "  2,\n",
              "  1,\n",
              "  987,\n",
              "  2128,\n",
              "  679,\n",
              "  438,\n",
              "  138,\n",
              "  6,\n",
              "  1,\n",
              "  210,\n",
              "  534,\n",
              "  1288,\n",
              "  137,\n",
              "  103,\n",
              "  857,\n",
              "  1069,\n",
              "  2804,\n",
              "  1,\n",
              "  277,\n",
              "  38,\n",
              "  943,\n",
              "  189,\n",
              "  61,\n",
              "  709,\n",
              "  1048,\n",
              "  388,\n",
              "  5551,\n",
              "  755,\n",
              "  2574,\n",
              "  238,\n",
              "  4,\n",
              "  2,\n",
              "  1,\n",
              "  39,\n",
              "  2746,\n",
              "  1995,\n",
              "  189,\n",
              "  153],\n",
              " [2803,\n",
              "  1142,\n",
              "  52,\n",
              "  8,\n",
              "  655,\n",
              "  304,\n",
              "  27,\n",
              "  5552,\n",
              "  213,\n",
              "  5553,\n",
              "  562,\n",
              "  91,\n",
              "  584,\n",
              "  3,\n",
              "  71,\n",
              "  350,\n",
              "  2289,\n",
              "  61,\n",
              "  71,\n",
              "  584,\n",
              "  39,\n",
              "  309,\n",
              "  12,\n",
              "  22,\n",
              "  30,\n",
              "  410,\n",
              "  46,\n",
              "  1693,\n",
              "  1019,\n",
              "  1117,\n",
              "  357,\n",
              "  5554,\n",
              "  44,\n",
              "  5555,\n",
              "  5556,\n",
              "  5557,\n",
              "  2475,\n",
              "  5558,\n",
              "  25,\n",
              "  110,\n",
              "  1341,\n",
              "  302,\n",
              "  23,\n",
              "  717,\n",
              "  5559,\n",
              "  112],\n",
              " [5560,\n",
              "  407,\n",
              "  1555,\n",
              "  4,\n",
              "  1461,\n",
              "  2148,\n",
              "  76,\n",
              "  432,\n",
              "  150,\n",
              "  1627,\n",
              "  1478,\n",
              "  5561,\n",
              "  5562,\n",
              "  387,\n",
              "  109,\n",
              "  2,\n",
              "  312,\n",
              "  5563,\n",
              "  149,\n",
              "  11,\n",
              "  2800,\n",
              "  832,\n",
              "  58,\n",
              "  486,\n",
              "  1379,\n",
              "  45,\n",
              "  62,\n",
              "  146,\n",
              "  433,\n",
              "  2656,\n",
              "  1588,\n",
              "  47,\n",
              "  276,\n",
              "  17,\n",
              "  87,\n",
              "  143,\n",
              "  12,\n",
              "  43,\n",
              "  143,\n",
              "  198,\n",
              "  17,\n",
              "  52,\n",
              "  493,\n",
              "  251,\n",
              "  17,\n",
              "  599,\n",
              "  599,\n",
              "  278,\n",
              "  599,\n",
              "  2772,\n",
              "  912,\n",
              "  642,\n",
              "  611,\n",
              "  76,\n",
              "  74,\n",
              "  22,\n",
              "  76,\n",
              "  109],\n",
              " [125,\n",
              "  66,\n",
              "  26,\n",
              "  2813,\n",
              "  667,\n",
              "  2200,\n",
              "  84,\n",
              "  2552,\n",
              "  80,\n",
              "  1161,\n",
              "  5564,\n",
              "  622,\n",
              "  424,\n",
              "  1752,\n",
              "  950,\n",
              "  56,\n",
              "  2094,\n",
              "  5565,\n",
              "  898,\n",
              "  90,\n",
              "  5566,\n",
              "  38,\n",
              "  368,\n",
              "  117,\n",
              "  234,\n",
              "  280,\n",
              "  29,\n",
              "  2521,\n",
              "  212,\n",
              "  5567,\n",
              "  647,\n",
              "  77,\n",
              "  624,\n",
              "  35,\n",
              "  1467,\n",
              "  90,\n",
              "  121,\n",
              "  2260,\n",
              "  77,\n",
              "  998,\n",
              "  457,\n",
              "  546,\n",
              "  165,\n",
              "  1793,\n",
              "  1091,\n",
              "  19,\n",
              "  740,\n",
              "  1154,\n",
              "  1254,\n",
              "  5568,\n",
              "  16,\n",
              "  10,\n",
              "  136,\n",
              "  222,\n",
              "  16,\n",
              "  8],\n",
              " [2628,\n",
              "  71,\n",
              "  506,\n",
              "  1336,\n",
              "  257,\n",
              "  7,\n",
              "  49,\n",
              "  20,\n",
              "  1701,\n",
              "  31,\n",
              "  12,\n",
              "  21,\n",
              "  1318,\n",
              "  792,\n",
              "  385,\n",
              "  545,\n",
              "  127,\n",
              "  13,\n",
              "  113,\n",
              "  5569,\n",
              "  96,\n",
              "  1502,\n",
              "  942],\n",
              " [174,\n",
              "  70,\n",
              "  348,\n",
              "  122,\n",
              "  627,\n",
              "  89,\n",
              "  59,\n",
              "  4,\n",
              "  156,\n",
              "  113,\n",
              "  834,\n",
              "  10,\n",
              "  1596,\n",
              "  1096,\n",
              "  117,\n",
              "  263,\n",
              "  1281,\n",
              "  25,\n",
              "  47,\n",
              "  2471,\n",
              "  116,\n",
              "  335,\n",
              "  86,\n",
              "  2367,\n",
              "  106,\n",
              "  5570,\n",
              "  140,\n",
              "  48,\n",
              "  153,\n",
              "  295,\n",
              "  1188,\n",
              "  44,\n",
              "  47,\n",
              "  16,\n",
              "  503,\n",
              "  229,\n",
              "  2543,\n",
              "  99,\n",
              "  524,\n",
              "  321,\n",
              "  103,\n",
              "  262,\n",
              "  25,\n",
              "  2613,\n",
              "  5571,\n",
              "  5572,\n",
              "  194,\n",
              "  183,\n",
              "  1,\n",
              "  24,\n",
              "  68,\n",
              "  2729,\n",
              "  2,\n",
              "  978,\n",
              "  1426,\n",
              "  772,\n",
              "  33],\n",
              " [255,\n",
              "  184,\n",
              "  5573,\n",
              "  216,\n",
              "  5574,\n",
              "  339,\n",
              "  70,\n",
              "  83,\n",
              "  7,\n",
              "  99,\n",
              "  302,\n",
              "  79,\n",
              "  876,\n",
              "  168,\n",
              "  33,\n",
              "  831,\n",
              "  428,\n",
              "  175,\n",
              "  483,\n",
              "  400,\n",
              "  206,\n",
              "  216,\n",
              "  280,\n",
              "  678,\n",
              "  231,\n",
              "  413,\n",
              "  986,\n",
              "  123,\n",
              "  32,\n",
              "  12,\n",
              "  229,\n",
              "  44,\n",
              "  124,\n",
              "  6,\n",
              "  107,\n",
              "  47,\n",
              "  36,\n",
              "  7,\n",
              "  40,\n",
              "  6,\n",
              "  1560,\n",
              "  7,\n",
              "  641,\n",
              "  140,\n",
              "  33,\n",
              "  30,\n",
              "  401,\n",
              "  503],\n",
              " [150,\n",
              "  68,\n",
              "  1049,\n",
              "  105,\n",
              "  198,\n",
              "  5575,\n",
              "  1751,\n",
              "  315,\n",
              "  5576,\n",
              "  5577,\n",
              "  34,\n",
              "  17,\n",
              "  165,\n",
              "  15,\n",
              "  345,\n",
              "  5578,\n",
              "  16,\n",
              "  44,\n",
              "  175,\n",
              "  355,\n",
              "  357,\n",
              "  548,\n",
              "  242,\n",
              "  513,\n",
              "  847,\n",
              "  5579,\n",
              "  22,\n",
              "  1063,\n",
              "  829,\n",
              "  22,\n",
              "  1063,\n",
              "  5580,\n",
              "  229,\n",
              "  126,\n",
              "  521,\n",
              "  5581,\n",
              "  100,\n",
              "  79,\n",
              "  315,\n",
              "  354],\n",
              " [2624,\n",
              "  101,\n",
              "  1073,\n",
              "  5582,\n",
              "  39,\n",
              "  374,\n",
              "  1400,\n",
              "  3,\n",
              "  534,\n",
              "  462,\n",
              "  410,\n",
              "  148,\n",
              "  200,\n",
              "  194,\n",
              "  100,\n",
              "  396,\n",
              "  7,\n",
              "  2,\n",
              "  50,\n",
              "  48,\n",
              "  2454,\n",
              "  1073,\n",
              "  138,\n",
              "  469,\n",
              "  341,\n",
              "  341,\n",
              "  628,\n",
              "  310],\n",
              " [5583,\n",
              "  1854,\n",
              "  119,\n",
              "  5584,\n",
              "  5585,\n",
              "  211,\n",
              "  287,\n",
              "  107,\n",
              "  5586,\n",
              "  1893,\n",
              "  41,\n",
              "  315,\n",
              "  1264,\n",
              "  1298,\n",
              "  2210,\n",
              "  430],\n",
              " [749,\n",
              "  5,\n",
              "  6,\n",
              "  5587,\n",
              "  1529,\n",
              "  14,\n",
              "  5588,\n",
              "  218,\n",
              "  929,\n",
              "  117,\n",
              "  4,\n",
              "  1139,\n",
              "  285,\n",
              "  268,\n",
              "  52,\n",
              "  1563,\n",
              "  5589,\n",
              "  328,\n",
              "  2,\n",
              "  14,\n",
              "  767,\n",
              "  2702,\n",
              "  525,\n",
              "  650,\n",
              "  1340,\n",
              "  2813,\n",
              "  149,\n",
              "  2748,\n",
              "  817,\n",
              "  240,\n",
              "  1561,\n",
              "  547,\n",
              "  470,\n",
              "  191,\n",
              "  52,\n",
              "  30,\n",
              "  56],\n",
              " [5590,\n",
              "  2129,\n",
              "  239,\n",
              "  1051,\n",
              "  265,\n",
              "  505,\n",
              "  5591,\n",
              "  672,\n",
              "  308,\n",
              "  227,\n",
              "  22,\n",
              "  19,\n",
              "  246,\n",
              "  745,\n",
              "  43,\n",
              "  345,\n",
              "  2707,\n",
              "  72,\n",
              "  670,\n",
              "  339,\n",
              "  326,\n",
              "  594,\n",
              "  6,\n",
              "  223,\n",
              "  37,\n",
              "  19,\n",
              "  1826,\n",
              "  240,\n",
              "  1511,\n",
              "  72,\n",
              "  670,\n",
              "  183,\n",
              "  134,\n",
              "  23,\n",
              "  855,\n",
              "  670,\n",
              "  60,\n",
              "  326,\n",
              "  13,\n",
              "  223,\n",
              "  69,\n",
              "  127,\n",
              "  261,\n",
              "  167,\n",
              "  72,\n",
              "  670,\n",
              "  1571,\n",
              "  326,\n",
              "  948],\n",
              " [80,\n",
              "  84,\n",
              "  5592,\n",
              "  382,\n",
              "  53,\n",
              "  1383,\n",
              "  52,\n",
              "  5593,\n",
              "  205,\n",
              "  160,\n",
              "  869,\n",
              "  52,\n",
              "  269,\n",
              "  10,\n",
              "  19,\n",
              "  1383,\n",
              "  170,\n",
              "  14,\n",
              "  56,\n",
              "  100,\n",
              "  182,\n",
              "  135,\n",
              "  2760,\n",
              "  14,\n",
              "  115,\n",
              "  212,\n",
              "  473],\n",
              " [8,\n",
              "  5,\n",
              "  1220,\n",
              "  86,\n",
              "  228,\n",
              "  27,\n",
              "  401,\n",
              "  237,\n",
              "  384,\n",
              "  5594,\n",
              "  66,\n",
              "  1558,\n",
              "  1465,\n",
              "  18,\n",
              "  319,\n",
              "  130,\n",
              "  642,\n",
              "  500,\n",
              "  130,\n",
              "  118,\n",
              "  72,\n",
              "  26,\n",
              "  1,\n",
              "  985,\n",
              "  124,\n",
              "  921,\n",
              "  37,\n",
              "  2403,\n",
              "  618,\n",
              "  394,\n",
              "  10,\n",
              "  84,\n",
              "  5595,\n",
              "  8,\n",
              "  5,\n",
              "  1697,\n",
              "  1818,\n",
              "  2745,\n",
              "  21,\n",
              "  157,\n",
              "  131,\n",
              "  28,\n",
              "  37,\n",
              "  7,\n",
              "  299,\n",
              "  383,\n",
              "  157,\n",
              "  74,\n",
              "  18,\n",
              "  457,\n",
              "  140,\n",
              "  387,\n",
              "  1329,\n",
              "  401,\n",
              "  4,\n",
              "  518,\n",
              "  1593,\n",
              "  716,\n",
              "  100,\n",
              "  1112],\n",
              " [128,\n",
              "  109,\n",
              "  5596,\n",
              "  5597,\n",
              "  2790,\n",
              "  1558,\n",
              "  1019,\n",
              "  5598,\n",
              "  128,\n",
              "  109,\n",
              "  1848,\n",
              "  5599,\n",
              "  945,\n",
              "  2343,\n",
              "  2638,\n",
              "  102,\n",
              "  2619,\n",
              "  361,\n",
              "  1247,\n",
              "  5600,\n",
              "  5601,\n",
              "  880,\n",
              "  702,\n",
              "  29,\n",
              "  1848,\n",
              "  27,\n",
              "  702,\n",
              "  11,\n",
              "  461,\n",
              "  1054,\n",
              "  29,\n",
              "  1848],\n",
              " [56,\n",
              "  117,\n",
              "  234,\n",
              "  1247,\n",
              "  5602,\n",
              "  73,\n",
              "  195,\n",
              "  2798,\n",
              "  5603,\n",
              "  764,\n",
              "  73,\n",
              "  1433,\n",
              "  67,\n",
              "  195,\n",
              "  234,\n",
              "  35,\n",
              "  6,\n",
              "  82,\n",
              "  712,\n",
              "  67,\n",
              "  24,\n",
              "  392,\n",
              "  55,\n",
              "  1282],\n",
              " [281,\n",
              "  1753,\n",
              "  85,\n",
              "  37,\n",
              "  112,\n",
              "  5604,\n",
              "  20,\n",
              "  15,\n",
              "  982,\n",
              "  101,\n",
              "  2,\n",
              "  579,\n",
              "  328,\n",
              "  2,\n",
              "  475,\n",
              "  531,\n",
              "  126,\n",
              "  68,\n",
              "  33,\n",
              "  2749,\n",
              "  497,\n",
              "  159,\n",
              "  1515],\n",
              " [180,\n",
              "  168,\n",
              "  95,\n",
              "  660,\n",
              "  666,\n",
              "  784,\n",
              "  46,\n",
              "  37,\n",
              "  159,\n",
              "  2370,\n",
              "  666,\n",
              "  294,\n",
              "  442,\n",
              "  5605,\n",
              "  5606,\n",
              "  37,\n",
              "  100,\n",
              "  442,\n",
              "  113,\n",
              "  7,\n",
              "  365,\n",
              "  516,\n",
              "  737,\n",
              "  288,\n",
              "  192,\n",
              "  17,\n",
              "  347,\n",
              "  353,\n",
              "  318,\n",
              "  1034,\n",
              "  19,\n",
              "  1795,\n",
              "  571,\n",
              "  95,\n",
              "  423,\n",
              "  58,\n",
              "  29,\n",
              "  5607,\n",
              "  61,\n",
              "  1090,\n",
              "  353],\n",
              " [202,\n",
              "  34,\n",
              "  15,\n",
              "  817,\n",
              "  5608,\n",
              "  1043,\n",
              "  3,\n",
              "  192,\n",
              "  202,\n",
              "  80,\n",
              "  24,\n",
              "  639,\n",
              "  46,\n",
              "  3,\n",
              "  58,\n",
              "  124,\n",
              "  26,\n",
              "  108,\n",
              "  2814,\n",
              "  5609,\n",
              "  309,\n",
              "  57,\n",
              "  331,\n",
              "  411,\n",
              "  97,\n",
              "  165,\n",
              "  60,\n",
              "  934,\n",
              "  106,\n",
              "  34,\n",
              "  148,\n",
              "  41,\n",
              "  15,\n",
              "  11,\n",
              "  103,\n",
              "  166,\n",
              "  5610,\n",
              "  38,\n",
              "  9,\n",
              "  235,\n",
              "  193,\n",
              "  1053],\n",
              " [51,\n",
              "  32,\n",
              "  1372,\n",
              "  1387,\n",
              "  1296,\n",
              "  1458,\n",
              "  5611,\n",
              "  105,\n",
              "  2291,\n",
              "  441,\n",
              "  16,\n",
              "  1,\n",
              "  987,\n",
              "  468,\n",
              "  1169,\n",
              "  7,\n",
              "  309,\n",
              "  63,\n",
              "  164,\n",
              "  107,\n",
              "  120,\n",
              "  242,\n",
              "  403,\n",
              "  387,\n",
              "  1845,\n",
              "  468,\n",
              "  309,\n",
              "  258,\n",
              "  179,\n",
              "  342,\n",
              "  1845,\n",
              "  2715,\n",
              "  26],\n",
              " [572,\n",
              "  224,\n",
              "  1,\n",
              "  2126,\n",
              "  62,\n",
              "  1224,\n",
              "  464,\n",
              "  604,\n",
              "  5612,\n",
              "  110,\n",
              "  5613,\n",
              "  1442,\n",
              "  235,\n",
              "  1131,\n",
              "  86,\n",
              "  1849,\n",
              "  58,\n",
              "  459,\n",
              "  1849,\n",
              "  430,\n",
              "  565,\n",
              "  172,\n",
              "  7,\n",
              "  812,\n",
              "  41,\n",
              "  5614,\n",
              "  565,\n",
              "  361,\n",
              "  2468,\n",
              "  5615,\n",
              "  755,\n",
              "  2654,\n",
              "  514,\n",
              "  565,\n",
              "  5616,\n",
              "  235,\n",
              "  1131,\n",
              "  688,\n",
              "  459,\n",
              "  1849,\n",
              "  2118,\n",
              "  584,\n",
              "  41,\n",
              "  282,\n",
              "  204,\n",
              "  205,\n",
              "  34,\n",
              "  29,\n",
              "  1017,\n",
              "  5617,\n",
              "  329,\n",
              "  991,\n",
              "  1463,\n",
              "  1698,\n",
              "  708,\n",
              "  340,\n",
              "  1507,\n",
              "  1103,\n",
              "  139,\n",
              "  559,\n",
              "  361,\n",
              "  48,\n",
              "  276,\n",
              "  5618,\n",
              "  1104,\n",
              "  2495,\n",
              "  992,\n",
              "  185,\n",
              "  5619,\n",
              "  340,\n",
              "  1155,\n",
              "  1761,\n",
              "  5620,\n",
              "  2623,\n",
              "  1104],\n",
              " [1395,\n",
              "  7,\n",
              "  405,\n",
              "  268,\n",
              "  7,\n",
              "  5621,\n",
              "  240,\n",
              "  5622,\n",
              "  7,\n",
              "  5623,\n",
              "  5624,\n",
              "  494,\n",
              "  395,\n",
              "  713,\n",
              "  84,\n",
              "  55,\n",
              "  2,\n",
              "  67,\n",
              "  2054,\n",
              "  254,\n",
              "  77,\n",
              "  260,\n",
              "  2084,\n",
              "  1652,\n",
              "  5625,\n",
              "  2153,\n",
              "  501,\n",
              "  268,\n",
              "  424,\n",
              "  5626],\n",
              " [557,\n",
              "  262,\n",
              "  26,\n",
              "  2766,\n",
              "  5627,\n",
              "  147,\n",
              "  41,\n",
              "  125,\n",
              "  1518,\n",
              "  2815,\n",
              "  167,\n",
              "  2539,\n",
              "  45,\n",
              "  5628,\n",
              "  2815,\n",
              "  5629,\n",
              "  419,\n",
              "  12,\n",
              "  31,\n",
              "  1154,\n",
              "  31,\n",
              "  910,\n",
              "  426,\n",
              "  302,\n",
              "  79,\n",
              "  136,\n",
              "  109,\n",
              "  212],\n",
              " [1846,\n",
              "  5630,\n",
              "  118,\n",
              "  681,\n",
              "  5631,\n",
              "  1108,\n",
              "  5632,\n",
              "  408,\n",
              "  393,\n",
              "  423,\n",
              "  11,\n",
              "  6,\n",
              "  116,\n",
              "  939,\n",
              "  42,\n",
              "  82,\n",
              "  73,\n",
              "  2,\n",
              "  5633,\n",
              "  5634,\n",
              "  7,\n",
              "  2768,\n",
              "  241,\n",
              "  1562,\n",
              "  36,\n",
              "  71,\n",
              "  5635,\n",
              "  330,\n",
              "  105,\n",
              "  404,\n",
              "  5636,\n",
              "  1709,\n",
              "  437,\n",
              "  233,\n",
              "  1108,\n",
              "  64,\n",
              "  124,\n",
              "  110,\n",
              "  356,\n",
              "  2259],\n",
              " [168,\n",
              "  10,\n",
              "  5637,\n",
              "  574,\n",
              "  47,\n",
              "  276,\n",
              "  25,\n",
              "  1623,\n",
              "  13,\n",
              "  32,\n",
              "  2406,\n",
              "  53,\n",
              "  81,\n",
              "  487,\n",
              "  181,\n",
              "  169,\n",
              "  309,\n",
              "  102,\n",
              "  331,\n",
              "  4,\n",
              "  362,\n",
              "  13,\n",
              "  77,\n",
              "  5638,\n",
              "  77,\n",
              "  741,\n",
              "  1,\n",
              "  2505,\n",
              "  64,\n",
              "  5639,\n",
              "  210,\n",
              "  85,\n",
              "  57,\n",
              "  137,\n",
              "  1623,\n",
              "  126,\n",
              "  1,\n",
              "  64,\n",
              "  98,\n",
              "  258,\n",
              "  179,\n",
              "  69,\n",
              "  276,\n",
              "  169,\n",
              "  271,\n",
              "  99,\n",
              "  1,\n",
              "  84,\n",
              "  730,\n",
              "  844],\n",
              " [648,\n",
              "  313,\n",
              "  5640,\n",
              "  555,\n",
              "  250,\n",
              "  243,\n",
              "  66,\n",
              "  47,\n",
              "  273,\n",
              "  1983,\n",
              "  191,\n",
              "  5641,\n",
              "  2,\n",
              "  708,\n",
              "  657,\n",
              "  12,\n",
              "  1065,\n",
              "  597,\n",
              "  1048,\n",
              "  244,\n",
              "  796,\n",
              "  2565,\n",
              "  549,\n",
              "  190,\n",
              "  309,\n",
              "  20,\n",
              "  141,\n",
              "  1148,\n",
              "  72,\n",
              "  581,\n",
              "  170,\n",
              "  65,\n",
              "  170,\n",
              "  2566],\n",
              " [314,\n",
              "  459,\n",
              "  132,\n",
              "  357,\n",
              "  214,\n",
              "  315,\n",
              "  1327,\n",
              "  532,\n",
              "  19,\n",
              "  1862,\n",
              "  806,\n",
              "  368,\n",
              "  313,\n",
              "  1075,\n",
              "  48,\n",
              "  444,\n",
              "  87,\n",
              "  8,\n",
              "  12,\n",
              "  312,\n",
              "  870,\n",
              "  12,\n",
              "  18,\n",
              "  5,\n",
              "  321,\n",
              "  418,\n",
              "  29,\n",
              "  2604,\n",
              "  193,\n",
              "  375,\n",
              "  71,\n",
              "  32],\n",
              " [111,\n",
              "  1979,\n",
              "  268,\n",
              "  4,\n",
              "  2,\n",
              "  17,\n",
              "  1407,\n",
              "  33,\n",
              "  145,\n",
              "  101,\n",
              "  5642,\n",
              "  209,\n",
              "  29,\n",
              "  1025,\n",
              "  96,\n",
              "  3,\n",
              "  78,\n",
              "  36,\n",
              "  111,\n",
              "  1603,\n",
              "  214,\n",
              "  2,\n",
              "  14,\n",
              "  1310,\n",
              "  1,\n",
              "  57,\n",
              "  415,\n",
              "  32,\n",
              "  253,\n",
              "  1,\n",
              "  72,\n",
              "  561,\n",
              "  126,\n",
              "  3,\n",
              "  67,\n",
              "  790,\n",
              "  17,\n",
              "  1,\n",
              "  2666],\n",
              " [986,\n",
              "  123,\n",
              "  44,\n",
              "  56,\n",
              "  942,\n",
              "  3,\n",
              "  200,\n",
              "  91,\n",
              "  1462,\n",
              "  133,\n",
              "  9,\n",
              "  209,\n",
              "  310,\n",
              "  92,\n",
              "  41,\n",
              "  153,\n",
              "  418,\n",
              "  694,\n",
              "  852,\n",
              "  124,\n",
              "  34,\n",
              "  5643,\n",
              "  188,\n",
              "  5,\n",
              "  116,\n",
              "  671,\n",
              "  262],\n",
              " [350,\n",
              "  1096,\n",
              "  1347,\n",
              "  2390,\n",
              "  5644,\n",
              "  1035,\n",
              "  463,\n",
              "  1703,\n",
              "  619,\n",
              "  1345,\n",
              "  2816,\n",
              "  93,\n",
              "  954,\n",
              "  5,\n",
              "  115,\n",
              "  194,\n",
              "  528,\n",
              "  43,\n",
              "  5645,\n",
              "  2816,\n",
              "  296,\n",
              "  811,\n",
              "  214,\n",
              "  2814,\n",
              "  854,\n",
              "  145,\n",
              "  5,\n",
              "  1799,\n",
              "  351,\n",
              "  231,\n",
              "  564,\n",
              "  5646,\n",
              "  1484,\n",
              "  656,\n",
              "  429,\n",
              "  1844,\n",
              "  5647,\n",
              "  1500,\n",
              "  377,\n",
              "  2751,\n",
              "  2472,\n",
              "  2750,\n",
              "  1844,\n",
              "  1463,\n",
              "  128,\n",
              "  1135,\n",
              "  708,\n",
              "  38,\n",
              "  89,\n",
              "  13,\n",
              "  33,\n",
              "  886,\n",
              "  52],\n",
              " [10,\n",
              "  39,\n",
              "  2030,\n",
              "  2451,\n",
              "  5648,\n",
              "  641,\n",
              "  142,\n",
              "  205,\n",
              "  417,\n",
              "  1,\n",
              "  1139,\n",
              "  53,\n",
              "  5649,\n",
              "  10,\n",
              "  2422,\n",
              "  227,\n",
              "  22,\n",
              "  19,\n",
              "  1822,\n",
              "  2,\n",
              "  5650],\n",
              " [549,\n",
              "  106,\n",
              "  12,\n",
              "  943,\n",
              "  1,\n",
              "  154,\n",
              "  11,\n",
              "  1,\n",
              "  821,\n",
              "  209,\n",
              "  247,\n",
              "  515,\n",
              "  8,\n",
              "  36,\n",
              "  1943,\n",
              "  26,\n",
              "  58,\n",
              "  415,\n",
              "  155,\n",
              "  244,\n",
              "  5651,\n",
              "  425,\n",
              "  2264,\n",
              "  138,\n",
              "  134,\n",
              "  70,\n",
              "  20,\n",
              "  36,\n",
              "  643,\n",
              "  8,\n",
              "  5,\n",
              "  20,\n",
              "  80],\n",
              " [88,\n",
              "  432,\n",
              "  5652,\n",
              "  5653,\n",
              "  517,\n",
              "  2647,\n",
              "  5654,\n",
              "  5655,\n",
              "  13,\n",
              "  93,\n",
              "  836,\n",
              "  76,\n",
              "  432,\n",
              "  460,\n",
              "  5656,\n",
              "  195,\n",
              "  16,\n",
              "  5657,\n",
              "  54,\n",
              "  5658,\n",
              "  5659,\n",
              "  5660,\n",
              "  5661,\n",
              "  1356,\n",
              "  1760,\n",
              "  340,\n",
              "  1356,\n",
              "  1760],\n",
              " [455,\n",
              "  828,\n",
              "  2810,\n",
              "  269,\n",
              "  1070,\n",
              "  1555,\n",
              "  33,\n",
              "  5662,\n",
              "  1974,\n",
              "  228,\n",
              "  290,\n",
              "  1190,\n",
              "  882,\n",
              "  555,\n",
              "  25,\n",
              "  88,\n",
              "  28,\n",
              "  1190,\n",
              "  882,\n",
              "  210,\n",
              "  830,\n",
              "  749,\n",
              "  1111,\n",
              "  229,\n",
              "  355,\n",
              "  641,\n",
              "  25,\n",
              "  1303,\n",
              "  4,\n",
              "  34,\n",
              "  1597,\n",
              "  65,\n",
              "  52,\n",
              "  105,\n",
              "  360,\n",
              "  924,\n",
              "  2,\n",
              "  382,\n",
              "  278,\n",
              "  87,\n",
              "  5663,\n",
              "  1595,\n",
              "  46,\n",
              "  51,\n",
              "  182,\n",
              "  23],\n",
              " [125,\n",
              "  206,\n",
              "  98,\n",
              "  49,\n",
              "  206,\n",
              "  706,\n",
              "  238,\n",
              "  371,\n",
              "  49,\n",
              "  46,\n",
              "  731,\n",
              "  1573,\n",
              "  1296,\n",
              "  474,\n",
              "  309,\n",
              "  66,\n",
              "  336,\n",
              "  132,\n",
              "  9,\n",
              "  2019,\n",
              "  549,\n",
              "  5664,\n",
              "  313,\n",
              "  1642,\n",
              "  466,\n",
              "  534,\n",
              "  154,\n",
              "  3,\n",
              "  3,\n",
              "  85,\n",
              "  22,\n",
              "  118,\n",
              "  174,\n",
              "  165,\n",
              "  146,\n",
              "  433,\n",
              "  49,\n",
              "  1817,\n",
              "  379,\n",
              "  323,\n",
              "  433,\n",
              "  290,\n",
              "  195,\n",
              "  5665],\n",
              " [161,\n",
              "  5666,\n",
              "  137,\n",
              "  30,\n",
              "  150,\n",
              "  527,\n",
              "  247,\n",
              "  367,\n",
              "  151,\n",
              "  11,\n",
              "  535,\n",
              "  491,\n",
              "  130,\n",
              "  1989,\n",
              "  5667,\n",
              "  535,\n",
              "  1123,\n",
              "  365,\n",
              "  516,\n",
              "  737,\n",
              "  2795,\n",
              "  18,\n",
              "  2625,\n",
              "  2461,\n",
              "  17,\n",
              "  26,\n",
              "  113,\n",
              "  57,\n",
              "  19,\n",
              "  535,\n",
              "  1417,\n",
              "  43,\n",
              "  486,\n",
              "  1650,\n",
              "  198,\n",
              "  41,\n",
              "  3,\n",
              "  861,\n",
              "  189,\n",
              "  5668,\n",
              "  11,\n",
              "  103,\n",
              "  2206,\n",
              "  102,\n",
              "  190,\n",
              "  2571,\n",
              "  91,\n",
              "  571,\n",
              "  115,\n",
              "  18,\n",
              "  2586,\n",
              "  100,\n",
              "  44,\n",
              "  129,\n",
              "  48,\n",
              "  1883,\n",
              "  664,\n",
              "  1145,\n",
              "  374,\n",
              "  157,\n",
              "  673,\n",
              "  126,\n",
              "  197,\n",
              "  2,\n",
              "  14,\n",
              "  950,\n",
              "  1010,\n",
              "  347],\n",
              " [864,\n",
              "  532,\n",
              "  341,\n",
              "  161,\n",
              "  57,\n",
              "  162,\n",
              "  1362,\n",
              "  86,\n",
              "  1837,\n",
              "  175,\n",
              "  570,\n",
              "  412,\n",
              "  2513,\n",
              "  569,\n",
              "  2817,\n",
              "  412,\n",
              "  38,\n",
              "  136,\n",
              "  43,\n",
              "  153,\n",
              "  7,\n",
              "  770,\n",
              "  36,\n",
              "  48,\n",
              "  249,\n",
              "  2817,\n",
              "  878,\n",
              "  412,\n",
              "  77,\n",
              "  363,\n",
              "  5669,\n",
              "  13],\n",
              " [68,\n",
              "  69,\n",
              "  793,\n",
              "  343,\n",
              "  23,\n",
              "  600,\n",
              "  14,\n",
              "  61,\n",
              "  581,\n",
              "  170,\n",
              "  1032,\n",
              "  16,\n",
              "  541,\n",
              "  15,\n",
              "  275,\n",
              "  105,\n",
              "  351,\n",
              "  924,\n",
              "  85,\n",
              "  727,\n",
              "  21,\n",
              "  99,\n",
              "  165,\n",
              "  83,\n",
              "  1361,\n",
              "  170,\n",
              "  45,\n",
              "  191,\n",
              "  42,\n",
              "  204,\n",
              "  354,\n",
              "  5670,\n",
              "  536,\n",
              "  116,\n",
              "  351,\n",
              "  924,\n",
              "  275,\n",
              "  131,\n",
              "  47,\n",
              "  920,\n",
              "  114,\n",
              "  2340,\n",
              "  1387,\n",
              "  638,\n",
              "  70,\n",
              "  638,\n",
              "  998,\n",
              "  45],\n",
              " [91,\n",
              "  144,\n",
              "  610,\n",
              "  5671,\n",
              "  37,\n",
              "  65,\n",
              "  102,\n",
              "  581,\n",
              "  1654,\n",
              "  105,\n",
              "  5672,\n",
              "  20,\n",
              "  46,\n",
              "  2720,\n",
              "  482,\n",
              "  192,\n",
              "  1695,\n",
              "  8,\n",
              "  113,\n",
              "  127,\n",
              "  60,\n",
              "  135,\n",
              "  1273,\n",
              "  337,\n",
              "  5673,\n",
              "  5674,\n",
              "  5675,\n",
              "  163,\n",
              "  5676,\n",
              "  130],\n",
              " [244,\n",
              "  5,\n",
              "  1553,\n",
              "  1850,\n",
              "  991,\n",
              "  40,\n",
              "  45,\n",
              "  5677,\n",
              "  628,\n",
              "  1850,\n",
              "  2818,\n",
              "  628,\n",
              "  775,\n",
              "  815,\n",
              "  667,\n",
              "  5678,\n",
              "  99,\n",
              "  1306,\n",
              "  24,\n",
              "  5679,\n",
              "  775,\n",
              "  202,\n",
              "  775,\n",
              "  815,\n",
              "  2819,\n",
              "  5680,\n",
              "  5681,\n",
              "  24,\n",
              "  76,\n",
              "  5682,\n",
              "  292,\n",
              "  173,\n",
              "  775,\n",
              "  815,\n",
              "  667,\n",
              "  1850,\n",
              "  2818,\n",
              "  2819,\n",
              "  292,\n",
              "  173,\n",
              "  775,\n",
              "  815,\n",
              "  667,\n",
              "  173],\n",
              " [3,\n",
              "  743,\n",
              "  502,\n",
              "  9,\n",
              "  121,\n",
              "  3,\n",
              "  187,\n",
              "  90,\n",
              "  133,\n",
              "  2192,\n",
              "  2,\n",
              "  1,\n",
              "  399,\n",
              "  5683,\n",
              "  146,\n",
              "  502,\n",
              "  314,\n",
              "  90,\n",
              "  338,\n",
              "  143,\n",
              "  411,\n",
              "  622,\n",
              "  35,\n",
              "  6,\n",
              "  10,\n",
              "  9,\n",
              "  67,\n",
              "  5684,\n",
              "  106,\n",
              "  1830,\n",
              "  5685,\n",
              "  105,\n",
              "  404,\n",
              "  194,\n",
              "  786,\n",
              "  16,\n",
              "  163,\n",
              "  87,\n",
              "  157,\n",
              "  85,\n",
              "  51,\n",
              "  6,\n",
              "  17,\n",
              "  719,\n",
              "  117,\n",
              "  234],\n",
              " [1,\n",
              "  40,\n",
              "  62,\n",
              "  2573,\n",
              "  72,\n",
              "  5686,\n",
              "  143,\n",
              "  723,\n",
              "  2789,\n",
              "  1476,\n",
              "  1,\n",
              "  285,\n",
              "  5687,\n",
              "  105,\n",
              "  634,\n",
              "  5688,\n",
              "  762,\n",
              "  105,\n",
              "  2820,\n",
              "  53,\n",
              "  2,\n",
              "  1,\n",
              "  920,\n",
              "  124,\n",
              "  1637,\n",
              "  178,\n",
              "  5689,\n",
              "  51,\n",
              "  6,\n",
              "  116,\n",
              "  944,\n",
              "  535,\n",
              "  249,\n",
              "  5690,\n",
              "  45,\n",
              "  191,\n",
              "  288,\n",
              "  5691,\n",
              "  2052,\n",
              "  5692,\n",
              "  178,\n",
              "  245,\n",
              "  437,\n",
              "  72,\n",
              "  4,\n",
              "  2,\n",
              "  1,\n",
              "  24,\n",
              "  342,\n",
              "  6,\n",
              "  1012,\n",
              "  1,\n",
              "  2802,\n",
              "  1,\n",
              "  490,\n",
              "  6,\n",
              "  265,\n",
              "  295,\n",
              "  1,\n",
              "  84,\n",
              "  730,\n",
              "  730,\n",
              "  2821,\n",
              "  2821,\n",
              "  2626,\n",
              "  43,\n",
              "  2820,\n",
              "  449,\n",
              "  5693,\n",
              "  105,\n",
              "  5694,\n",
              "  178,\n",
              "  954]]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(seq) for seq in (train_text_vec + test_text_vec)])\n",
        "from keras.preprocessing import sequence\n",
        "max_words = max_length\n",
        "X_train = keras.utils.pad_sequences(train_text_vec, maxlen=max_words)\n",
        "X_test = keras.utils.pad_sequences(test_text_vec, maxlen=max_words)\n",
        "modelRNN = None\n",
        "modelLSTM = None\n",
        "print(\"After Padding x[train[0]=\\n\" , X_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzRdm-lF8s7J",
        "outputId": "aa693c99-527e-4847-daad-d95a57daa1ad"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Padding x[train[0]=\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0  172  794 2173    2  287\n",
            "  155  172   50 5429    9  154  479  289   36   84   66  954   43  211\n",
            "  204    6  287]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelling**"
      ],
      "metadata": {
        "id": "zTcQUwY3-LOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXi3wnTY931E",
        "outputId": "08ad51f3-d9f1-4b44-9829-b064cf117c07"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5694 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = len((train_text_vec + test_text_vec))*2\n",
        "vocabulary_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO8I41Rc-Ose",
        "outputId": "e3cb1dbc-22f8-4e07-b624-8ffe47d79a00"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1430"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Glove Embeddings**"
      ],
      "metadata": {
        "id": "mt89vPL4-Ve7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open('/content/glove.6B.100d.txt',encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4jfPYEZ-RPQ",
        "outputId": "7e1c2f11-4389-40d8-c679-1cc06e8c99d8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 328025 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "c1NetEk--iSA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recurrent Neural Network(RNN)**"
      ],
      "metadata": {
        "id": "jSGy2krD_LBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "rDWCjv3q-zB_"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size=100\n",
        "\n",
        "\n",
        "modelRNN=Sequential()\n",
        "modelRNN.add(Embedding(len(word_index) + 1,embedding_size,weights = [embedding_matrix],input_length=max_words)) #embdsize\n",
        "# modelRNN.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "modelRNN.add(Dropout(0.70))\n",
        "modelRNN.add(SimpleRNN(150,activation = \"tanh\",kernel_regularizer=regularizers.l2(0.01))) \n",
        "modelRNN.add(Dropout(0.15))\n",
        "modelRNN.add(Dense(10, activation='softmax'))\n",
        "print(modelRNN.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GprU_wh0_OoQ",
        "outputId": "94cbc5d0-ee7f-4257-d565-8600fda1c3c4"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 129, 100)          569500    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 129, 100)          0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 150)               37650     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 150)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1510      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 608,660\n",
            "Trainable params: 608,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelRNN.compile(loss='categorical_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'],run_eagerly=True)"
      ],
      "metadata": {
        "id": "xypMQwcl_f6D"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "num_epochs = 300\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "callback_listRNN  = [#early1\n",
        "                keras.callbacks.ModelCheckpoint(filepath=\"my_modRNN_BestValAcc.h5\", monitor=\"val_acc\",\n",
        "                                               save_best_only=True),\n",
        "                #keras.callbacks.TerminateOnNaN()\n",
        "                ]"
      ],
      "metadata": {
        "id": "_kEB2htp_odH"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "MRmR9tznEnEx",
        "outputId": "91d0ce6d-8f99-4490-b01f-1d1218ee5273"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     almosthomeless  anxiety  assistance  domesticviolence  food_pantry  \\\n",
              "591               0        1           0                 0            0   \n",
              "302               0        0           0                 1            0   \n",
              "101               0        1           0                 0            0   \n",
              "526               0        0           0                 0            0   \n",
              "192               0        0           0                 0            0   \n",
              "..              ...      ...         ...               ...          ...   \n",
              "71                0        0           0                 1            0   \n",
              "106               0        0           0                 0            0   \n",
              "270               0        0           0                 0            0   \n",
              "435               0        0           0                 0            0   \n",
              "102               0        0           0                 0            0   \n",
              "\n",
              "     homeless  ptsd  relationships  stress  survivorsofabuse  \n",
              "591         0     0              0       0                 0  \n",
              "302         0     0              0       0                 0  \n",
              "101         0     0              0       0                 0  \n",
              "526         0     0              1       0                 0  \n",
              "192         0     1              0       0                 0  \n",
              "..        ...   ...            ...     ...               ...  \n",
              "71          0     0              0       0                 0  \n",
              "106         0     0              0       0                 1  \n",
              "270         0     1              0       0                 0  \n",
              "435         0     0              1       0                 0  \n",
              "102         0     0              0       0                 1  \n",
              "\n",
              "[643 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5000a968-820a-4679-9ddc-b5846c231b6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>almosthomeless</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>assistance</th>\n",
              "      <th>domesticviolence</th>\n",
              "      <th>food_pantry</th>\n",
              "      <th>homeless</th>\n",
              "      <th>ptsd</th>\n",
              "      <th>relationships</th>\n",
              "      <th>stress</th>\n",
              "      <th>survivorsofabuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>643 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5000a968-820a-4679-9ddc-b5846c231b6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5000a968-820a-4679-9ddc-b5846c231b6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5000a968-820a-4679-9ddc-b5846c231b6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "history = modelRNN.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs, \n",
        "             callbacks=callback_listRNN)\n",
        "modelRNN.save_weights(\"my_modRNN_Latest\")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrfFwjZJ_rzA",
        "outputId": "02f83c15-5ded-419f-b3a6-836209da405b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - ETA: 0s - loss: 3.9483 - accuracy: 0.1135"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 969ms/step - loss: 3.9483 - accuracy: 0.1135 - val_loss: 3.6354 - val_accuracy: 0.1462\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.8187 - accuracy: 0.1135"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 3.8187 - accuracy: 0.1135 - val_loss: 3.4871 - val_accuracy: 0.1773\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7676 - accuracy: 0.1229"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 3.7676 - accuracy: 0.1229 - val_loss: 3.3772 - val_accuracy: 0.1897\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6695 - accuracy: 0.1571"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 3.6695 - accuracy: 0.1571 - val_loss: 3.2963 - val_accuracy: 0.2193\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5970 - accuracy: 0.1555"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 690ms/step - loss: 3.5970 - accuracy: 0.1555 - val_loss: 3.2381 - val_accuracy: 0.2317\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5369 - accuracy: 0.1555"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 699ms/step - loss: 3.5369 - accuracy: 0.1555 - val_loss: 3.1978 - val_accuracy: 0.2348\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5158 - accuracy: 0.1835"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 692ms/step - loss: 3.5158 - accuracy: 0.1835 - val_loss: 3.1728 - val_accuracy: 0.2535\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.4318 - accuracy: 0.1913"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 718ms/step - loss: 3.4318 - accuracy: 0.1913 - val_loss: 3.1609 - val_accuracy: 0.2737\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.4227 - accuracy: 0.1851"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 637ms/step - loss: 3.4227 - accuracy: 0.1851 - val_loss: 3.1590 - val_accuracy: 0.2706\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3450 - accuracy: 0.2006"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 639ms/step - loss: 3.3450 - accuracy: 0.2006 - val_loss: 3.1649 - val_accuracy: 0.2535\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3325 - accuracy: 0.2146"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 692ms/step - loss: 3.3325 - accuracy: 0.2146 - val_loss: 3.1720 - val_accuracy: 0.2582\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3162 - accuracy: 0.2006"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 633ms/step - loss: 3.3162 - accuracy: 0.2006 - val_loss: 3.1736 - val_accuracy: 0.2535\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2657 - accuracy: 0.2100"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 691ms/step - loss: 3.2657 - accuracy: 0.2100 - val_loss: 3.1655 - val_accuracy: 0.2504\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2641 - accuracy: 0.2240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 627ms/step - loss: 3.2641 - accuracy: 0.2240 - val_loss: 3.1435 - val_accuracy: 0.2535\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2264 - accuracy: 0.2208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 620ms/step - loss: 3.2264 - accuracy: 0.2208 - val_loss: 3.1066 - val_accuracy: 0.2551\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2213 - accuracy: 0.2302"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 648ms/step - loss: 3.2213 - accuracy: 0.2302 - val_loss: 3.0607 - val_accuracy: 0.2582\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2072 - accuracy: 0.2271"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 727ms/step - loss: 3.2072 - accuracy: 0.2271 - val_loss: 3.0150 - val_accuracy: 0.2753\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1074 - accuracy: 0.2395"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 650ms/step - loss: 3.1074 - accuracy: 0.2395 - val_loss: 2.9743 - val_accuracy: 0.2815\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0977 - accuracy: 0.2582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 3.0977 - accuracy: 0.2582 - val_loss: 2.9419 - val_accuracy: 0.3017\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0413 - accuracy: 0.2706"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 844ms/step - loss: 3.0413 - accuracy: 0.2706 - val_loss: 2.9167 - val_accuracy: 0.3593\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0668 - accuracy: 0.2395"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 3.0668 - accuracy: 0.2395 - val_loss: 2.8960 - val_accuracy: 0.3686\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0605 - accuracy: 0.2457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 3.0605 - accuracy: 0.2457 - val_loss: 2.8773 - val_accuracy: 0.3810\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0342 - accuracy: 0.2613"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 969ms/step - loss: 3.0342 - accuracy: 0.2613 - val_loss: 2.8578 - val_accuracy: 0.3764\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0300 - accuracy: 0.2302"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 702ms/step - loss: 3.0300 - accuracy: 0.2302 - val_loss: 2.8363 - val_accuracy: 0.3826\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9824 - accuracy: 0.2722"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 723ms/step - loss: 2.9824 - accuracy: 0.2722 - val_loss: 2.8121 - val_accuracy: 0.4012\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0268 - accuracy: 0.2426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 710ms/step - loss: 3.0268 - accuracy: 0.2426 - val_loss: 2.7877 - val_accuracy: 0.3857\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9631 - accuracy: 0.2566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 659ms/step - loss: 2.9631 - accuracy: 0.2566 - val_loss: 2.7647 - val_accuracy: 0.3795\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9412 - accuracy: 0.2644"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 648ms/step - loss: 2.9412 - accuracy: 0.2644 - val_loss: 2.7426 - val_accuracy: 0.3764\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9152 - accuracy: 0.2395"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 660ms/step - loss: 2.9152 - accuracy: 0.2395 - val_loss: 2.7210 - val_accuracy: 0.3670\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8752 - accuracy: 0.2722"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 691ms/step - loss: 2.8752 - accuracy: 0.2722 - val_loss: 2.6993 - val_accuracy: 0.3639\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8795 - accuracy: 0.2784"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 737ms/step - loss: 2.8795 - accuracy: 0.2784 - val_loss: 2.6758 - val_accuracy: 0.3624\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8658 - accuracy: 0.2628"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 627ms/step - loss: 2.8658 - accuracy: 0.2628 - val_loss: 2.6490 - val_accuracy: 0.3686\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8076 - accuracy: 0.2799"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 611ms/step - loss: 2.8076 - accuracy: 0.2799 - val_loss: 2.6215 - val_accuracy: 0.3779\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8191 - accuracy: 0.2628"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 644ms/step - loss: 2.8191 - accuracy: 0.2628 - val_loss: 2.5952 - val_accuracy: 0.3935\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8142 - accuracy: 0.2815"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 701ms/step - loss: 2.8142 - accuracy: 0.2815 - val_loss: 2.5701 - val_accuracy: 0.4137\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7878 - accuracy: 0.2908"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 702ms/step - loss: 2.7878 - accuracy: 0.2908 - val_loss: 2.5440 - val_accuracy: 0.4277\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7917 - accuracy: 0.3064"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 654ms/step - loss: 2.7917 - accuracy: 0.3064 - val_loss: 2.5176 - val_accuracy: 0.4401\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7415 - accuracy: 0.3002"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.7415 - accuracy: 0.3002 - val_loss: 2.4900 - val_accuracy: 0.4526\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6998 - accuracy: 0.2939"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.6998 - accuracy: 0.2939 - val_loss: 2.4619 - val_accuracy: 0.4603\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7342 - accuracy: 0.2986"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.7342 - accuracy: 0.2986 - val_loss: 2.4351 - val_accuracy: 0.4759\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6824 - accuracy: 0.3344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.6824 - accuracy: 0.3344 - val_loss: 2.4094 - val_accuracy: 0.4868\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7004 - accuracy: 0.2862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 914ms/step - loss: 2.7004 - accuracy: 0.2862 - val_loss: 2.3847 - val_accuracy: 0.4946\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6939 - accuracy: 0.3064"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 640ms/step - loss: 2.6939 - accuracy: 0.3064 - val_loss: 2.3615 - val_accuracy: 0.5023\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6468 - accuracy: 0.3390"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 722ms/step - loss: 2.6468 - accuracy: 0.3390 - val_loss: 2.3409 - val_accuracy: 0.4977\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6097 - accuracy: 0.3359"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 683ms/step - loss: 2.6097 - accuracy: 0.3359 - val_loss: 2.3225 - val_accuracy: 0.5039\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6417 - accuracy: 0.2784"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 657ms/step - loss: 2.6417 - accuracy: 0.2784 - val_loss: 2.3035 - val_accuracy: 0.5117\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5699 - accuracy: 0.3530"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 723ms/step - loss: 2.5699 - accuracy: 0.3530 - val_loss: 2.2854 - val_accuracy: 0.5101\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5992 - accuracy: 0.3328"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 726ms/step - loss: 2.5992 - accuracy: 0.3328 - val_loss: 2.2675 - val_accuracy: 0.5070\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5478 - accuracy: 0.3593"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 656ms/step - loss: 2.5478 - accuracy: 0.3593 - val_loss: 2.2515 - val_accuracy: 0.5023\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4997 - accuracy: 0.3608"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 713ms/step - loss: 2.4997 - accuracy: 0.3608 - val_loss: 2.2348 - val_accuracy: 0.5054\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5100 - accuracy: 0.3499"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 724ms/step - loss: 2.5100 - accuracy: 0.3499 - val_loss: 2.2158 - val_accuracy: 0.5132\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4990 - accuracy: 0.3390"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 699ms/step - loss: 2.4990 - accuracy: 0.3390 - val_loss: 2.1952 - val_accuracy: 0.5241\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4517 - accuracy: 0.3841"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 719ms/step - loss: 2.4517 - accuracy: 0.3841 - val_loss: 2.1723 - val_accuracy: 0.5474\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4767 - accuracy: 0.3686"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 724ms/step - loss: 2.4767 - accuracy: 0.3686 - val_loss: 2.1499 - val_accuracy: 0.5583\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4537 - accuracy: 0.3857"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 644ms/step - loss: 2.4537 - accuracy: 0.3857 - val_loss: 2.1264 - val_accuracy: 0.5614\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4766 - accuracy: 0.3281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 669ms/step - loss: 2.4766 - accuracy: 0.3281 - val_loss: 2.1030 - val_accuracy: 0.5723\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4289 - accuracy: 0.3857"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.4289 - accuracy: 0.3857 - val_loss: 2.0793 - val_accuracy: 0.5785\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4534 - accuracy: 0.3468"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.4534 - accuracy: 0.3468 - val_loss: 2.0577 - val_accuracy: 0.5832\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3931 - accuracy: 0.3826"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.3931 - accuracy: 0.3826 - val_loss: 2.0327 - val_accuracy: 0.6019\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4026 - accuracy: 0.3515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.4026 - accuracy: 0.3515 - val_loss: 2.0090 - val_accuracy: 0.6096\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3817 - accuracy: 0.3810"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 695ms/step - loss: 2.3817 - accuracy: 0.3810 - val_loss: 1.9858 - val_accuracy: 0.6221\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3193 - accuracy: 0.4137"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 702ms/step - loss: 2.3193 - accuracy: 0.4137 - val_loss: 1.9634 - val_accuracy: 0.6252\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3599 - accuracy: 0.3810"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 629ms/step - loss: 2.3599 - accuracy: 0.3810 - val_loss: 1.9414 - val_accuracy: 0.6361\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3539 - accuracy: 0.3593"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 652ms/step - loss: 2.3539 - accuracy: 0.3593 - val_loss: 1.9229 - val_accuracy: 0.6392\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3005 - accuracy: 0.3795"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 640ms/step - loss: 2.3005 - accuracy: 0.3795 - val_loss: 1.9020 - val_accuracy: 0.6423\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2979 - accuracy: 0.4292"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 648ms/step - loss: 2.2979 - accuracy: 0.4292 - val_loss: 1.8773 - val_accuracy: 0.6485\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3271 - accuracy: 0.3997"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 729ms/step - loss: 2.3271 - accuracy: 0.3997 - val_loss: 1.8487 - val_accuracy: 0.6547\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2337 - accuracy: 0.4075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 708ms/step - loss: 2.2337 - accuracy: 0.4075 - val_loss: 1.8181 - val_accuracy: 0.6625\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2591 - accuracy: 0.4184"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 714ms/step - loss: 2.2591 - accuracy: 0.4184 - val_loss: 1.7903 - val_accuracy: 0.6656\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2544 - accuracy: 0.3966"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 702ms/step - loss: 2.2544 - accuracy: 0.3966 - val_loss: 1.7635 - val_accuracy: 0.6719\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1869 - accuracy: 0.4432"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 656ms/step - loss: 2.1869 - accuracy: 0.4432 - val_loss: 1.7369 - val_accuracy: 0.6750\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2439 - accuracy: 0.3919"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 702ms/step - loss: 2.2439 - accuracy: 0.3919 - val_loss: 1.7109 - val_accuracy: 0.6843\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1965 - accuracy: 0.4261"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 713ms/step - loss: 2.1965 - accuracy: 0.4261 - val_loss: 1.6843 - val_accuracy: 0.6921\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1783 - accuracy: 0.4277"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 641ms/step - loss: 2.1783 - accuracy: 0.4277 - val_loss: 1.6583 - val_accuracy: 0.6998\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1819 - accuracy: 0.4184"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 714ms/step - loss: 2.1819 - accuracy: 0.4184 - val_loss: 1.6356 - val_accuracy: 0.7061\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1427 - accuracy: 0.4541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.1427 - accuracy: 0.4541 - val_loss: 1.6137 - val_accuracy: 0.7138\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1433 - accuracy: 0.4417"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.1433 - accuracy: 0.4417 - val_loss: 1.5940 - val_accuracy: 0.7185\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1054 - accuracy: 0.4308"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.1054 - accuracy: 0.4308 - val_loss: 1.5744 - val_accuracy: 0.7185\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0477 - accuracy: 0.4977"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.0477 - accuracy: 0.4977 - val_loss: 1.5529 - val_accuracy: 0.7247\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1088 - accuracy: 0.4603"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 770ms/step - loss: 2.1088 - accuracy: 0.4603 - val_loss: 1.5310 - val_accuracy: 0.7247\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0692 - accuracy: 0.4526"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 641ms/step - loss: 2.0692 - accuracy: 0.4526 - val_loss: 1.5062 - val_accuracy: 0.7356\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0407 - accuracy: 0.4650"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 663ms/step - loss: 2.0407 - accuracy: 0.4650 - val_loss: 1.4768 - val_accuracy: 0.7496\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0434 - accuracy: 0.4557"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 700ms/step - loss: 2.0434 - accuracy: 0.4557 - val_loss: 1.4501 - val_accuracy: 0.7621\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9947 - accuracy: 0.4790"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 675ms/step - loss: 1.9947 - accuracy: 0.4790 - val_loss: 1.4234 - val_accuracy: 0.7776\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0173 - accuracy: 0.4417"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 722ms/step - loss: 2.0173 - accuracy: 0.4417 - val_loss: 1.4007 - val_accuracy: 0.7823\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9839 - accuracy: 0.4728"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 717ms/step - loss: 1.9839 - accuracy: 0.4728 - val_loss: 1.3795 - val_accuracy: 0.7885\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9334 - accuracy: 0.5086"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 681ms/step - loss: 1.9334 - accuracy: 0.5086 - val_loss: 1.3602 - val_accuracy: 0.7978\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9159 - accuracy: 0.5039"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 674ms/step - loss: 1.9159 - accuracy: 0.5039 - val_loss: 1.3467 - val_accuracy: 0.7885\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9604 - accuracy: 0.4930"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 677ms/step - loss: 1.9604 - accuracy: 0.4930 - val_loss: 1.3350 - val_accuracy: 0.7823\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9004 - accuracy: 0.4961"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 722ms/step - loss: 1.9004 - accuracy: 0.4961 - val_loss: 1.3181 - val_accuracy: 0.7916\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8880 - accuracy: 0.5148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 732ms/step - loss: 1.8880 - accuracy: 0.5148 - val_loss: 1.2951 - val_accuracy: 0.7916\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8751 - accuracy: 0.5163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 725ms/step - loss: 1.8751 - accuracy: 0.5163 - val_loss: 1.2730 - val_accuracy: 0.7947\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8802 - accuracy: 0.5054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 724ms/step - loss: 1.8802 - accuracy: 0.5054 - val_loss: 1.2448 - val_accuracy: 0.8134\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8721 - accuracy: 0.5163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.8721 - accuracy: 0.5163 - val_loss: 1.2348 - val_accuracy: 0.8274\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8189 - accuracy: 0.5194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.8189 - accuracy: 0.5194 - val_loss: 1.2677 - val_accuracy: 0.8087\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8103 - accuracy: 0.5334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.8103 - accuracy: 0.5334 - val_loss: 1.2802 - val_accuracy: 0.7823\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7993 - accuracy: 0.5412"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.7993 - accuracy: 0.5412 - val_loss: 1.2564 - val_accuracy: 0.7838\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7496 - accuracy: 0.5661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 837ms/step - loss: 1.7496 - accuracy: 0.5661 - val_loss: 1.2578 - val_accuracy: 0.7792\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8181 - accuracy: 0.5101"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 660ms/step - loss: 1.8181 - accuracy: 0.5101 - val_loss: 1.3297 - val_accuracy: 0.7356\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7302 - accuracy: 0.5770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 722ms/step - loss: 1.7302 - accuracy: 0.5770 - val_loss: 1.5084 - val_accuracy: 0.6765\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6819 - accuracy: 0.5941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 660ms/step - loss: 1.6819 - accuracy: 0.5941 - val_loss: 1.5106 - val_accuracy: 0.6672\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7155 - accuracy: 0.5801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 649ms/step - loss: 1.7155 - accuracy: 0.5801 - val_loss: 1.2516 - val_accuracy: 0.7574\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6776 - accuracy: 0.5630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 704ms/step - loss: 1.6776 - accuracy: 0.5630 - val_loss: 1.1563 - val_accuracy: 0.7963\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6960 - accuracy: 0.5661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 712ms/step - loss: 1.6960 - accuracy: 0.5661 - val_loss: 1.1480 - val_accuracy: 0.7947\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7009 - accuracy: 0.5412"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 653ms/step - loss: 1.7009 - accuracy: 0.5412 - val_loss: 1.2001 - val_accuracy: 0.7714\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6728 - accuracy: 0.5832"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 712ms/step - loss: 1.6728 - accuracy: 0.5832 - val_loss: 1.1157 - val_accuracy: 0.8118\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5809 - accuracy: 0.5941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 646ms/step - loss: 1.5809 - accuracy: 0.5941 - val_loss: 0.9885 - val_accuracy: 0.8600\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6492 - accuracy: 0.6003"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 711ms/step - loss: 1.6492 - accuracy: 0.6003 - val_loss: 1.0067 - val_accuracy: 0.8336\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5694 - accuracy: 0.5972"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 702ms/step - loss: 1.5694 - accuracy: 0.5972 - val_loss: 1.0069 - val_accuracy: 0.8351\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5769 - accuracy: 0.5863"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 643ms/step - loss: 1.5769 - accuracy: 0.5863 - val_loss: 0.9417 - val_accuracy: 0.8787\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5219 - accuracy: 0.6236"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 695ms/step - loss: 1.5219 - accuracy: 0.6236 - val_loss: 0.9127 - val_accuracy: 0.8756\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5273 - accuracy: 0.6096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 651ms/step - loss: 1.5273 - accuracy: 0.6096 - val_loss: 0.9640 - val_accuracy: 0.8616\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5533 - accuracy: 0.5988"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 855ms/step - loss: 1.5533 - accuracy: 0.5988 - val_loss: 0.9376 - val_accuracy: 0.8709\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5033 - accuracy: 0.6190"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.5033 - accuracy: 0.6190 - val_loss: 0.8954 - val_accuracy: 0.8802\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4960 - accuracy: 0.6112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.4960 - accuracy: 0.6112 - val_loss: 0.9282 - val_accuracy: 0.8507\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5432 - accuracy: 0.5770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 996ms/step - loss: 1.5432 - accuracy: 0.5770 - val_loss: 0.9042 - val_accuracy: 0.8569\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5427 - accuracy: 0.5879"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.5427 - accuracy: 0.5879 - val_loss: 0.9167 - val_accuracy: 0.8569\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4818 - accuracy: 0.6376"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 651ms/step - loss: 1.4818 - accuracy: 0.6376 - val_loss: 0.9837 - val_accuracy: 0.8305\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4673 - accuracy: 0.6392"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 714ms/step - loss: 1.4673 - accuracy: 0.6392 - val_loss: 0.8772 - val_accuracy: 0.8616\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4323 - accuracy: 0.6485"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 702ms/step - loss: 1.4323 - accuracy: 0.6485 - val_loss: 0.8446 - val_accuracy: 0.8709\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3856 - accuracy: 0.6719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 710ms/step - loss: 1.3856 - accuracy: 0.6719 - val_loss: 0.8101 - val_accuracy: 0.8942\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4181 - accuracy: 0.6267"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 663ms/step - loss: 1.4181 - accuracy: 0.6267 - val_loss: 0.7902 - val_accuracy: 0.9051\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3778 - accuracy: 0.6532"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 675ms/step - loss: 1.3778 - accuracy: 0.6532 - val_loss: 0.8217 - val_accuracy: 0.8818\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3985 - accuracy: 0.6361"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 640ms/step - loss: 1.3985 - accuracy: 0.6361 - val_loss: 0.8348 - val_accuracy: 0.8725\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3321 - accuracy: 0.6765"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 726ms/step - loss: 1.3321 - accuracy: 0.6765 - val_loss: 0.7867 - val_accuracy: 0.8958\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3224 - accuracy: 0.6827"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 714ms/step - loss: 1.3224 - accuracy: 0.6827 - val_loss: 0.7903 - val_accuracy: 0.8974\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3502 - accuracy: 0.6610"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 724ms/step - loss: 1.3502 - accuracy: 0.6610 - val_loss: 0.8651 - val_accuracy: 0.8585\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3563 - accuracy: 0.6579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 665ms/step - loss: 1.3563 - accuracy: 0.6579 - val_loss: 0.8621 - val_accuracy: 0.8600\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3004 - accuracy: 0.6952"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 720ms/step - loss: 1.3004 - accuracy: 0.6952 - val_loss: 0.8421 - val_accuracy: 0.8631\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3270 - accuracy: 0.6501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 628ms/step - loss: 1.3270 - accuracy: 0.6501 - val_loss: 0.8110 - val_accuracy: 0.8694\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2908 - accuracy: 0.6625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 700ms/step - loss: 1.2908 - accuracy: 0.6625 - val_loss: 0.7135 - val_accuracy: 0.9067\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2618 - accuracy: 0.6921"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.2618 - accuracy: 0.6921 - val_loss: 0.6838 - val_accuracy: 0.9207\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2788 - accuracy: 0.6843"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.2788 - accuracy: 0.6843 - val_loss: 0.6673 - val_accuracy: 0.9238\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2300 - accuracy: 0.7092"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.2300 - accuracy: 0.7092 - val_loss: 0.7525 - val_accuracy: 0.9036\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2350 - accuracy: 0.7014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.2350 - accuracy: 0.7014 - val_loss: 0.7201 - val_accuracy: 0.9051\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2053 - accuracy: 0.7030"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 787ms/step - loss: 1.2053 - accuracy: 0.7030 - val_loss: 0.7090 - val_accuracy: 0.8989\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2079 - accuracy: 0.6998"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 673ms/step - loss: 1.2079 - accuracy: 0.6998 - val_loss: 0.8066 - val_accuracy: 0.8694\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2292 - accuracy: 0.7138"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 638ms/step - loss: 1.2292 - accuracy: 0.7138 - val_loss: 0.8967 - val_accuracy: 0.8165\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1630 - accuracy: 0.7216"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 711ms/step - loss: 1.1630 - accuracy: 0.7216 - val_loss: 0.7030 - val_accuracy: 0.9051\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1445 - accuracy: 0.7294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 717ms/step - loss: 1.1445 - accuracy: 0.7294 - val_loss: 0.6150 - val_accuracy: 0.9378\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1601 - accuracy: 0.7061"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 714ms/step - loss: 1.1601 - accuracy: 0.7061 - val_loss: 0.6026 - val_accuracy: 0.9409\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1595 - accuracy: 0.7154"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 725ms/step - loss: 1.1595 - accuracy: 0.7154 - val_loss: 0.5848 - val_accuracy: 0.9440\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1584 - accuracy: 0.7201"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 725ms/step - loss: 1.1584 - accuracy: 0.7201 - val_loss: 0.5551 - val_accuracy: 0.9580\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1121 - accuracy: 0.7481"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 670ms/step - loss: 1.1121 - accuracy: 0.7481 - val_loss: 0.5365 - val_accuracy: 0.9611\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0992 - accuracy: 0.7512"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 658ms/step - loss: 1.0992 - accuracy: 0.7512 - val_loss: 0.5339 - val_accuracy: 0.9596\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0764 - accuracy: 0.7325"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 723ms/step - loss: 1.0764 - accuracy: 0.7325 - val_loss: 0.5572 - val_accuracy: 0.9549\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0590 - accuracy: 0.7636"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 715ms/step - loss: 1.0590 - accuracy: 0.7636 - val_loss: 0.5582 - val_accuracy: 0.9518\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0873 - accuracy: 0.7589"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 712ms/step - loss: 1.0873 - accuracy: 0.7589 - val_loss: 0.5321 - val_accuracy: 0.9596\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0413 - accuracy: 0.7683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 676ms/step - loss: 1.0413 - accuracy: 0.7683 - val_loss: 0.5052 - val_accuracy: 0.9689\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0568 - accuracy: 0.7481"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.0568 - accuracy: 0.7481 - val_loss: 0.4970 - val_accuracy: 0.9673\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9944 - accuracy: 0.7776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.9944 - accuracy: 0.7776 - val_loss: 0.5150 - val_accuracy: 0.9565\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0228 - accuracy: 0.7589"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.0228 - accuracy: 0.7589 - val_loss: 0.5198 - val_accuracy: 0.9596\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9892 - accuracy: 0.7636"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.9892 - accuracy: 0.7636 - val_loss: 0.4975 - val_accuracy: 0.9565\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0040 - accuracy: 0.7621"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 973ms/step - loss: 1.0040 - accuracy: 0.7621 - val_loss: 0.5131 - val_accuracy: 0.9627\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.7652"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 638ms/step - loss: 0.9802 - accuracy: 0.7652 - val_loss: 0.5906 - val_accuracy: 0.9285\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9777 - accuracy: 0.7698"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 708ms/step - loss: 0.9777 - accuracy: 0.7698 - val_loss: 0.5219 - val_accuracy: 0.9533\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0124 - accuracy: 0.7589"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 720ms/step - loss: 1.0124 - accuracy: 0.7589 - val_loss: 0.4855 - val_accuracy: 0.9673\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9528 - accuracy: 0.7776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 644ms/step - loss: 0.9528 - accuracy: 0.7776 - val_loss: 0.5065 - val_accuracy: 0.9549\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0014 - accuracy: 0.7605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 653ms/step - loss: 1.0014 - accuracy: 0.7605 - val_loss: 0.4697 - val_accuracy: 0.9611\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9349 - accuracy: 0.7760"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 676ms/step - loss: 0.9349 - accuracy: 0.7760 - val_loss: 0.4299 - val_accuracy: 0.9782\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9677 - accuracy: 0.7729"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 667ms/step - loss: 0.9677 - accuracy: 0.7729 - val_loss: 0.4378 - val_accuracy: 0.9658\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9573 - accuracy: 0.7667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 639ms/step - loss: 0.9573 - accuracy: 0.7667 - val_loss: 0.5909 - val_accuracy: 0.9036\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8865 - accuracy: 0.7963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 634ms/step - loss: 0.8865 - accuracy: 0.7963 - val_loss: 0.7403 - val_accuracy: 0.8414\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.7823"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 660ms/step - loss: 0.9524 - accuracy: 0.7823 - val_loss: 0.4023 - val_accuracy: 0.9844\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9072 - accuracy: 0.7807"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 706ms/step - loss: 0.9072 - accuracy: 0.7807 - val_loss: 0.4925 - val_accuracy: 0.9425\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9364 - accuracy: 0.7729"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 702ms/step - loss: 0.9364 - accuracy: 0.7729 - val_loss: 0.3782 - val_accuracy: 0.9907\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8941 - accuracy: 0.8025"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 636ms/step - loss: 0.8941 - accuracy: 0.8025 - val_loss: 0.3768 - val_accuracy: 0.9907\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9271 - accuracy: 0.7916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 713ms/step - loss: 0.9271 - accuracy: 0.7916 - val_loss: 0.3947 - val_accuracy: 0.9844\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9395 - accuracy: 0.7838"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.9395 - accuracy: 0.7838 - val_loss: 0.4454 - val_accuracy: 0.9736\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9053 - accuracy: 0.7932"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.9053 - accuracy: 0.7932 - val_loss: 0.3735 - val_accuracy: 0.9953\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9297 - accuracy: 0.7792"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.9297 - accuracy: 0.7792 - val_loss: 0.4375 - val_accuracy: 0.9611\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9127 - accuracy: 0.7963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.9127 - accuracy: 0.7963 - val_loss: 0.3607 - val_accuracy: 0.9860\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8651 - accuracy: 0.8040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.8651 - accuracy: 0.8040 - val_loss: 0.3745 - val_accuracy: 0.9860\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8439 - accuracy: 0.8165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 709ms/step - loss: 0.8439 - accuracy: 0.8165 - val_loss: 0.3592 - val_accuracy: 0.9891\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8101 - accuracy: 0.8149"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 716ms/step - loss: 0.8101 - accuracy: 0.8149 - val_loss: 0.3440 - val_accuracy: 0.9891\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7812 - accuracy: 0.8336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 700ms/step - loss: 0.7812 - accuracy: 0.8336 - val_loss: 0.3513 - val_accuracy: 0.9876\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8522 - accuracy: 0.8227"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 705ms/step - loss: 0.8522 - accuracy: 0.8227 - val_loss: 0.3664 - val_accuracy: 0.9829\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8250 - accuracy: 0.8243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 668ms/step - loss: 0.8250 - accuracy: 0.8243 - val_loss: 0.3791 - val_accuracy: 0.9782\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8291 - accuracy: 0.8243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 648ms/step - loss: 0.8291 - accuracy: 0.8243 - val_loss: 0.4030 - val_accuracy: 0.9736\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8117 - accuracy: 0.8087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 709ms/step - loss: 0.8117 - accuracy: 0.8087 - val_loss: 0.4329 - val_accuracy: 0.9627\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7830 - accuracy: 0.8227"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 730ms/step - loss: 0.7830 - accuracy: 0.8227 - val_loss: 0.4438 - val_accuracy: 0.9565\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.8414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 710ms/step - loss: 0.7428 - accuracy: 0.8414 - val_loss: 0.3803 - val_accuracy: 0.9782\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7939 - accuracy: 0.8134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 648ms/step - loss: 0.7939 - accuracy: 0.8134 - val_loss: 0.3272 - val_accuracy: 0.9844\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7873 - accuracy: 0.8212"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 740ms/step - loss: 0.7873 - accuracy: 0.8212 - val_loss: 0.3123 - val_accuracy: 0.9891\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7580 - accuracy: 0.8445"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 722ms/step - loss: 0.7580 - accuracy: 0.8445 - val_loss: 0.3069 - val_accuracy: 0.9922\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7489 - accuracy: 0.8398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 660ms/step - loss: 0.7489 - accuracy: 0.8398 - val_loss: 0.2971 - val_accuracy: 0.9938\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.8429"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 709ms/step - loss: 0.7216 - accuracy: 0.8429 - val_loss: 0.2963 - val_accuracy: 0.9922\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7294 - accuracy: 0.8445"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.7294 - accuracy: 0.8445 - val_loss: 0.2976 - val_accuracy: 0.9938\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.8414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 934ms/step - loss: 0.7245 - accuracy: 0.8414 - val_loss: 0.3025 - val_accuracy: 0.9922\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7437 - accuracy: 0.8491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.7437 - accuracy: 0.8491 - val_loss: 0.3162 - val_accuracy: 0.9907\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7068 - accuracy: 0.8507"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.7068 - accuracy: 0.8507 - val_loss: 0.3595 - val_accuracy: 0.9798\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.8445"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 831ms/step - loss: 0.7026 - accuracy: 0.8445 - val_loss: 0.3685 - val_accuracy: 0.9829\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6864 - accuracy: 0.8771"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 662ms/step - loss: 0.6864 - accuracy: 0.8771 - val_loss: 0.3659 - val_accuracy: 0.9782\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7493 - accuracy: 0.8320"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 655ms/step - loss: 0.7493 - accuracy: 0.8320 - val_loss: 0.3407 - val_accuracy: 0.9860\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.8538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 715ms/step - loss: 0.6860 - accuracy: 0.8538 - val_loss: 0.3188 - val_accuracy: 0.9907\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.8538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 655ms/step - loss: 0.6895 - accuracy: 0.8538 - val_loss: 0.2850 - val_accuracy: 0.9953\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.8725"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 655ms/step - loss: 0.6255 - accuracy: 0.8725 - val_loss: 0.2716 - val_accuracy: 0.9969\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.8740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 662ms/step - loss: 0.6296 - accuracy: 0.8740 - val_loss: 0.2692 - val_accuracy: 0.9969\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6393 - accuracy: 0.8787"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 653ms/step - loss: 0.6393 - accuracy: 0.8787 - val_loss: 0.2692 - val_accuracy: 0.9969\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6409 - accuracy: 0.8771"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 644ms/step - loss: 0.6409 - accuracy: 0.8771 - val_loss: 0.2843 - val_accuracy: 0.9938\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6323 - accuracy: 0.8678"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 736ms/step - loss: 0.6323 - accuracy: 0.8678 - val_loss: 0.3023 - val_accuracy: 0.9844\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.8663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 650ms/step - loss: 0.6742 - accuracy: 0.8663 - val_loss: 0.3249 - val_accuracy: 0.9798\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6468 - accuracy: 0.8585"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 719ms/step - loss: 0.6468 - accuracy: 0.8585 - val_loss: 0.3705 - val_accuracy: 0.9565\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.8694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 675ms/step - loss: 0.6177 - accuracy: 0.8694 - val_loss: 0.3707 - val_accuracy: 0.9565\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.8600"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 717ms/step - loss: 0.6299 - accuracy: 0.8600 - val_loss: 0.2983 - val_accuracy: 0.9876\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6005 - accuracy: 0.8880"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 708ms/step - loss: 0.6005 - accuracy: 0.8880 - val_loss: 0.2721 - val_accuracy: 0.9876\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.8585"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.6101 - accuracy: 0.8585 - val_loss: 0.2581 - val_accuracy: 0.9953\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.8849"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.5918 - accuracy: 0.8849 - val_loss: 0.2511 - val_accuracy: 0.9953\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.8834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.6059 - accuracy: 0.8834 - val_loss: 0.2468 - val_accuracy: 0.9969\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.8896"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.5907 - accuracy: 0.8896 - val_loss: 0.2462 - val_accuracy: 0.9969\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5834 - accuracy: 0.8880"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 693ms/step - loss: 0.5834 - accuracy: 0.8880 - val_loss: 0.2602 - val_accuracy: 0.9953\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5416 - accuracy: 0.9051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 723ms/step - loss: 0.5416 - accuracy: 0.9051 - val_loss: 0.3342 - val_accuracy: 0.9736\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.8896"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 728ms/step - loss: 0.5929 - accuracy: 0.8896 - val_loss: 0.2870 - val_accuracy: 0.9860\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5977 - accuracy: 0.8834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 649ms/step - loss: 0.5977 - accuracy: 0.8834 - val_loss: 0.2419 - val_accuracy: 0.9969\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.8958"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 711ms/step - loss: 0.5569 - accuracy: 0.8958 - val_loss: 0.2372 - val_accuracy: 0.9969\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.8896"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 666ms/step - loss: 0.5873 - accuracy: 0.8896 - val_loss: 0.2407 - val_accuracy: 0.9984\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5963 - accuracy: 0.8725"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 664ms/step - loss: 0.5963 - accuracy: 0.8725 - val_loss: 0.2739 - val_accuracy: 0.9907\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.9051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 662ms/step - loss: 0.5726 - accuracy: 0.9051 - val_loss: 0.2510 - val_accuracy: 0.9938\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.8725"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 721ms/step - loss: 0.6112 - accuracy: 0.8725 - val_loss: 0.2252 - val_accuracy: 0.9969\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.8880"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 658ms/step - loss: 0.5654 - accuracy: 0.8880 - val_loss: 0.2270 - val_accuracy: 0.9969\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.8740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 650ms/step - loss: 0.6095 - accuracy: 0.8740 - val_loss: 0.2224 - val_accuracy: 0.9984\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5310 - accuracy: 0.8974"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 729ms/step - loss: 0.5310 - accuracy: 0.8974 - val_loss: 0.2225 - val_accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.9020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 652ms/step - loss: 0.5393 - accuracy: 0.9020 - val_loss: 0.2465 - val_accuracy: 0.9953\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.8927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 657ms/step - loss: 0.5697 - accuracy: 0.8927 - val_loss: 0.2399 - val_accuracy: 0.9953\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.8958"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.5393 - accuracy: 0.8958 - val_loss: 0.2263 - val_accuracy: 0.9984\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8958"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.5414 - accuracy: 0.8958 - val_loss: 0.2249 - val_accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.8880"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.5459 - accuracy: 0.8880 - val_loss: 0.2348 - val_accuracy: 0.9969\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.9051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.4963 - accuracy: 0.9051 - val_loss: 0.2648 - val_accuracy: 0.9922\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.9051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 942ms/step - loss: 0.5166 - accuracy: 0.9051 - val_loss: 0.2319 - val_accuracy: 0.9984\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.9020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 680ms/step - loss: 0.5215 - accuracy: 0.9020 - val_loss: 0.2127 - val_accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.9238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 704ms/step - loss: 0.4684 - accuracy: 0.9238 - val_loss: 0.2120 - val_accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.9036"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 657ms/step - loss: 0.5150 - accuracy: 0.9036 - val_loss: 0.2085 - val_accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.8927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 710ms/step - loss: 0.4964 - accuracy: 0.8927 - val_loss: 0.2200 - val_accuracy: 0.9969\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.9067"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 708ms/step - loss: 0.4844 - accuracy: 0.9067 - val_loss: 0.2192 - val_accuracy: 0.9969\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.9191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 657ms/step - loss: 0.4799 - accuracy: 0.9191 - val_loss: 0.2097 - val_accuracy: 0.9984\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.8834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 665ms/step - loss: 0.5262 - accuracy: 0.8834 - val_loss: 0.2035 - val_accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.9145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 713ms/step - loss: 0.4800 - accuracy: 0.9145 - val_loss: 0.2023 - val_accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.9082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 664ms/step - loss: 0.4773 - accuracy: 0.9082 - val_loss: 0.2072 - val_accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.9098"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 671ms/step - loss: 0.4828 - accuracy: 0.9098 - val_loss: 0.2201 - val_accuracy: 0.9953\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.9160"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 710ms/step - loss: 0.4735 - accuracy: 0.9160 - val_loss: 0.2297 - val_accuracy: 0.9938\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.9145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 714ms/step - loss: 0.4620 - accuracy: 0.9145 - val_loss: 0.1996 - val_accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.9067"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 761ms/step - loss: 0.4829 - accuracy: 0.9067 - val_loss: 0.1971 - val_accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 717ms/step - loss: 0.4843 - accuracy: 0.9005 - val_loss: 0.1984 - val_accuracy: 0.9984\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.9207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.4515 - accuracy: 0.9207 - val_loss: 0.1994 - val_accuracy: 0.9984\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.9362"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 925ms/step - loss: 0.4129 - accuracy: 0.9362 - val_loss: 0.1991 - val_accuracy: 0.9984\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.9253"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.4313 - accuracy: 0.9253 - val_loss: 0.1956 - val_accuracy: 0.9984\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.9285"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.4355 - accuracy: 0.9285 - val_loss: 0.1921 - val_accuracy: 0.9984\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.9191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 993ms/step - loss: 0.4527 - accuracy: 0.9191 - val_loss: 0.1894 - val_accuracy: 0.9984\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.9393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 722ms/step - loss: 0.3882 - accuracy: 0.9393 - val_loss: 0.1874 - val_accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.8989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 730ms/step - loss: 0.4847 - accuracy: 0.8989 - val_loss: 0.1858 - val_accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.9129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 656ms/step - loss: 0.4576 - accuracy: 0.9129 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.9082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 698ms/step - loss: 0.4623 - accuracy: 0.9082 - val_loss: 0.1875 - val_accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.9129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 697ms/step - loss: 0.4641 - accuracy: 0.9129 - val_loss: 0.2203 - val_accuracy: 0.9953\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.9051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 718ms/step - loss: 0.4469 - accuracy: 0.9051 - val_loss: 0.2389 - val_accuracy: 0.9876\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4704 - accuracy: 0.9082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 628ms/step - loss: 0.4704 - accuracy: 0.9082 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.9238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 696ms/step - loss: 0.4385 - accuracy: 0.9238 - val_loss: 0.1772 - val_accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.9440"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.4208 - accuracy: 0.9440 - val_loss: 0.1756 - val_accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.9253"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 2s 2s/step - loss: 0.4145 - accuracy: 0.9253 - val_loss: 0.1749 - val_accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.9129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.4499 - accuracy: 0.9129 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.9502"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.3765 - accuracy: 0.9502 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 2s 2s/step - loss: 0.4348 - accuracy: 0.9222 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.9316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.3959 - accuracy: 0.9316 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.9207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 683ms/step - loss: 0.4225 - accuracy: 0.9207 - val_loss: 0.1774 - val_accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.9129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 701ms/step - loss: 0.4421 - accuracy: 0.9129 - val_loss: 0.2006 - val_accuracy: 0.9953\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4014 - accuracy: 0.9269"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 641ms/step - loss: 0.4014 - accuracy: 0.9269 - val_loss: 0.1973 - val_accuracy: 0.9953\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.9409"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 627ms/step - loss: 0.3760 - accuracy: 0.9409 - val_loss: 0.1873 - val_accuracy: 0.9984\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3925 - accuracy: 0.9238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 649ms/step - loss: 0.3925 - accuracy: 0.9238 - val_loss: 0.1783 - val_accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.9393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 713ms/step - loss: 0.3785 - accuracy: 0.9393 - val_loss: 0.1742 - val_accuracy: 0.9984\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.9331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 720ms/step - loss: 0.3700 - accuracy: 0.9331 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3975 - accuracy: 0.9238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 646ms/step - loss: 0.3975 - accuracy: 0.9238 - val_loss: 0.1673 - val_accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.9316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 712ms/step - loss: 0.4081 - accuracy: 0.9316 - val_loss: 0.1641 - val_accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.9502"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 649ms/step - loss: 0.3442 - accuracy: 0.9502 - val_loss: 0.1635 - val_accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.9285"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 656ms/step - loss: 0.3931 - accuracy: 0.9285 - val_loss: 0.1620 - val_accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.9316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 711ms/step - loss: 0.4032 - accuracy: 0.9316 - val_loss: 0.1653 - val_accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.9300"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 726ms/step - loss: 0.3669 - accuracy: 0.9300 - val_loss: 0.1689 - val_accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.9238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 661ms/step - loss: 0.4057 - accuracy: 0.9238 - val_loss: 0.1634 - val_accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.9393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 711ms/step - loss: 0.3739 - accuracy: 0.9393 - val_loss: 0.1760 - val_accuracy: 0.9969\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.9331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.3917 - accuracy: 0.9331 - val_loss: 0.1686 - val_accuracy: 0.9969\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.9502"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 928ms/step - loss: 0.3481 - accuracy: 0.9502 - val_loss: 0.1596 - val_accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.9409"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.3599 - accuracy: 0.9409 - val_loss: 0.1579 - val_accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.9565"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.3466 - accuracy: 0.9565 - val_loss: 0.1578 - val_accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.9331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 923ms/step - loss: 0.3605 - accuracy: 0.9331 - val_loss: 0.1564 - val_accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.9487"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 714ms/step - loss: 0.3283 - accuracy: 0.9487 - val_loss: 0.1604 - val_accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.9471"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 730ms/step - loss: 0.3351 - accuracy: 0.9471 - val_loss: 0.1622 - val_accuracy: 0.9984\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3647 - accuracy: 0.9316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 650ms/step - loss: 0.3647 - accuracy: 0.9316 - val_loss: 0.1623 - val_accuracy: 0.9984\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.9471"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 698ms/step - loss: 0.3673 - accuracy: 0.9471 - val_loss: 0.1550 - val_accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.9440"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 638ms/step - loss: 0.3469 - accuracy: 0.9440 - val_loss: 0.1535 - val_accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.9409"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 732ms/step - loss: 0.3609 - accuracy: 0.9409 - val_loss: 0.1519 - val_accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.9549"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 708ms/step - loss: 0.3170 - accuracy: 0.9549 - val_loss: 0.1501 - val_accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9471"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 696ms/step - loss: 0.3182 - accuracy: 0.9471 - val_loss: 0.1497 - val_accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.9191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 656ms/step - loss: 0.3777 - accuracy: 0.9191 - val_loss: 0.1501 - val_accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.9456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 638ms/step - loss: 0.3388 - accuracy: 0.9456 - val_loss: 0.1513 - val_accuracy: 0.9984\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.9565"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 655ms/step - loss: 0.3225 - accuracy: 0.9565 - val_loss: 0.1539 - val_accuracy: 0.9984\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.9393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 650ms/step - loss: 0.3256 - accuracy: 0.9393 - val_loss: 0.1538 - val_accuracy: 0.9984\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.9518"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 707ms/step - loss: 0.3221 - accuracy: 0.9518 - val_loss: 0.1522 - val_accuracy: 0.9984\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.9440"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 713ms/step - loss: 0.3196 - accuracy: 0.9440 - val_loss: 0.1494 - val_accuracy: 0.9984\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3323 - accuracy: 0.9471"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.3323 - accuracy: 0.9471 - val_loss: 0.1483 - val_accuracy: 0.9984\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.9549"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.3067 - accuracy: 0.9549 - val_loss: 0.1467 - val_accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.9393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.3262 - accuracy: 0.9393 - val_loss: 0.1450 - val_accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.9456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 976ms/step - loss: 0.3136 - accuracy: 0.9456 - val_loss: 0.1438 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy-RNN')\n",
        "plt.legend()\n",
        " \n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss-RNN')\n",
        "plt.legend()\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "OOn7Q1Cn_0Fi",
        "outputId": "566332e6-86bb-42e3-a6bf-838df1e2cb81"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=['It was not a good day in my life']\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_test  = np.array( tokenizer.texts_to_sequences(test_data))\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)\n",
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RErR6_afHKYB",
        "outputId": "7dca5480-a4a8-4333-83a2-087610060624"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 71, 32,\n",
              "        22]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(test_data)):\n",
        "  print('Test sentence:-',test_data[i])\n",
        "  \n",
        "  res=modelRNN.predict(x_test)\n",
        "  labels = ['almosthomeless', 'anxiety', 'assistance', 'domesticviolence',\n",
        "       'food_pantry', 'homeless', 'ptsd', 'relationships', 'stress',\n",
        "       'survivorsofabuse']\n",
        "  print(res, labels[np.argmax(res)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pthvffauHadM",
        "outputId": "51bbb3a0-a5b8-42b1-e2f8-56795ad9dfa3"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sentence:- It was not a good day in my life\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "[[0.14460966 0.00074211 0.380133   0.05613133 0.09147227 0.17303567\n",
            "  0.14247204 0.00686077 0.00193125 0.0026119 ]] assistance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=['I need a new home , my current home is almost broke']\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_test  = np.array( tokenizer.texts_to_sequences(test_data))\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)\n",
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH8O2GF4HlrU",
        "outputId": "752e9528-7c7c-4f93-99bf-a9cac0cac97f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  34,  74,  57, 488,  57, 138, 216]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(test_data)):\n",
        "  print('Test sentence:-',test_data[i])\n",
        "  \n",
        "  res=modelRNN.predict(x_test)\n",
        "  labels = ['almosthomeless', 'anxiety', 'assistance', 'domesticviolence',\n",
        "       'food_pantry', 'homeless', 'ptsd', 'relationships', 'stress',\n",
        "       'survivorsofabuse']\n",
        "  print(res, labels[np.argmax(res)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfx6qHXLMw6K",
        "outputId": "df81bb47-d5ca-4ad4-ff1e-63e8a47a8b3f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sentence:- I need a new home , my current home is almost broke\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "[[0.0428846  0.03577623 0.13820887 0.00393586 0.09271288 0.45102915\n",
            "  0.1224326  0.06991497 0.01902289 0.02408196]] homeless\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integrating with Langchain to suggest some remedies**"
      ],
      "metadata": {
        "id": "CZBPpgj_tY5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install langchain unstructured sentence_transformers faiss-cpu huggingface_hub OpenAI\n",
        "# !pip install langchain"
      ],
      "metadata": {
        "id": "-HgI0lkule0W"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(data):\n",
        "  test_data = [data]\n",
        "  from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "  x_test  = np.array( tokenizer.texts_to_sequences(test_data))\n",
        "  x_test = pad_sequences(x_test, maxlen=max_length)\n",
        "  for i in range(0,len(test_data)):\n",
        "    print('Test sentence:-',test_data[i])\n",
        "    \n",
        "    res=modelRNN.predict(x_test)\n",
        "    labels = ['almosthomeless', 'anxiety', 'assistance', 'domesticviolence',\n",
        "        'food_pantry', 'homeless', 'ptsd', 'relationships', 'stress',\n",
        "        'survivorsofabuse']\n",
        "    return labels[np.argmax(res)]\n",
        "data=input()\n",
        "ans = print(predict(data)) "
      ],
      "metadata": {
        "id": "bxQSbLrX0Woc",
        "outputId": "320fbd46-9857-401d-e688-01c7c941766f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I need a new home , my current home is almost broke\n",
            "Test sentence:- I need a new home , my current home is almost broke\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "homeless\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "template = \"\"\"You are a mental health stress analyzer who will be provided with a {stress}.\n",
        "Your task is to analyze the stress and provide a soothing answer that will help the user improve their current condition.\n",
        "The types of stress you will be receiving are 'almosthomeless', 'anxiety', 'assistance', 'domesticviolence', 'food_pantry', 'homeless', 'ptsd', 'relationships', 'stress', 'survivorsofabuse'\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"stress\"])\n",
        "llm = OpenAI()\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "data=input()\n",
        "stress = predict(data)\n",
        "\n",
        "llm_chain.run(stress)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "MRYaG8uktNfS",
        "outputId": "b728cdfd-7b72-4ac3-df48-24fe8567b75a"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My parents beat me evryday as im not so good at studies , i want to run away from them\n",
            "Test sentence:- My parents beat me evryday as im not so good at studies , i want to run away from them\n",
            "1/1 [==============================] - 0s 231ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" and 'trauma'.\\n\\nFor 'domesticviolence', the first step is to acknowledge the stress and trauma that the user is experiencing. It is important to let the user know that they are not alone in this difficult experience and that there are resources available to help them. It is also important to provide them with a safe space to talk about their experiences and provide them with support. You can also refer them to counseling services to help them cope with their trauma. In addition, it is important to provide them with resources to help them find safe and secure housing, legal aid, and other forms of assistance. Finally, it is important to remind them that they are not to blame for the abuse and that they can take steps to protect themselves in the future.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The End**"
      ],
      "metadata": {
        "id": "tWrqaKiLQA8F"
      }
    }
  ]
}