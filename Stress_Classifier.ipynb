{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7nZ0RUZnyLnZPX5Q1GAJN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anish2105/Stress-Classifer/blob/main/Stress_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Class Stress Detector Using RNN**"
      ],
      "metadata": {
        "id": "kVkbvyMfQHZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "from keras.layers import Dropout\n",
        "from nltk.tokenize import TweetTokenizer\n"
      ],
      "metadata": {
        "id": "HAZgX3YKQT4b"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/dreaddit_StressAnalysis - Sheet1.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "UElAwbXIWswS",
        "outputId": "b45bfca3-2c96-4b18-b177-64ccf880e408"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id      subreddit post_id sentence_range  \\\n",
              "0    896  relationships  7nu7as       [50, 55]   \n",
              "1  19059        anxiety  680i6d        (5, 10)   \n",
              "2   7977           ptsd  8eeu1t        (5, 10)   \n",
              "3   1214           ptsd  8d28vu         [2, 7]   \n",
              "4   1965  relationships  7r1e85       [23, 28]   \n",
              "\n",
              "                                                text  label  confidence  \\\n",
              "0  Its like that, if you want or not.“ ME: I have...      0         0.8   \n",
              "1  I man the front desk and my title is HR Custom...      0         1.0   \n",
              "2  We'd be saving so much money with this new hou...      1         1.0   \n",
              "3  My ex used to shoot back with \"Do you want me ...      1         0.5   \n",
              "4  I haven’t said anything to him yet because I’m...      0         0.8   \n",
              "\n",
              "   social_timestamp  social_karma  syntax_ari  ...  lex_dal_min_pleasantness  \\\n",
              "0        1514980773            22   -1.238793  ...                    1.0000   \n",
              "1        1493348050             5    7.684583  ...                    1.4000   \n",
              "2        1524516630            10    2.360408  ...                    1.1429   \n",
              "3        1524018289             5    5.997000  ...                    1.0000   \n",
              "4        1516200171           138    4.649418  ...                    1.1250   \n",
              "\n",
              "   lex_dal_min_activation  lex_dal_min_imagery  lex_dal_avg_activation  \\\n",
              "0                  1.2000                  1.0                 1.65864   \n",
              "1                  1.1250                  1.0                 1.69133   \n",
              "2                  1.0000                  1.0                 1.70974   \n",
              "3                  1.3000                  1.0                 1.72615   \n",
              "4                  1.1429                  1.0                 1.75642   \n",
              "\n",
              "   lex_dal_avg_imagery  lex_dal_avg_pleasantness  social_upvote_ratio  \\\n",
              "0              1.32245                   1.80264                 0.63   \n",
              "1              1.69180                   1.97249                 1.00   \n",
              "2              1.52985                   1.86108                 1.00   \n",
              "3              1.52000                   1.84909                 1.00   \n",
              "4              1.43582                   1.91725                 0.84   \n",
              "\n",
              "   social_num_comments  syntax_fk_grade  sentiment  \n",
              "0                   62        -0.148707   0.000000  \n",
              "1                    2         7.398222  -0.065909  \n",
              "2                    8         3.149288  -0.036818  \n",
              "3                    7         6.606000  -0.066667  \n",
              "4                   70         4.801869   0.141667  \n",
              "\n",
              "[5 rows x 116 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07d6952e-ed0e-4dd7-b348-a8817a111ad4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>post_id</th>\n",
              "      <th>sentence_range</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>confidence</th>\n",
              "      <th>social_timestamp</th>\n",
              "      <th>social_karma</th>\n",
              "      <th>syntax_ari</th>\n",
              "      <th>...</th>\n",
              "      <th>lex_dal_min_pleasantness</th>\n",
              "      <th>lex_dal_min_activation</th>\n",
              "      <th>lex_dal_min_imagery</th>\n",
              "      <th>lex_dal_avg_activation</th>\n",
              "      <th>lex_dal_avg_imagery</th>\n",
              "      <th>lex_dal_avg_pleasantness</th>\n",
              "      <th>social_upvote_ratio</th>\n",
              "      <th>social_num_comments</th>\n",
              "      <th>syntax_fk_grade</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>896</td>\n",
              "      <td>relationships</td>\n",
              "      <td>7nu7as</td>\n",
              "      <td>[50, 55]</td>\n",
              "      <td>Its like that, if you want or not.“ ME: I have...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1514980773</td>\n",
              "      <td>22</td>\n",
              "      <td>-1.238793</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.2000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.65864</td>\n",
              "      <td>1.32245</td>\n",
              "      <td>1.80264</td>\n",
              "      <td>0.63</td>\n",
              "      <td>62</td>\n",
              "      <td>-0.148707</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19059</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>680i6d</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>I man the front desk and my title is HR Custom...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1493348050</td>\n",
              "      <td>5</td>\n",
              "      <td>7.684583</td>\n",
              "      <td>...</td>\n",
              "      <td>1.4000</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.69133</td>\n",
              "      <td>1.69180</td>\n",
              "      <td>1.97249</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "      <td>7.398222</td>\n",
              "      <td>-0.065909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7977</td>\n",
              "      <td>ptsd</td>\n",
              "      <td>8eeu1t</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>We'd be saving so much money with this new hou...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1524516630</td>\n",
              "      <td>10</td>\n",
              "      <td>2.360408</td>\n",
              "      <td>...</td>\n",
              "      <td>1.1429</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.70974</td>\n",
              "      <td>1.52985</td>\n",
              "      <td>1.86108</td>\n",
              "      <td>1.00</td>\n",
              "      <td>8</td>\n",
              "      <td>3.149288</td>\n",
              "      <td>-0.036818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1214</td>\n",
              "      <td>ptsd</td>\n",
              "      <td>8d28vu</td>\n",
              "      <td>[2, 7]</td>\n",
              "      <td>My ex used to shoot back with \"Do you want me ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1524018289</td>\n",
              "      <td>5</td>\n",
              "      <td>5.997000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.3000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.72615</td>\n",
              "      <td>1.52000</td>\n",
              "      <td>1.84909</td>\n",
              "      <td>1.00</td>\n",
              "      <td>7</td>\n",
              "      <td>6.606000</td>\n",
              "      <td>-0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1965</td>\n",
              "      <td>relationships</td>\n",
              "      <td>7r1e85</td>\n",
              "      <td>[23, 28]</td>\n",
              "      <td>I haven’t said anything to him yet because I’m...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1516200171</td>\n",
              "      <td>138</td>\n",
              "      <td>4.649418</td>\n",
              "      <td>...</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>1.1429</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.75642</td>\n",
              "      <td>1.43582</td>\n",
              "      <td>1.91725</td>\n",
              "      <td>0.84</td>\n",
              "      <td>70</td>\n",
              "      <td>4.801869</td>\n",
              "      <td>0.141667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 116 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07d6952e-ed0e-4dd7-b348-a8817a111ad4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07d6952e-ed0e-4dd7-b348-a8817a111ad4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07d6952e-ed0e-4dd7-b348-a8817a111ad4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['subreddit' , 'text']]"
      ],
      "metadata": {
        "id": "dgU2xma_XGpi"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4rpjESesXW4d",
        "outputId": "1a76f3eb-0c21-42ab-d8bf-e710dc0e5b1f"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       subreddit                                               text\n",
              "0  relationships  Its like that, if you want or not.“ ME: I have...\n",
              "1        anxiety  I man the front desk and my title is HR Custom...\n",
              "2           ptsd  We'd be saving so much money with this new hou...\n",
              "3           ptsd  My ex used to shoot back with \"Do you want me ...\n",
              "4  relationships  I haven’t said anything to him yet because I’m..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c673526b-2744-4ab7-bfac-1dcbe914c891\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relationships</td>\n",
              "      <td>Its like that, if you want or not.“ ME: I have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>I man the front desk and my title is HR Custom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>We'd be saving so much money with this new hou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>My ex used to shoot back with \"Do you want me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relationships</td>\n",
              "      <td>I haven’t said anything to him yet because I’m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c673526b-2744-4ab7-bfac-1dcbe914c891')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c673526b-2744-4ab7-bfac-1dcbe914c891 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c673526b-2744-4ab7-bfac-1dcbe914c891');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = len(data['subreddit'].unique())\n",
        "unique_values "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1tLSyDvX2PA",
        "outputId": "86eb6d1e-05c7-4c1d-b450-954bfcf44c23"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].astype('str')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MLW_D4ZYnqP",
        "outputId": "4d725e77-2e08-4dcd-ad85-26d3c651f072"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-130-2b34dc1dca25>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].astype('str')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrpqZu40Y0dn",
        "outputId": "1241af81-3d2c-46ae-a764-72ce03f8ac75"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subreddit    0\n",
              "text         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].str.lower()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "_-d-AGdrY-3X",
        "outputId": "2a79a213-754e-46ea-93b7-52a8484818f3"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-132-c88097a19625>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].str.lower()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       subreddit                                               text\n",
              "0  relationships  its like that, if you want or not.“ me: i have...\n",
              "1        anxiety  i man the front desk and my title is hr custom...\n",
              "2           ptsd  we'd be saving so much money with this new hou...\n",
              "3           ptsd  my ex used to shoot back with \"do you want me ...\n",
              "4  relationships  i haven’t said anything to him yet because i’m..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70015c25-64b0-4c1e-b387-9287a1511699\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relationships</td>\n",
              "      <td>its like that, if you want or not.“ me: i have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>i man the front desk and my title is hr custom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>we'd be saving so much money with this new hou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>my ex used to shoot back with \"do you want me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relationships</td>\n",
              "      <td>i haven’t said anything to him yet because i’m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70015c25-64b0-4c1e-b387-9287a1511699')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70015c25-64b0-4c1e-b387-9287a1511699 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70015c25-64b0-4c1e-b387-9287a1511699');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'][35]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "jzNZRAZzZJfP",
        "outputId": "d2eaa09e-7cfa-4324-ae6d-5eb44d2ec061"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we are down to less than $100 for another week and 4 days. her weight watchers is due, and she is sad we may have to cancel. i am already doing what i can, and anything seemingly extra goes towards our 3 kids which we love dearly. i started a gofundme. i am looking for $100 so i can give her money towards weight watchers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removal of @ and User names**"
      ],
      "metadata": {
        "id": "BZZzbFJdaKLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tknzr = TweetTokenizer(strip_handles=True)\n",
        "\n",
        "for a in range(len(data['text'])):\n",
        "\n",
        "  result = tknzr.tokenize(data['text'][a])\n",
        "  res=\" \".join(result)\n",
        "  data['text'][a]=res\n",
        "print(\"\\nTokenize a twitter text:\")\n",
        "print(data['text'][10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O3QjFzCZzVm",
        "outputId": "83b11d7d-65b2-4e74-956f-4bed21bd3a20"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-134-ae51779103b3>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'][a]=res\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenize a twitter text:\n",
            "i've always hated nail files . somehow that's a part of this . god . i'm confused by it all . it's a feeling to recall it that i've carried my whole life but never understood like a cloud .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Punctuations**"
      ],
      "metadata": {
        "id": "Cbp37hEOaZ74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "punct_to_remove = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "  return text.translate(str.maketrans('','',punct_to_remove))\n",
        "\n",
        "data['text'] = data['text'].apply(lambda text:remove_punctuation(text))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "RM90dzU1aSX8",
        "outputId": "30f8e5ab-c613-4749-9caf-cf7be81ce2c3"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-135-c2d87b989dc8>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda text:remove_punctuation(text))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       subreddit                                               text\n",
              "0  relationships  its like that  if you want or not  “ me  i hav...\n",
              "1        anxiety  i man the front desk and my title is hr custom...\n",
              "2           ptsd  wed be saving so much money with this new hous...\n",
              "3           ptsd  my ex used to shoot back with  do you want me ...\n",
              "4  relationships  i haven ’ t said anything to him yet because i..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65d26165-1b6d-42a9-ae48-705d1117c74d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relationships</td>\n",
              "      <td>its like that  if you want or not  “ me  i hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>i man the front desk and my title is hr custom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>wed be saving so much money with this new hous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>my ex used to shoot back with  do you want me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relationships</td>\n",
              "      <td>i haven ’ t said anything to him yet because i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65d26165-1b6d-42a9-ae48-705d1117c74d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65d26165-1b6d-42a9-ae48-705d1117c74d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65d26165-1b6d-42a9-ae48-705d1117c74d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_special(text):\n",
        "    rem = ''\n",
        "    for i in text:\n",
        "        if i.isalnum():\n",
        "            rem = rem + i\n",
        "        else:\n",
        "            rem = rem + ' '\n",
        "    return rem\n",
        "data.text = data.text.apply(is_special)\n",
        "data.text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "JWshSQp86qON",
        "outputId": "9aebc1d9-95b4-4781-d7a2-754222a956e9"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-136-f71d68ad4a15>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.text = data.text.apply(is_special)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'its like that  if you want or not    me  i have no problem  if it takes longer  but you asked my friend for help and let him wait for one hour and then you haven   t prepared anything  thats not what you asked for  instead of 3 hours  he helped you for 10 hours till 5am '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Labeling the target fields**"
      ],
      "metadata": {
        "id": "N8C9MsP1cFiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df = pd.get_dummies(data = data , columns = ['subreddit'])\n",
        "encoded_df"
      ],
      "metadata": {
        "id": "GLQrJqx3f4JU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4de5433-a86e-4a82-f529-a5860c358b97"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  \\\n",
              "0    its like that  if you want or not    me  i hav...   \n",
              "1    i man the front desk and my title is hr custom...   \n",
              "2    wed be saving so much money with this new hous...   \n",
              "3    my ex used to shoot back with  do you want me ...   \n",
              "4    i haven   t said anything to him yet because i...   \n",
              "..                                                 ...   \n",
              "710  i have horrible vivid nightmares every night  ...   \n",
              "711  also i cant think about both of them without g...   \n",
              "712  furthermore  i told him before we got really s...   \n",
              "713  heres the link to my amazon wish list where th...   \n",
              "714  how can i keep us protected  they have already...   \n",
              "\n",
              "     subreddit_almosthomeless  subreddit_anxiety  subreddit_assistance  \\\n",
              "0                           0                  0                     0   \n",
              "1                           0                  1                     0   \n",
              "2                           0                  0                     0   \n",
              "3                           0                  0                     0   \n",
              "4                           0                  0                     0   \n",
              "..                        ...                ...                   ...   \n",
              "710                         0                  0                     0   \n",
              "711                         0                  0                     0   \n",
              "712                         0                  0                     0   \n",
              "713                         0                  0                     1   \n",
              "714                         0                  0                     1   \n",
              "\n",
              "     subreddit_domesticviolence  subreddit_food_pantry  subreddit_homeless  \\\n",
              "0                             0                      0                   0   \n",
              "1                             0                      0                   0   \n",
              "2                             0                      0                   0   \n",
              "3                             0                      0                   0   \n",
              "4                             0                      0                   0   \n",
              "..                          ...                    ...                 ...   \n",
              "710                           0                      0                   0   \n",
              "711                           0                      0                   0   \n",
              "712                           0                      0                   0   \n",
              "713                           0                      0                   0   \n",
              "714                           0                      0                   0   \n",
              "\n",
              "     subreddit_ptsd  subreddit_relationships  subreddit_stress  \\\n",
              "0                 0                        1                 0   \n",
              "1                 0                        0                 0   \n",
              "2                 1                        0                 0   \n",
              "3                 1                        0                 0   \n",
              "4                 0                        1                 0   \n",
              "..              ...                      ...               ...   \n",
              "710               1                        0                 0   \n",
              "711               0                        1                 0   \n",
              "712               0                        1                 0   \n",
              "713               0                        0                 0   \n",
              "714               0                        0                 0   \n",
              "\n",
              "     subreddit_survivorsofabuse  \n",
              "0                             0  \n",
              "1                             0  \n",
              "2                             0  \n",
              "3                             0  \n",
              "4                             0  \n",
              "..                          ...  \n",
              "710                           0  \n",
              "711                           0  \n",
              "712                           0  \n",
              "713                           0  \n",
              "714                           0  \n",
              "\n",
              "[715 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d477cc46-aa71-4345-8718-e19ddc1db9b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>subreddit_almosthomeless</th>\n",
              "      <th>subreddit_anxiety</th>\n",
              "      <th>subreddit_assistance</th>\n",
              "      <th>subreddit_domesticviolence</th>\n",
              "      <th>subreddit_food_pantry</th>\n",
              "      <th>subreddit_homeless</th>\n",
              "      <th>subreddit_ptsd</th>\n",
              "      <th>subreddit_relationships</th>\n",
              "      <th>subreddit_stress</th>\n",
              "      <th>subreddit_survivorsofabuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>its like that  if you want or not    me  i hav...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i man the front desk and my title is hr custom...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wed be saving so much money with this new hous...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my ex used to shoot back with  do you want me ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i haven   t said anything to him yet because i...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>i have horrible vivid nightmares every night  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>also i cant think about both of them without g...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>furthermore  i told him before we got really s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>heres the link to my amazon wish list where th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>how can i keep us protected  they have already...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d477cc46-aa71-4345-8718-e19ddc1db9b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d477cc46-aa71-4345-8718-e19ddc1db9b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d477cc46-aa71-4345-8718-e19ddc1db9b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Renaming column names into a shortforms**"
      ],
      "metadata": {
        "id": "LbYNhHso3H1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_names = ['text','almosthomeless', 'anxiety', 'assistance', 'domesticviolence',\n",
        "       'food_pantry', 'homeless', 'ptsd', 'relationships', 'stress',\n",
        "       'survivorsofabuse']\n",
        "encoded_df.columns = new_column_names"
      ],
      "metadata": {
        "id": "LsbIqOH51b6X"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1jzm0ZSa1vxA",
        "outputId": "5b6f5778-6a3d-449a-aace-f6af776ae7f1"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  almosthomeless  \\\n",
              "0    its like that  if you want or not    me  i hav...               0   \n",
              "1    i man the front desk and my title is hr custom...               0   \n",
              "2    wed be saving so much money with this new hous...               0   \n",
              "3    my ex used to shoot back with  do you want me ...               0   \n",
              "4    i haven   t said anything to him yet because i...               0   \n",
              "..                                                 ...             ...   \n",
              "710  i have horrible vivid nightmares every night  ...               0   \n",
              "711  also i cant think about both of them without g...               0   \n",
              "712  furthermore  i told him before we got really s...               0   \n",
              "713  heres the link to my amazon wish list where th...               0   \n",
              "714  how can i keep us protected  they have already...               0   \n",
              "\n",
              "     anxiety  assistance  domesticviolence  food_pantry  homeless  ptsd  \\\n",
              "0          0           0                 0            0         0     0   \n",
              "1          1           0                 0            0         0     0   \n",
              "2          0           0                 0            0         0     1   \n",
              "3          0           0                 0            0         0     1   \n",
              "4          0           0                 0            0         0     0   \n",
              "..       ...         ...               ...          ...       ...   ...   \n",
              "710        0           0                 0            0         0     1   \n",
              "711        0           0                 0            0         0     0   \n",
              "712        0           0                 0            0         0     0   \n",
              "713        0           1                 0            0         0     0   \n",
              "714        0           1                 0            0         0     0   \n",
              "\n",
              "     relationships  stress  survivorsofabuse  \n",
              "0                1       0                 0  \n",
              "1                0       0                 0  \n",
              "2                0       0                 0  \n",
              "3                0       0                 0  \n",
              "4                1       0                 0  \n",
              "..             ...     ...               ...  \n",
              "710              0       0                 0  \n",
              "711              1       0                 0  \n",
              "712              1       0                 0  \n",
              "713              0       0                 0  \n",
              "714              0       0                 0  \n",
              "\n",
              "[715 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b67d9c70-f649-41e8-a544-42fcb5e51bbd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>almosthomeless</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>assistance</th>\n",
              "      <th>domesticviolence</th>\n",
              "      <th>food_pantry</th>\n",
              "      <th>homeless</th>\n",
              "      <th>ptsd</th>\n",
              "      <th>relationships</th>\n",
              "      <th>stress</th>\n",
              "      <th>survivorsofabuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>its like that  if you want or not    me  i hav...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i man the front desk and my title is hr custom...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wed be saving so much money with this new hous...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my ex used to shoot back with  do you want me ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i haven   t said anything to him yet because i...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>i have horrible vivid nightmares every night  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>also i cant think about both of them without g...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>furthermore  i told him before we got really s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>heres the link to my amazon wish list where th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>how can i keep us protected  they have already...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b67d9c70-f649-41e8-a544-42fcb5e51bbd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b67d9c70-f649-41e8-a544-42fcb5e51bbd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b67d9c70-f649-41e8-a544-42fcb5e51bbd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing libaries**"
      ],
      "metadata": {
        "id": "a-3CKEUe3Vy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# np.random.seed(1)\n",
        "# tf.set_random_seed(2)\n",
        "\n",
        "import pandas as pd\n",
        "import keras\n",
        "# from tqdm import tqdm\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import f1_score, classification_report, log_loss\n",
        "\n",
        "# !pip install keras_preprocessing\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# from keras_preprocessing.sequence import pad_sequences\n",
        "# from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional, Flatten\n",
        "from keras.layers import Dropout, Conv1D, GlobalMaxPool1D, GRU, GlobalAvgPool1D\n",
        "# from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "3WcsDlXS1vOX"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhah61I33YRE",
        "outputId": "37601a9d-8d9a-4bf2-ee97-0e9fb223aa5c"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_stopwords(text):\n",
        "  return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
        "\n",
        "encoded_df['text'] = encoded_df['text'].apply(lambda text : cleaning_stopwords(text))\n",
        "encoded_df['text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhHp6VX030db",
        "outputId": "691ee21d-ec71-4622-9c4a-08fa9ca6f688"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    like want problem takes longer asked friend he...\n",
              "1    man front desk title hr customer service repre...\n",
              "2    wed saving much money new housr expensive city...\n",
              "3    ex used shoot back want go time matter almost ...\n",
              "4    said anything yet sure someone would take hear...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmentization**"
      ],
      "metadata": {
        "id": "DIn2yri54H-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lm = nltk.WordNetLemmatizer()\n",
        "def lemmatizer_on_text(data):\n",
        "    text = [lm.lemmatize(word) for word in data]\n",
        "    return data\n",
        "encoded_df['text'] = encoded_df['text'].apply(lambda x: lemmatizer_on_text(x))\n",
        "encoded_df['text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtmvICi74HhW",
        "outputId": "e04c7d35-bc88-4e5b-cec9-010c6a7b9bfe"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    like want problem takes longer asked friend he...\n",
              "1    man front desk title hr customer service repre...\n",
              "2    wed saving much money new housr expensive city...\n",
              "3    ex used shoot back want go time matter almost ...\n",
              "4    said anything yet sure someone would take hear...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = encoded_df['text']\n",
        "y = encoded_df.iloc[: , 1:]"
      ],
      "metadata": {
        "id": "PKJJgMku33Z7"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "i6mfIp-X4fwv",
        "outputId": "cde9b923-601b-4083-cc31-fb16b2483717"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     almosthomeless  anxiety  assistance  domesticviolence  food_pantry  \\\n",
              "0                 0        0           0                 0            0   \n",
              "1                 0        1           0                 0            0   \n",
              "2                 0        0           0                 0            0   \n",
              "3                 0        0           0                 0            0   \n",
              "4                 0        0           0                 0            0   \n",
              "..              ...      ...         ...               ...          ...   \n",
              "710               0        0           0                 0            0   \n",
              "711               0        0           0                 0            0   \n",
              "712               0        0           0                 0            0   \n",
              "713               0        0           1                 0            0   \n",
              "714               0        0           1                 0            0   \n",
              "\n",
              "     homeless  ptsd  relationships  stress  survivorsofabuse  \n",
              "0           0     0              1       0                 0  \n",
              "1           0     0              0       0                 0  \n",
              "2           0     1              0       0                 0  \n",
              "3           0     1              0       0                 0  \n",
              "4           0     0              1       0                 0  \n",
              "..        ...   ...            ...     ...               ...  \n",
              "710         0     1              0       0                 0  \n",
              "711         0     0              1       0                 0  \n",
              "712         0     0              1       0                 0  \n",
              "713         0     0              0       0                 0  \n",
              "714         0     0              0       0                 0  \n",
              "\n",
              "[715 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0533613-2012-4c47-b5c6-c2f41091ab46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>almosthomeless</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>assistance</th>\n",
              "      <th>domesticviolence</th>\n",
              "      <th>food_pantry</th>\n",
              "      <th>homeless</th>\n",
              "      <th>ptsd</th>\n",
              "      <th>relationships</th>\n",
              "      <th>stress</th>\n",
              "      <th>survivorsofabuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0533613-2012-4c47-b5c6-c2f41091ab46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0533613-2012-4c47-b5c6-c2f41091ab46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0533613-2012-4c47-b5c6-c2f41091ab46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train,y_test = train_test_split(x, y,random_state = 42, test_size=0.1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW2vyBBs4hVC",
        "outputId": "e9afc30c-c04b-4378-e7c8-da294f30e58c"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(643,)\n",
            "(72,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sahPpKtS8au_",
        "outputId": "a35093a3-5174-491f-9c95-2a7e3ac41dd0"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(643, 10)\n",
            "(72, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5bKnWVZ8g5p",
        "outputId": "678aa87c-0142-4c88-bb5e-d41b631c35b6"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120    url learn disabilities like read post url talk...\n",
              "570    wanted believed said would talk toe days later...\n",
              "39     server encourages happiness improving glamoriz...\n",
              "294    anyone dealt urinary retention side effect lex...\n",
              "666    cw mentions selfharm suicide feel overwhelmed ...\n",
              "                             ...                        \n",
              "286    best friend nearly 20 years dealing anxiety ar...\n",
              "617    bad situation stuck nashville friends family m...\n",
              "664    probably know created political survey last we...\n",
              "399    get intrusive memories really hard get head so...\n",
              "698    im last year secondary school mocks doesnt mea...\n",
              "Name: text, Length: 72, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Sequencing**"
      ],
      "metadata": {
        "id": "wja91rd48pSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(lower = False)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_text_vec = tokenizer.texts_to_sequences(X_train)\n",
        "tokenizer.fit_on_texts(X_test)\n",
        "test_text_vec = tokenizer.texts_to_sequences(X_test)\n",
        "test_text_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_gg5v6h8loo",
        "outputId": "39a69254-0289-4195-e096-2e4a2f4284f4"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[172,\n",
              "  794,\n",
              "  2173,\n",
              "  2,\n",
              "  287,\n",
              "  155,\n",
              "  172,\n",
              "  50,\n",
              "  5429,\n",
              "  9,\n",
              "  154,\n",
              "  479,\n",
              "  289,\n",
              "  36,\n",
              "  84,\n",
              "  66,\n",
              "  954,\n",
              "  43,\n",
              "  211,\n",
              "  204,\n",
              "  6,\n",
              "  287],\n",
              " [96,\n",
              "  888,\n",
              "  47,\n",
              "  7,\n",
              "  50,\n",
              "  953,\n",
              "  70,\n",
              "  191,\n",
              "  232,\n",
              "  30,\n",
              "  5430,\n",
              "  2583,\n",
              "  685,\n",
              "  286,\n",
              "  953,\n",
              "  358,\n",
              "  1,\n",
              "  5431,\n",
              "  2756,\n",
              "  8,\n",
              "  11,\n",
              "  5,\n",
              "  187,\n",
              "  4,\n",
              "  75,\n",
              "  953,\n",
              "  1688,\n",
              "  726,\n",
              "  26,\n",
              "  8,\n",
              "  5],\n",
              " [5432,\n",
              "  5433,\n",
              "  2722,\n",
              "  1863,\n",
              "  5434,\n",
              "  152,\n",
              "  1766,\n",
              "  2717,\n",
              "  18,\n",
              "  1055,\n",
              "  5435,\n",
              "  800,\n",
              "  31,\n",
              "  505,\n",
              "  152,\n",
              "  1766,\n",
              "  5436,\n",
              "  63,\n",
              "  505,\n",
              "  13,\n",
              "  16,\n",
              "  1891,\n",
              "  2113,\n",
              "  907,\n",
              "  520,\n",
              "  50,\n",
              "  18,\n",
              "  361,\n",
              "  716,\n",
              "  34,\n",
              "  120,\n",
              "  1784,\n",
              "  430,\n",
              "  172],\n",
              " [41,\n",
              "  1681,\n",
              "  2808,\n",
              "  2809,\n",
              "  455,\n",
              "  1362,\n",
              "  1133,\n",
              "  10,\n",
              "  204,\n",
              "  1133,\n",
              "  2,\n",
              "  134,\n",
              "  135,\n",
              "  100,\n",
              "  45,\n",
              "  366,\n",
              "  387,\n",
              "  1407,\n",
              "  11,\n",
              "  57,\n",
              "  90,\n",
              "  444,\n",
              "  115,\n",
              "  963,\n",
              "  5437,\n",
              "  19,\n",
              "  197,\n",
              "  2,\n",
              "  602,\n",
              "  2763,\n",
              "  17,\n",
              "  769,\n",
              "  116,\n",
              "  17,\n",
              "  303,\n",
              "  2,\n",
              "  51,\n",
              "  547,\n",
              "  5438,\n",
              "  373,\n",
              "  11,\n",
              "  104,\n",
              "  544,\n",
              "  288,\n",
              "  771,\n",
              "  43,\n",
              "  141,\n",
              "  862,\n",
              "  1456,\n",
              "  2808,\n",
              "  2809,\n",
              "  38,\n",
              "  455,\n",
              "  971,\n",
              "  1133],\n",
              " [5439,\n",
              "  1999,\n",
              "  2270,\n",
              "  710,\n",
              "  4,\n",
              "  1046,\n",
              "  677,\n",
              "  117,\n",
              "  263,\n",
              "  456,\n",
              "  607,\n",
              "  90,\n",
              "  2810,\n",
              "  949,\n",
              "  147,\n",
              "  3,\n",
              "  5440,\n",
              "  677,\n",
              "  544,\n",
              "  5441,\n",
              "  69,\n",
              "  5442,\n",
              "  107,\n",
              "  71,\n",
              "  1841,\n",
              "  5443,\n",
              "  3,\n",
              "  20,\n",
              "  50,\n",
              "  396,\n",
              "  5444,\n",
              "  643,\n",
              "  333,\n",
              "  14,\n",
              "  117],\n",
              " [174,\n",
              "  1099,\n",
              "  48,\n",
              "  339,\n",
              "  352,\n",
              "  5445,\n",
              "  6,\n",
              "  48,\n",
              "  1998,\n",
              "  1722,\n",
              "  5446,\n",
              "  401,\n",
              "  562,\n",
              "  5447,\n",
              "  2442,\n",
              "  700,\n",
              "  2568,\n",
              "  5448,\n",
              "  16],\n",
              " [42,\n",
              "  11,\n",
              "  75,\n",
              "  1105,\n",
              "  161,\n",
              "  5449,\n",
              "  2738,\n",
              "  520,\n",
              "  116,\n",
              "  161,\n",
              "  498,\n",
              "  687,\n",
              "  756,\n",
              "  1791,\n",
              "  11,\n",
              "  38,\n",
              "  127,\n",
              "  62,\n",
              "  5450,\n",
              "  269,\n",
              "  1418,\n",
              "  22,\n",
              "  1847,\n",
              "  5451,\n",
              "  209,\n",
              "  65,\n",
              "  356,\n",
              "  5452,\n",
              "  269,\n",
              "  43,\n",
              "  153,\n",
              "  299,\n",
              "  110,\n",
              "  1366,\n",
              "  446,\n",
              "  50,\n",
              "  1022,\n",
              "  9,\n",
              "  9,\n",
              "  12,\n",
              "  354,\n",
              "  901,\n",
              "  194,\n",
              "  5453,\n",
              "  137,\n",
              "  30,\n",
              "  1791,\n",
              "  520,\n",
              "  126,\n",
              "  5454,\n",
              "  2785,\n",
              "  412,\n",
              "  5455,\n",
              "  9,\n",
              "  49,\n",
              "  28],\n",
              " [530,\n",
              "  495,\n",
              "  61,\n",
              "  303,\n",
              "  2089,\n",
              "  814,\n",
              "  2698,\n",
              "  392,\n",
              "  43,\n",
              "  1320,\n",
              "  9,\n",
              "  292,\n",
              "  5456,\n",
              "  743,\n",
              "  239,\n",
              "  774,\n",
              "  205,\n",
              "  40,\n",
              "  45,\n",
              "  2572,\n",
              "  347,\n",
              "  1240,\n",
              "  504,\n",
              "  306,\n",
              "  24,\n",
              "  309,\n",
              "  368,\n",
              "  968,\n",
              "  76,\n",
              "  5457,\n",
              "  19,\n",
              "  2400,\n",
              "  22,\n",
              "  996,\n",
              "  1648,\n",
              "  134,\n",
              "  101,\n",
              "  125,\n",
              "  2811,\n",
              "  19,\n",
              "  252,\n",
              "  154,\n",
              "  297],\n",
              " [20,\n",
              "  266,\n",
              "  65,\n",
              "  8,\n",
              "  162,\n",
              "  102,\n",
              "  15,\n",
              "  41,\n",
              "  15,\n",
              "  11,\n",
              "  103,\n",
              "  166,\n",
              "  7,\n",
              "  5458,\n",
              "  812,\n",
              "  20,\n",
              "  11,\n",
              "  1178,\n",
              "  136,\n",
              "  54,\n",
              "  493,\n",
              "  521,\n",
              "  296,\n",
              "  201,\n",
              "  544,\n",
              "  159,\n",
              "  130,\n",
              "  186,\n",
              "  117,\n",
              "  263,\n",
              "  10,\n",
              "  136,\n",
              "  16,\n",
              "  2,\n",
              "  5459,\n",
              "  451,\n",
              "  199,\n",
              "  11,\n",
              "  190,\n",
              "  5460,\n",
              "  34],\n",
              " [282,\n",
              "  307,\n",
              "  320,\n",
              "  8,\n",
              "  17,\n",
              "  12,\n",
              "  251,\n",
              "  89,\n",
              "  389,\n",
              "  55,\n",
              "  21,\n",
              "  207,\n",
              "  30,\n",
              "  146,\n",
              "  69,\n",
              "  302,\n",
              "  23,\n",
              "  106,\n",
              "  208,\n",
              "  5461,\n",
              "  29,\n",
              "  416,\n",
              "  48,\n",
              "  139,\n",
              "  1803,\n",
              "  44,\n",
              "  35,\n",
              "  207,\n",
              "  240,\n",
              "  1086,\n",
              "  295,\n",
              "  5462,\n",
              "  66,\n",
              "  1361,\n",
              "  78],\n",
              " [36,\n",
              "  5463,\n",
              "  355,\n",
              "  797,\n",
              "  5464,\n",
              "  30,\n",
              "  601,\n",
              "  28,\n",
              "  5465,\n",
              "  913,\n",
              "  5466,\n",
              "  2799,\n",
              "  65,\n",
              "  87,\n",
              "  963,\n",
              "  229,\n",
              "  29,\n",
              "  74,\n",
              "  37,\n",
              "  82,\n",
              "  2676,\n",
              "  7,\n",
              "  140,\n",
              "  33,\n",
              "  88,\n",
              "  87,\n",
              "  641,\n",
              "  32,\n",
              "  36,\n",
              "  1398,\n",
              "  65,\n",
              "  36,\n",
              "  1405,\n",
              "  5467,\n",
              "  1673,\n",
              "  1672,\n",
              "  1125,\n",
              "  149,\n",
              "  243,\n",
              "  514],\n",
              " [6,\n",
              "  44,\n",
              "  720,\n",
              "  515,\n",
              "  1847,\n",
              "  14,\n",
              "  9,\n",
              "  84,\n",
              "  730,\n",
              "  5468,\n",
              "  8,\n",
              "  36,\n",
              "  402,\n",
              "  1231,\n",
              "  1780,\n",
              "  113,\n",
              "  157,\n",
              "  49,\n",
              "  515,\n",
              "  27,\n",
              "  394,\n",
              "  100,\n",
              "  182,\n",
              "  23,\n",
              "  9,\n",
              "  1315,\n",
              "  1366,\n",
              "  1620,\n",
              "  1843,\n",
              "  5469,\n",
              "  236,\n",
              "  5470,\n",
              "  34,\n",
              "  5471,\n",
              "  34,\n",
              "  5472,\n",
              "  5473,\n",
              "  34,\n",
              "  68,\n",
              "  5474,\n",
              "  1337,\n",
              "  82],\n",
              " [2788,\n",
              "  1507,\n",
              "  99,\n",
              "  111,\n",
              "  223,\n",
              "  526,\n",
              "  19,\n",
              "  256,\n",
              "  692,\n",
              "  5475,\n",
              "  193,\n",
              "  2701,\n",
              "  28,\n",
              "  5476,\n",
              "  502,\n",
              "  358,\n",
              "  205,\n",
              "  22,\n",
              "  258,\n",
              "  179,\n",
              "  49,\n",
              "  488,\n",
              "  402,\n",
              "  36,\n",
              "  106,\n",
              "  49,\n",
              "  35,\n",
              "  49,\n",
              "  1006],\n",
              " [349,\n",
              "  809,\n",
              "  807,\n",
              "  1025,\n",
              "  20,\n",
              "  2534,\n",
              "  1009,\n",
              "  743,\n",
              "  239,\n",
              "  376,\n",
              "  119,\n",
              "  226,\n",
              "  75,\n",
              "  963,\n",
              "  838,\n",
              "  838,\n",
              "  5477,\n",
              "  5478,\n",
              "  13,\n",
              "  5479,\n",
              "  67,\n",
              "  9,\n",
              "  34,\n",
              "  772,\n",
              "  633,\n",
              "  1306,\n",
              "  76,\n",
              "  226,\n",
              "  76,\n",
              "  2672,\n",
              "  397,\n",
              "  68,\n",
              "  37,\n",
              "  130,\n",
              "  208,\n",
              "  1314,\n",
              "  1314,\n",
              "  7,\n",
              "  39,\n",
              "  163,\n",
              "  104,\n",
              "  1922,\n",
              "  786,\n",
              "  104,\n",
              "  1269,\n",
              "  980,\n",
              "  5480,\n",
              "  547,\n",
              "  470,\n",
              "  1314,\n",
              "  1121,\n",
              "  651,\n",
              "  75,\n",
              "  1836,\n",
              "  822,\n",
              "  347,\n",
              "  44,\n",
              "  1395,\n",
              "  438,\n",
              "  283,\n",
              "  651,\n",
              "  110,\n",
              "  498,\n",
              "  487,\n",
              "  148,\n",
              "  219,\n",
              "  577,\n",
              "  438,\n",
              "  283,\n",
              "  651,\n",
              "  333,\n",
              "  78,\n",
              "  822,\n",
              "  918,\n",
              "  104,\n",
              "  161,\n",
              "  178,\n",
              "  10,\n",
              "  888,\n",
              "  496,\n",
              "  25,\n",
              "  31,\n",
              "  80,\n",
              "  78,\n",
              "  54,\n",
              "  529,\n",
              "  2481,\n",
              "  588,\n",
              "  795,\n",
              "  2528,\n",
              "  178],\n",
              " [35,\n",
              "  60,\n",
              "  101,\n",
              "  136,\n",
              "  2811,\n",
              "  636,\n",
              "  147,\n",
              "  40,\n",
              "  13,\n",
              "  168,\n",
              "  37,\n",
              "  60,\n",
              "  5481,\n",
              "  37,\n",
              "  911,\n",
              "  208,\n",
              "  5482,\n",
              "  2812,\n",
              "  220,\n",
              "  5483,\n",
              "  122,\n",
              "  487,\n",
              "  1847,\n",
              "  941,\n",
              "  577,\n",
              "  528,\n",
              "  5484,\n",
              "  271,\n",
              "  373,\n",
              "  191,\n",
              "  2812,\n",
              "  915,\n",
              "  259,\n",
              "  5485,\n",
              "  5486,\n",
              "  202,\n",
              "  5487,\n",
              "  612,\n",
              "  1420,\n",
              "  940,\n",
              "  25,\n",
              "  1661,\n",
              "  1420],\n",
              " [1576,\n",
              "  362,\n",
              "  351,\n",
              "  31,\n",
              "  119,\n",
              "  6,\n",
              "  9,\n",
              "  39,\n",
              "  73,\n",
              "  568,\n",
              "  1269,\n",
              "  159,\n",
              "  19,\n",
              "  1471,\n",
              "  21,\n",
              "  86,\n",
              "  5488,\n",
              "  109,\n",
              "  82,\n",
              "  92,\n",
              "  96,\n",
              "  241,\n",
              "  5489,\n",
              "  225,\n",
              "  947,\n",
              "  4,\n",
              "  1142,\n",
              "  66,\n",
              "  92,\n",
              "  525,\n",
              "  407,\n",
              "  2705,\n",
              "  110,\n",
              "  30,\n",
              "  51,\n",
              "  225,\n",
              "  152,\n",
              "  1474,\n",
              "  55,\n",
              "  410,\n",
              "  260,\n",
              "  1681,\n",
              "  360,\n",
              "  4,\n",
              "  422],\n",
              " [81,\n",
              "  35,\n",
              "  77,\n",
              "  10,\n",
              "  82,\n",
              "  9,\n",
              "  1016,\n",
              "  425,\n",
              "  42,\n",
              "  66,\n",
              "  1082,\n",
              "  92,\n",
              "  5,\n",
              "  14,\n",
              "  3,\n",
              "  94,\n",
              "  2783,\n",
              "  5490,\n",
              "  1630,\n",
              "  188,\n",
              "  61,\n",
              "  279,\n",
              "  81,\n",
              "  382,\n",
              "  81,\n",
              "  382,\n",
              "  5491],\n",
              " [322,\n",
              "  345,\n",
              "  21,\n",
              "  589,\n",
              "  8,\n",
              "  11,\n",
              "  5,\n",
              "  1,\n",
              "  479,\n",
              "  52,\n",
              "  8,\n",
              "  11,\n",
              "  5,\n",
              "  1,\n",
              "  266,\n",
              "  4,\n",
              "  1441,\n",
              "  1018,\n",
              "  66,\n",
              "  52,\n",
              "  1,\n",
              "  274,\n",
              "  5492,\n",
              "  479,\n",
              "  626,\n",
              "  107,\n",
              "  340,\n",
              "  301,\n",
              "  1440],\n",
              " [25,\n",
              "  20,\n",
              "  36,\n",
              "  118,\n",
              "  84,\n",
              "  277,\n",
              "  573,\n",
              "  50,\n",
              "  133,\n",
              "  489,\n",
              "  115,\n",
              "  258,\n",
              "  179,\n",
              "  270,\n",
              "  37,\n",
              "  13,\n",
              "  1121,\n",
              "  49,\n",
              "  824,\n",
              "  824,\n",
              "  1121,\n",
              "  49,\n",
              "  199,\n",
              "  53,\n",
              "  43,\n",
              "  246,\n",
              "  38,\n",
              "  68,\n",
              "  5493,\n",
              "  905,\n",
              "  2787,\n",
              "  119,\n",
              "  5494],\n",
              " [99,\n",
              "  339,\n",
              "  23,\n",
              "  161,\n",
              "  99,\n",
              "  566,\n",
              "  630,\n",
              "  213,\n",
              "  101,\n",
              "  356,\n",
              "  1343,\n",
              "  39,\n",
              "  1885,\n",
              "  190,\n",
              "  664,\n",
              "  25,\n",
              "  328,\n",
              "  5495,\n",
              "  16,\n",
              "  5496,\n",
              "  934,\n",
              "  439,\n",
              "  5497,\n",
              "  338,\n",
              "  7,\n",
              "  36,\n",
              "  198,\n",
              "  43,\n",
              "  5498,\n",
              "  1008,\n",
              "  5499,\n",
              "  5500,\n",
              "  5501,\n",
              "  2399],\n",
              " [25,\n",
              "  5502,\n",
              "  364,\n",
              "  394,\n",
              "  2,\n",
              "  5503,\n",
              "  5504,\n",
              "  5505,\n",
              "  5506,\n",
              "  5507,\n",
              "  1437,\n",
              "  33,\n",
              "  76,\n",
              "  334,\n",
              "  56,\n",
              "  204,\n",
              "  2547,\n",
              "  1029,\n",
              "  313,\n",
              "  5508,\n",
              "  752,\n",
              "  56,\n",
              "  5509,\n",
              "  61,\n",
              "  451,\n",
              "  442,\n",
              "  25,\n",
              "  259,\n",
              "  171,\n",
              "  90,\n",
              "  139,\n",
              "  1364,\n",
              "  13,\n",
              "  6,\n",
              "  105,\n",
              "  404,\n",
              "  5510,\n",
              "  476,\n",
              "  187,\n",
              "  91,\n",
              "  814,\n",
              "  5511,\n",
              "  178,\n",
              "  21,\n",
              "  232,\n",
              "  30,\n",
              "  5512,\n",
              "  1437,\n",
              "  125,\n",
              "  2777,\n",
              "  1047,\n",
              "  1432,\n",
              "  227,\n",
              "  178,\n",
              "  1694,\n",
              "  814,\n",
              "  27,\n",
              "  2578],\n",
              " [440,\n",
              "  406,\n",
              "  299,\n",
              "  96,\n",
              "  50,\n",
              "  11,\n",
              "  10,\n",
              "  166,\n",
              "  5513,\n",
              "  5514,\n",
              "  5515,\n",
              "  891,\n",
              "  796,\n",
              "  2083,\n",
              "  8,\n",
              "  1416,\n",
              "  29,\n",
              "  2443,\n",
              "  90,\n",
              "  5516,\n",
              "  121,\n",
              "  133,\n",
              "  980,\n",
              "  5517,\n",
              "  5518,\n",
              "  440,\n",
              "  75,\n",
              "  212,\n",
              "  1420],\n",
              " [10,\n",
              "  636,\n",
              "  113,\n",
              "  969,\n",
              "  51,\n",
              "  6,\n",
              "  46,\n",
              "  514,\n",
              "  338,\n",
              "  1606,\n",
              "  619,\n",
              "  30,\n",
              "  268,\n",
              "  2792,\n",
              "  656,\n",
              "  5519,\n",
              "  242,\n",
              "  161,\n",
              "  419,\n",
              "  314,\n",
              "  5520,\n",
              "  20,\n",
              "  750,\n",
              "  159,\n",
              "  93,\n",
              "  5521,\n",
              "  190,\n",
              "  64,\n",
              "  5522,\n",
              "  715,\n",
              "  84,\n",
              "  1406,\n",
              "  7,\n",
              "  310,\n",
              "  65,\n",
              "  11,\n",
              "  121,\n",
              "  323,\n",
              "  1066,\n",
              "  61,\n",
              "  427,\n",
              "  553,\n",
              "  242,\n",
              "  230,\n",
              "  2433,\n",
              "  311],\n",
              " [374,\n",
              "  160,\n",
              "  81,\n",
              "  318,\n",
              "  1300,\n",
              "  8,\n",
              "  78,\n",
              "  151,\n",
              "  2,\n",
              "  6,\n",
              "  923,\n",
              "  142,\n",
              "  31,\n",
              "  10,\n",
              "  9,\n",
              "  524,\n",
              "  1812,\n",
              "  44,\n",
              "  261,\n",
              "  99,\n",
              "  158,\n",
              "  143,\n",
              "  356,\n",
              "  1039,\n",
              "  11,\n",
              "  1418,\n",
              "  415,\n",
              "  135,\n",
              "  643,\n",
              "  303,\n",
              "  780,\n",
              "  627,\n",
              "  6,\n",
              "  517,\n",
              "  1,\n",
              "  209,\n",
              "  2662,\n",
              "  731,\n",
              "  49,\n",
              "  36,\n",
              "  1701,\n",
              "  532,\n",
              "  1,\n",
              "  428,\n",
              "  1333,\n",
              "  183,\n",
              "  12,\n",
              "  6,\n",
              "  8,\n",
              "  12,\n",
              "  108,\n",
              "  16,\n",
              "  910,\n",
              "  19,\n",
              "  3,\n",
              "  431],\n",
              " [2046,\n",
              "  388,\n",
              "  1801,\n",
              "  67,\n",
              "  7,\n",
              "  664,\n",
              "  597,\n",
              "  99,\n",
              "  47,\n",
              "  372,\n",
              "  157,\n",
              "  597,\n",
              "  255,\n",
              "  5523,\n",
              "  2,\n",
              "  11,\n",
              "  285,\n",
              "  5524,\n",
              "  2042,\n",
              "  1455,\n",
              "  160,\n",
              "  1455,\n",
              "  394,\n",
              "  2,\n",
              "  255,\n",
              "  157,\n",
              "  93,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  255,\n",
              "  8,\n",
              "  36,\n",
              "  2719,\n",
              "  2587,\n",
              "  2,\n",
              "  6,\n",
              "  238,\n",
              "  81,\n",
              "  157,\n",
              "  308,\n",
              "  162,\n",
              "  290,\n",
              "  4,\n",
              "  2,\n",
              "  81,\n",
              "  620,\n",
              "  3,\n",
              "  5525,\n",
              "  5526],\n",
              " [574,\n",
              "  5527,\n",
              "  5528,\n",
              "  7,\n",
              "  98,\n",
              "  21,\n",
              "  5529,\n",
              "  899,\n",
              "  69,\n",
              "  27,\n",
              "  130,\n",
              "  64,\n",
              "  258,\n",
              "  179,\n",
              "  2759,\n",
              "  69,\n",
              "  719,\n",
              "  450,\n",
              "  87,\n",
              "  64,\n",
              "  218,\n",
              "  69,\n",
              "  158,\n",
              "  1176,\n",
              "  1217],\n",
              " [35,\n",
              "  16,\n",
              "  35,\n",
              "  111,\n",
              "  5530,\n",
              "  711,\n",
              "  364,\n",
              "  215,\n",
              "  1795,\n",
              "  132,\n",
              "  52,\n",
              "  126,\n",
              "  155,\n",
              "  606,\n",
              "  3,\n",
              "  861,\n",
              "  40,\n",
              "  93,\n",
              "  12,\n",
              "  474,\n",
              "  766,\n",
              "  324,\n",
              "  106,\n",
              "  5531,\n",
              "  350,\n",
              "  1112,\n",
              "  2806,\n",
              "  237,\n",
              "  5532,\n",
              "  5533,\n",
              "  5534,\n",
              "  5535,\n",
              "  228,\n",
              "  350,\n",
              "  1781,\n",
              "  875,\n",
              "  5536,\n",
              "  414,\n",
              "  22,\n",
              "  929,\n",
              "  215,\n",
              "  429,\n",
              "  626,\n",
              "  5537,\n",
              "  142,\n",
              "  5538,\n",
              "  387,\n",
              "  93,\n",
              "  5539],\n",
              " [3,\n",
              "  296,\n",
              "  5540,\n",
              "  672,\n",
              "  714,\n",
              "  1388,\n",
              "  271,\n",
              "  419,\n",
              "  72,\n",
              "  1842,\n",
              "  34,\n",
              "  15,\n",
              "  296,\n",
              "  487,\n",
              "  520,\n",
              "  388,\n",
              "  2694,\n",
              "  1211,\n",
              "  1141,\n",
              "  5541,\n",
              "  5542],\n",
              " [71,\n",
              "  184,\n",
              "  144,\n",
              "  8,\n",
              "  36,\n",
              "  107,\n",
              "  37,\n",
              "  36,\n",
              "  523,\n",
              "  628,\n",
              "  860,\n",
              "  434,\n",
              "  170,\n",
              "  321,\n",
              "  25,\n",
              "  196,\n",
              "  162,\n",
              "  18,\n",
              "  523,\n",
              "  997,\n",
              "  36,\n",
              "  1418,\n",
              "  6,\n",
              "  18,\n",
              "  71,\n",
              "  306,\n",
              "  1475,\n",
              "  16,\n",
              "  324,\n",
              "  258,\n",
              "  179,\n",
              "  246,\n",
              "  14,\n",
              "  263,\n",
              "  5543,\n",
              "  635,\n",
              "  37,\n",
              "  37,\n",
              "  647,\n",
              "  5,\n",
              "  1404,\n",
              "  81,\n",
              "  53,\n",
              "  873,\n",
              "  291,\n",
              "  2563,\n",
              "  68,\n",
              "  267,\n",
              "  33],\n",
              " [2241,\n",
              "  107,\n",
              "  1523,\n",
              "  205,\n",
              "  5544,\n",
              "  478,\n",
              "  10,\n",
              "  230,\n",
              "  2535,\n",
              "  7,\n",
              "  91,\n",
              "  59,\n",
              "  67,\n",
              "  197,\n",
              "  212,\n",
              "  2488,\n",
              "  343,\n",
              "  248,\n",
              "  5545,\n",
              "  20,\n",
              "  46,\n",
              "  639,\n",
              "  447,\n",
              "  898,\n",
              "  125,\n",
              "  84,\n",
              "  592,\n",
              "  5546,\n",
              "  1138,\n",
              "  805,\n",
              "  1271,\n",
              "  425,\n",
              "  21,\n",
              "  30,\n",
              "  453,\n",
              "  195,\n",
              "  5547,\n",
              "  51,\n",
              "  6,\n",
              "  36],\n",
              " [9,\n",
              "  64,\n",
              "  1,\n",
              "  479,\n",
              "  5548,\n",
              "  2317,\n",
              "  89,\n",
              "  31,\n",
              "  1817,\n",
              "  24,\n",
              "  5549,\n",
              "  802,\n",
              "  2805,\n",
              "  4,\n",
              "  2,\n",
              "  303,\n",
              "  94,\n",
              "  1347,\n",
              "  311,\n",
              "  14,\n",
              "  227,\n",
              "  5550,\n",
              "  664,\n",
              "  6,\n",
              "  1683,\n",
              "  451,\n",
              "  23,\n",
              "  4,\n",
              "  2,\n",
              "  1,\n",
              "  987,\n",
              "  2128,\n",
              "  679,\n",
              "  438,\n",
              "  138,\n",
              "  6,\n",
              "  1,\n",
              "  210,\n",
              "  534,\n",
              "  1288,\n",
              "  137,\n",
              "  103,\n",
              "  857,\n",
              "  1069,\n",
              "  2804,\n",
              "  1,\n",
              "  277,\n",
              "  38,\n",
              "  943,\n",
              "  189,\n",
              "  61,\n",
              "  709,\n",
              "  1048,\n",
              "  388,\n",
              "  5551,\n",
              "  755,\n",
              "  2574,\n",
              "  238,\n",
              "  4,\n",
              "  2,\n",
              "  1,\n",
              "  39,\n",
              "  2746,\n",
              "  1995,\n",
              "  189,\n",
              "  153],\n",
              " [2803,\n",
              "  1142,\n",
              "  52,\n",
              "  8,\n",
              "  655,\n",
              "  304,\n",
              "  27,\n",
              "  5552,\n",
              "  213,\n",
              "  5553,\n",
              "  562,\n",
              "  91,\n",
              "  584,\n",
              "  3,\n",
              "  71,\n",
              "  350,\n",
              "  2289,\n",
              "  61,\n",
              "  71,\n",
              "  584,\n",
              "  39,\n",
              "  309,\n",
              "  12,\n",
              "  22,\n",
              "  30,\n",
              "  410,\n",
              "  46,\n",
              "  1693,\n",
              "  1019,\n",
              "  1117,\n",
              "  357,\n",
              "  5554,\n",
              "  44,\n",
              "  5555,\n",
              "  5556,\n",
              "  5557,\n",
              "  2475,\n",
              "  5558,\n",
              "  25,\n",
              "  110,\n",
              "  1341,\n",
              "  302,\n",
              "  23,\n",
              "  717,\n",
              "  5559,\n",
              "  112],\n",
              " [5560,\n",
              "  407,\n",
              "  1555,\n",
              "  4,\n",
              "  1461,\n",
              "  2148,\n",
              "  76,\n",
              "  432,\n",
              "  150,\n",
              "  1627,\n",
              "  1478,\n",
              "  5561,\n",
              "  5562,\n",
              "  387,\n",
              "  109,\n",
              "  2,\n",
              "  312,\n",
              "  5563,\n",
              "  149,\n",
              "  11,\n",
              "  2800,\n",
              "  832,\n",
              "  58,\n",
              "  486,\n",
              "  1379,\n",
              "  45,\n",
              "  62,\n",
              "  146,\n",
              "  433,\n",
              "  2656,\n",
              "  1588,\n",
              "  47,\n",
              "  276,\n",
              "  17,\n",
              "  87,\n",
              "  143,\n",
              "  12,\n",
              "  43,\n",
              "  143,\n",
              "  198,\n",
              "  17,\n",
              "  52,\n",
              "  493,\n",
              "  251,\n",
              "  17,\n",
              "  599,\n",
              "  599,\n",
              "  278,\n",
              "  599,\n",
              "  2772,\n",
              "  912,\n",
              "  642,\n",
              "  611,\n",
              "  76,\n",
              "  74,\n",
              "  22,\n",
              "  76,\n",
              "  109],\n",
              " [125,\n",
              "  66,\n",
              "  26,\n",
              "  2813,\n",
              "  667,\n",
              "  2200,\n",
              "  84,\n",
              "  2552,\n",
              "  80,\n",
              "  1161,\n",
              "  5564,\n",
              "  622,\n",
              "  424,\n",
              "  1752,\n",
              "  950,\n",
              "  56,\n",
              "  2094,\n",
              "  5565,\n",
              "  898,\n",
              "  90,\n",
              "  5566,\n",
              "  38,\n",
              "  368,\n",
              "  117,\n",
              "  234,\n",
              "  280,\n",
              "  29,\n",
              "  2521,\n",
              "  212,\n",
              "  5567,\n",
              "  647,\n",
              "  77,\n",
              "  624,\n",
              "  35,\n",
              "  1467,\n",
              "  90,\n",
              "  121,\n",
              "  2260,\n",
              "  77,\n",
              "  998,\n",
              "  457,\n",
              "  546,\n",
              "  165,\n",
              "  1793,\n",
              "  1091,\n",
              "  19,\n",
              "  740,\n",
              "  1154,\n",
              "  1254,\n",
              "  5568,\n",
              "  16,\n",
              "  10,\n",
              "  136,\n",
              "  222,\n",
              "  16,\n",
              "  8],\n",
              " [2628,\n",
              "  71,\n",
              "  506,\n",
              "  1336,\n",
              "  257,\n",
              "  7,\n",
              "  49,\n",
              "  20,\n",
              "  1701,\n",
              "  31,\n",
              "  12,\n",
              "  21,\n",
              "  1318,\n",
              "  792,\n",
              "  385,\n",
              "  545,\n",
              "  127,\n",
              "  13,\n",
              "  113,\n",
              "  5569,\n",
              "  96,\n",
              "  1502,\n",
              "  942],\n",
              " [174,\n",
              "  70,\n",
              "  348,\n",
              "  122,\n",
              "  627,\n",
              "  89,\n",
              "  59,\n",
              "  4,\n",
              "  156,\n",
              "  113,\n",
              "  834,\n",
              "  10,\n",
              "  1596,\n",
              "  1096,\n",
              "  117,\n",
              "  263,\n",
              "  1281,\n",
              "  25,\n",
              "  47,\n",
              "  2471,\n",
              "  116,\n",
              "  335,\n",
              "  86,\n",
              "  2367,\n",
              "  106,\n",
              "  5570,\n",
              "  140,\n",
              "  48,\n",
              "  153,\n",
              "  295,\n",
              "  1188,\n",
              "  44,\n",
              "  47,\n",
              "  16,\n",
              "  503,\n",
              "  229,\n",
              "  2543,\n",
              "  99,\n",
              "  524,\n",
              "  321,\n",
              "  103,\n",
              "  262,\n",
              "  25,\n",
              "  2613,\n",
              "  5571,\n",
              "  5572,\n",
              "  194,\n",
              "  183,\n",
              "  1,\n",
              "  24,\n",
              "  68,\n",
              "  2729,\n",
              "  2,\n",
              "  978,\n",
              "  1426,\n",
              "  772,\n",
              "  33],\n",
              " [255,\n",
              "  184,\n",
              "  5573,\n",
              "  216,\n",
              "  5574,\n",
              "  339,\n",
              "  70,\n",
              "  83,\n",
              "  7,\n",
              "  99,\n",
              "  302,\n",
              "  79,\n",
              "  876,\n",
              "  168,\n",
              "  33,\n",
              "  831,\n",
              "  428,\n",
              "  175,\n",
              "  483,\n",
              "  400,\n",
              "  206,\n",
              "  216,\n",
              "  280,\n",
              "  678,\n",
              "  231,\n",
              "  413,\n",
              "  986,\n",
              "  123,\n",
              "  32,\n",
              "  12,\n",
              "  229,\n",
              "  44,\n",
              "  124,\n",
              "  6,\n",
              "  107,\n",
              "  47,\n",
              "  36,\n",
              "  7,\n",
              "  40,\n",
              "  6,\n",
              "  1560,\n",
              "  7,\n",
              "  641,\n",
              "  140,\n",
              "  33,\n",
              "  30,\n",
              "  401,\n",
              "  503],\n",
              " [150,\n",
              "  68,\n",
              "  1049,\n",
              "  105,\n",
              "  198,\n",
              "  5575,\n",
              "  1751,\n",
              "  315,\n",
              "  5576,\n",
              "  5577,\n",
              "  34,\n",
              "  17,\n",
              "  165,\n",
              "  15,\n",
              "  345,\n",
              "  5578,\n",
              "  16,\n",
              "  44,\n",
              "  175,\n",
              "  355,\n",
              "  357,\n",
              "  548,\n",
              "  242,\n",
              "  513,\n",
              "  847,\n",
              "  5579,\n",
              "  22,\n",
              "  1063,\n",
              "  829,\n",
              "  22,\n",
              "  1063,\n",
              "  5580,\n",
              "  229,\n",
              "  126,\n",
              "  521,\n",
              "  5581,\n",
              "  100,\n",
              "  79,\n",
              "  315,\n",
              "  354],\n",
              " [2624,\n",
              "  101,\n",
              "  1073,\n",
              "  5582,\n",
              "  39,\n",
              "  374,\n",
              "  1400,\n",
              "  3,\n",
              "  534,\n",
              "  462,\n",
              "  410,\n",
              "  148,\n",
              "  200,\n",
              "  194,\n",
              "  100,\n",
              "  396,\n",
              "  7,\n",
              "  2,\n",
              "  50,\n",
              "  48,\n",
              "  2454,\n",
              "  1073,\n",
              "  138,\n",
              "  469,\n",
              "  341,\n",
              "  341,\n",
              "  628,\n",
              "  310],\n",
              " [5583,\n",
              "  1854,\n",
              "  119,\n",
              "  5584,\n",
              "  5585,\n",
              "  211,\n",
              "  287,\n",
              "  107,\n",
              "  5586,\n",
              "  1893,\n",
              "  41,\n",
              "  315,\n",
              "  1264,\n",
              "  1298,\n",
              "  2210,\n",
              "  430],\n",
              " [749,\n",
              "  5,\n",
              "  6,\n",
              "  5587,\n",
              "  1529,\n",
              "  14,\n",
              "  5588,\n",
              "  218,\n",
              "  929,\n",
              "  117,\n",
              "  4,\n",
              "  1139,\n",
              "  285,\n",
              "  268,\n",
              "  52,\n",
              "  1563,\n",
              "  5589,\n",
              "  328,\n",
              "  2,\n",
              "  14,\n",
              "  767,\n",
              "  2702,\n",
              "  525,\n",
              "  650,\n",
              "  1340,\n",
              "  2813,\n",
              "  149,\n",
              "  2748,\n",
              "  817,\n",
              "  240,\n",
              "  1561,\n",
              "  547,\n",
              "  470,\n",
              "  191,\n",
              "  52,\n",
              "  30,\n",
              "  56],\n",
              " [5590,\n",
              "  2129,\n",
              "  239,\n",
              "  1051,\n",
              "  265,\n",
              "  505,\n",
              "  5591,\n",
              "  672,\n",
              "  308,\n",
              "  227,\n",
              "  22,\n",
              "  19,\n",
              "  246,\n",
              "  745,\n",
              "  43,\n",
              "  345,\n",
              "  2707,\n",
              "  72,\n",
              "  670,\n",
              "  339,\n",
              "  326,\n",
              "  594,\n",
              "  6,\n",
              "  223,\n",
              "  37,\n",
              "  19,\n",
              "  1826,\n",
              "  240,\n",
              "  1511,\n",
              "  72,\n",
              "  670,\n",
              "  183,\n",
              "  134,\n",
              "  23,\n",
              "  855,\n",
              "  670,\n",
              "  60,\n",
              "  326,\n",
              "  13,\n",
              "  223,\n",
              "  69,\n",
              "  127,\n",
              "  261,\n",
              "  167,\n",
              "  72,\n",
              "  670,\n",
              "  1571,\n",
              "  326,\n",
              "  948],\n",
              " [80,\n",
              "  84,\n",
              "  5592,\n",
              "  382,\n",
              "  53,\n",
              "  1383,\n",
              "  52,\n",
              "  5593,\n",
              "  205,\n",
              "  160,\n",
              "  869,\n",
              "  52,\n",
              "  269,\n",
              "  10,\n",
              "  19,\n",
              "  1383,\n",
              "  170,\n",
              "  14,\n",
              "  56,\n",
              "  100,\n",
              "  182,\n",
              "  135,\n",
              "  2760,\n",
              "  14,\n",
              "  115,\n",
              "  212,\n",
              "  473],\n",
              " [8,\n",
              "  5,\n",
              "  1220,\n",
              "  86,\n",
              "  228,\n",
              "  27,\n",
              "  401,\n",
              "  237,\n",
              "  384,\n",
              "  5594,\n",
              "  66,\n",
              "  1558,\n",
              "  1465,\n",
              "  18,\n",
              "  319,\n",
              "  130,\n",
              "  642,\n",
              "  500,\n",
              "  130,\n",
              "  118,\n",
              "  72,\n",
              "  26,\n",
              "  1,\n",
              "  985,\n",
              "  124,\n",
              "  921,\n",
              "  37,\n",
              "  2403,\n",
              "  618,\n",
              "  394,\n",
              "  10,\n",
              "  84,\n",
              "  5595,\n",
              "  8,\n",
              "  5,\n",
              "  1697,\n",
              "  1818,\n",
              "  2745,\n",
              "  21,\n",
              "  157,\n",
              "  131,\n",
              "  28,\n",
              "  37,\n",
              "  7,\n",
              "  299,\n",
              "  383,\n",
              "  157,\n",
              "  74,\n",
              "  18,\n",
              "  457,\n",
              "  140,\n",
              "  387,\n",
              "  1329,\n",
              "  401,\n",
              "  4,\n",
              "  518,\n",
              "  1593,\n",
              "  716,\n",
              "  100,\n",
              "  1112],\n",
              " [128,\n",
              "  109,\n",
              "  5596,\n",
              "  5597,\n",
              "  2790,\n",
              "  1558,\n",
              "  1019,\n",
              "  5598,\n",
              "  128,\n",
              "  109,\n",
              "  1848,\n",
              "  5599,\n",
              "  945,\n",
              "  2343,\n",
              "  2638,\n",
              "  102,\n",
              "  2619,\n",
              "  361,\n",
              "  1247,\n",
              "  5600,\n",
              "  5601,\n",
              "  880,\n",
              "  702,\n",
              "  29,\n",
              "  1848,\n",
              "  27,\n",
              "  702,\n",
              "  11,\n",
              "  461,\n",
              "  1054,\n",
              "  29,\n",
              "  1848],\n",
              " [56,\n",
              "  117,\n",
              "  234,\n",
              "  1247,\n",
              "  5602,\n",
              "  73,\n",
              "  195,\n",
              "  2798,\n",
              "  5603,\n",
              "  764,\n",
              "  73,\n",
              "  1433,\n",
              "  67,\n",
              "  195,\n",
              "  234,\n",
              "  35,\n",
              "  6,\n",
              "  82,\n",
              "  712,\n",
              "  67,\n",
              "  24,\n",
              "  392,\n",
              "  55,\n",
              "  1282],\n",
              " [281,\n",
              "  1753,\n",
              "  85,\n",
              "  37,\n",
              "  112,\n",
              "  5604,\n",
              "  20,\n",
              "  15,\n",
              "  982,\n",
              "  101,\n",
              "  2,\n",
              "  579,\n",
              "  328,\n",
              "  2,\n",
              "  475,\n",
              "  531,\n",
              "  126,\n",
              "  68,\n",
              "  33,\n",
              "  2749,\n",
              "  497,\n",
              "  159,\n",
              "  1515],\n",
              " [180,\n",
              "  168,\n",
              "  95,\n",
              "  660,\n",
              "  666,\n",
              "  784,\n",
              "  46,\n",
              "  37,\n",
              "  159,\n",
              "  2370,\n",
              "  666,\n",
              "  294,\n",
              "  442,\n",
              "  5605,\n",
              "  5606,\n",
              "  37,\n",
              "  100,\n",
              "  442,\n",
              "  113,\n",
              "  7,\n",
              "  365,\n",
              "  516,\n",
              "  737,\n",
              "  288,\n",
              "  192,\n",
              "  17,\n",
              "  347,\n",
              "  353,\n",
              "  318,\n",
              "  1034,\n",
              "  19,\n",
              "  1795,\n",
              "  571,\n",
              "  95,\n",
              "  423,\n",
              "  58,\n",
              "  29,\n",
              "  5607,\n",
              "  61,\n",
              "  1090,\n",
              "  353],\n",
              " [202,\n",
              "  34,\n",
              "  15,\n",
              "  817,\n",
              "  5608,\n",
              "  1043,\n",
              "  3,\n",
              "  192,\n",
              "  202,\n",
              "  80,\n",
              "  24,\n",
              "  639,\n",
              "  46,\n",
              "  3,\n",
              "  58,\n",
              "  124,\n",
              "  26,\n",
              "  108,\n",
              "  2814,\n",
              "  5609,\n",
              "  309,\n",
              "  57,\n",
              "  331,\n",
              "  411,\n",
              "  97,\n",
              "  165,\n",
              "  60,\n",
              "  934,\n",
              "  106,\n",
              "  34,\n",
              "  148,\n",
              "  41,\n",
              "  15,\n",
              "  11,\n",
              "  103,\n",
              "  166,\n",
              "  5610,\n",
              "  38,\n",
              "  9,\n",
              "  235,\n",
              "  193,\n",
              "  1053],\n",
              " [51,\n",
              "  32,\n",
              "  1372,\n",
              "  1387,\n",
              "  1296,\n",
              "  1458,\n",
              "  5611,\n",
              "  105,\n",
              "  2291,\n",
              "  441,\n",
              "  16,\n",
              "  1,\n",
              "  987,\n",
              "  468,\n",
              "  1169,\n",
              "  7,\n",
              "  309,\n",
              "  63,\n",
              "  164,\n",
              "  107,\n",
              "  120,\n",
              "  242,\n",
              "  403,\n",
              "  387,\n",
              "  1845,\n",
              "  468,\n",
              "  309,\n",
              "  258,\n",
              "  179,\n",
              "  342,\n",
              "  1845,\n",
              "  2715,\n",
              "  26],\n",
              " [572,\n",
              "  224,\n",
              "  1,\n",
              "  2126,\n",
              "  62,\n",
              "  1224,\n",
              "  464,\n",
              "  604,\n",
              "  5612,\n",
              "  110,\n",
              "  5613,\n",
              "  1442,\n",
              "  235,\n",
              "  1131,\n",
              "  86,\n",
              "  1849,\n",
              "  58,\n",
              "  459,\n",
              "  1849,\n",
              "  430,\n",
              "  565,\n",
              "  172,\n",
              "  7,\n",
              "  812,\n",
              "  41,\n",
              "  5614,\n",
              "  565,\n",
              "  361,\n",
              "  2468,\n",
              "  5615,\n",
              "  755,\n",
              "  2654,\n",
              "  514,\n",
              "  565,\n",
              "  5616,\n",
              "  235,\n",
              "  1131,\n",
              "  688,\n",
              "  459,\n",
              "  1849,\n",
              "  2118,\n",
              "  584,\n",
              "  41,\n",
              "  282,\n",
              "  204,\n",
              "  205,\n",
              "  34,\n",
              "  29,\n",
              "  1017,\n",
              "  5617,\n",
              "  329,\n",
              "  991,\n",
              "  1463,\n",
              "  1698,\n",
              "  708,\n",
              "  340,\n",
              "  1507,\n",
              "  1103,\n",
              "  139,\n",
              "  559,\n",
              "  361,\n",
              "  48,\n",
              "  276,\n",
              "  5618,\n",
              "  1104,\n",
              "  2495,\n",
              "  992,\n",
              "  185,\n",
              "  5619,\n",
              "  340,\n",
              "  1155,\n",
              "  1761,\n",
              "  5620,\n",
              "  2623,\n",
              "  1104],\n",
              " [1395,\n",
              "  7,\n",
              "  405,\n",
              "  268,\n",
              "  7,\n",
              "  5621,\n",
              "  240,\n",
              "  5622,\n",
              "  7,\n",
              "  5623,\n",
              "  5624,\n",
              "  494,\n",
              "  395,\n",
              "  713,\n",
              "  84,\n",
              "  55,\n",
              "  2,\n",
              "  67,\n",
              "  2054,\n",
              "  254,\n",
              "  77,\n",
              "  260,\n",
              "  2084,\n",
              "  1652,\n",
              "  5625,\n",
              "  2153,\n",
              "  501,\n",
              "  268,\n",
              "  424,\n",
              "  5626],\n",
              " [557,\n",
              "  262,\n",
              "  26,\n",
              "  2766,\n",
              "  5627,\n",
              "  147,\n",
              "  41,\n",
              "  125,\n",
              "  1518,\n",
              "  2815,\n",
              "  167,\n",
              "  2539,\n",
              "  45,\n",
              "  5628,\n",
              "  2815,\n",
              "  5629,\n",
              "  419,\n",
              "  12,\n",
              "  31,\n",
              "  1154,\n",
              "  31,\n",
              "  910,\n",
              "  426,\n",
              "  302,\n",
              "  79,\n",
              "  136,\n",
              "  109,\n",
              "  212],\n",
              " [1846,\n",
              "  5630,\n",
              "  118,\n",
              "  681,\n",
              "  5631,\n",
              "  1108,\n",
              "  5632,\n",
              "  408,\n",
              "  393,\n",
              "  423,\n",
              "  11,\n",
              "  6,\n",
              "  116,\n",
              "  939,\n",
              "  42,\n",
              "  82,\n",
              "  73,\n",
              "  2,\n",
              "  5633,\n",
              "  5634,\n",
              "  7,\n",
              "  2768,\n",
              "  241,\n",
              "  1562,\n",
              "  36,\n",
              "  71,\n",
              "  5635,\n",
              "  330,\n",
              "  105,\n",
              "  404,\n",
              "  5636,\n",
              "  1709,\n",
              "  437,\n",
              "  233,\n",
              "  1108,\n",
              "  64,\n",
              "  124,\n",
              "  110,\n",
              "  356,\n",
              "  2259],\n",
              " [168,\n",
              "  10,\n",
              "  5637,\n",
              "  574,\n",
              "  47,\n",
              "  276,\n",
              "  25,\n",
              "  1623,\n",
              "  13,\n",
              "  32,\n",
              "  2406,\n",
              "  53,\n",
              "  81,\n",
              "  487,\n",
              "  181,\n",
              "  169,\n",
              "  309,\n",
              "  102,\n",
              "  331,\n",
              "  4,\n",
              "  362,\n",
              "  13,\n",
              "  77,\n",
              "  5638,\n",
              "  77,\n",
              "  741,\n",
              "  1,\n",
              "  2505,\n",
              "  64,\n",
              "  5639,\n",
              "  210,\n",
              "  85,\n",
              "  57,\n",
              "  137,\n",
              "  1623,\n",
              "  126,\n",
              "  1,\n",
              "  64,\n",
              "  98,\n",
              "  258,\n",
              "  179,\n",
              "  69,\n",
              "  276,\n",
              "  169,\n",
              "  271,\n",
              "  99,\n",
              "  1,\n",
              "  84,\n",
              "  730,\n",
              "  844],\n",
              " [648,\n",
              "  313,\n",
              "  5640,\n",
              "  555,\n",
              "  250,\n",
              "  243,\n",
              "  66,\n",
              "  47,\n",
              "  273,\n",
              "  1983,\n",
              "  191,\n",
              "  5641,\n",
              "  2,\n",
              "  708,\n",
              "  657,\n",
              "  12,\n",
              "  1065,\n",
              "  597,\n",
              "  1048,\n",
              "  244,\n",
              "  796,\n",
              "  2565,\n",
              "  549,\n",
              "  190,\n",
              "  309,\n",
              "  20,\n",
              "  141,\n",
              "  1148,\n",
              "  72,\n",
              "  581,\n",
              "  170,\n",
              "  65,\n",
              "  170,\n",
              "  2566],\n",
              " [314,\n",
              "  459,\n",
              "  132,\n",
              "  357,\n",
              "  214,\n",
              "  315,\n",
              "  1327,\n",
              "  532,\n",
              "  19,\n",
              "  1862,\n",
              "  806,\n",
              "  368,\n",
              "  313,\n",
              "  1075,\n",
              "  48,\n",
              "  444,\n",
              "  87,\n",
              "  8,\n",
              "  12,\n",
              "  312,\n",
              "  870,\n",
              "  12,\n",
              "  18,\n",
              "  5,\n",
              "  321,\n",
              "  418,\n",
              "  29,\n",
              "  2604,\n",
              "  193,\n",
              "  375,\n",
              "  71,\n",
              "  32],\n",
              " [111,\n",
              "  1979,\n",
              "  268,\n",
              "  4,\n",
              "  2,\n",
              "  17,\n",
              "  1407,\n",
              "  33,\n",
              "  145,\n",
              "  101,\n",
              "  5642,\n",
              "  209,\n",
              "  29,\n",
              "  1025,\n",
              "  96,\n",
              "  3,\n",
              "  78,\n",
              "  36,\n",
              "  111,\n",
              "  1603,\n",
              "  214,\n",
              "  2,\n",
              "  14,\n",
              "  1310,\n",
              "  1,\n",
              "  57,\n",
              "  415,\n",
              "  32,\n",
              "  253,\n",
              "  1,\n",
              "  72,\n",
              "  561,\n",
              "  126,\n",
              "  3,\n",
              "  67,\n",
              "  790,\n",
              "  17,\n",
              "  1,\n",
              "  2666],\n",
              " [986,\n",
              "  123,\n",
              "  44,\n",
              "  56,\n",
              "  942,\n",
              "  3,\n",
              "  200,\n",
              "  91,\n",
              "  1462,\n",
              "  133,\n",
              "  9,\n",
              "  209,\n",
              "  310,\n",
              "  92,\n",
              "  41,\n",
              "  153,\n",
              "  418,\n",
              "  694,\n",
              "  852,\n",
              "  124,\n",
              "  34,\n",
              "  5643,\n",
              "  188,\n",
              "  5,\n",
              "  116,\n",
              "  671,\n",
              "  262],\n",
              " [350,\n",
              "  1096,\n",
              "  1347,\n",
              "  2390,\n",
              "  5644,\n",
              "  1035,\n",
              "  463,\n",
              "  1703,\n",
              "  619,\n",
              "  1345,\n",
              "  2816,\n",
              "  93,\n",
              "  954,\n",
              "  5,\n",
              "  115,\n",
              "  194,\n",
              "  528,\n",
              "  43,\n",
              "  5645,\n",
              "  2816,\n",
              "  296,\n",
              "  811,\n",
              "  214,\n",
              "  2814,\n",
              "  854,\n",
              "  145,\n",
              "  5,\n",
              "  1799,\n",
              "  351,\n",
              "  231,\n",
              "  564,\n",
              "  5646,\n",
              "  1484,\n",
              "  656,\n",
              "  429,\n",
              "  1844,\n",
              "  5647,\n",
              "  1500,\n",
              "  377,\n",
              "  2751,\n",
              "  2472,\n",
              "  2750,\n",
              "  1844,\n",
              "  1463,\n",
              "  128,\n",
              "  1135,\n",
              "  708,\n",
              "  38,\n",
              "  89,\n",
              "  13,\n",
              "  33,\n",
              "  886,\n",
              "  52],\n",
              " [10,\n",
              "  39,\n",
              "  2030,\n",
              "  2451,\n",
              "  5648,\n",
              "  641,\n",
              "  142,\n",
              "  205,\n",
              "  417,\n",
              "  1,\n",
              "  1139,\n",
              "  53,\n",
              "  5649,\n",
              "  10,\n",
              "  2422,\n",
              "  227,\n",
              "  22,\n",
              "  19,\n",
              "  1822,\n",
              "  2,\n",
              "  5650],\n",
              " [549,\n",
              "  106,\n",
              "  12,\n",
              "  943,\n",
              "  1,\n",
              "  154,\n",
              "  11,\n",
              "  1,\n",
              "  821,\n",
              "  209,\n",
              "  247,\n",
              "  515,\n",
              "  8,\n",
              "  36,\n",
              "  1943,\n",
              "  26,\n",
              "  58,\n",
              "  415,\n",
              "  155,\n",
              "  244,\n",
              "  5651,\n",
              "  425,\n",
              "  2264,\n",
              "  138,\n",
              "  134,\n",
              "  70,\n",
              "  20,\n",
              "  36,\n",
              "  643,\n",
              "  8,\n",
              "  5,\n",
              "  20,\n",
              "  80],\n",
              " [88,\n",
              "  432,\n",
              "  5652,\n",
              "  5653,\n",
              "  517,\n",
              "  2647,\n",
              "  5654,\n",
              "  5655,\n",
              "  13,\n",
              "  93,\n",
              "  836,\n",
              "  76,\n",
              "  432,\n",
              "  460,\n",
              "  5656,\n",
              "  195,\n",
              "  16,\n",
              "  5657,\n",
              "  54,\n",
              "  5658,\n",
              "  5659,\n",
              "  5660,\n",
              "  5661,\n",
              "  1356,\n",
              "  1760,\n",
              "  340,\n",
              "  1356,\n",
              "  1760],\n",
              " [455,\n",
              "  828,\n",
              "  2810,\n",
              "  269,\n",
              "  1070,\n",
              "  1555,\n",
              "  33,\n",
              "  5662,\n",
              "  1974,\n",
              "  228,\n",
              "  290,\n",
              "  1190,\n",
              "  882,\n",
              "  555,\n",
              "  25,\n",
              "  88,\n",
              "  28,\n",
              "  1190,\n",
              "  882,\n",
              "  210,\n",
              "  830,\n",
              "  749,\n",
              "  1111,\n",
              "  229,\n",
              "  355,\n",
              "  641,\n",
              "  25,\n",
              "  1303,\n",
              "  4,\n",
              "  34,\n",
              "  1597,\n",
              "  65,\n",
              "  52,\n",
              "  105,\n",
              "  360,\n",
              "  924,\n",
              "  2,\n",
              "  382,\n",
              "  278,\n",
              "  87,\n",
              "  5663,\n",
              "  1595,\n",
              "  46,\n",
              "  51,\n",
              "  182,\n",
              "  23],\n",
              " [125,\n",
              "  206,\n",
              "  98,\n",
              "  49,\n",
              "  206,\n",
              "  706,\n",
              "  238,\n",
              "  371,\n",
              "  49,\n",
              "  46,\n",
              "  731,\n",
              "  1573,\n",
              "  1296,\n",
              "  474,\n",
              "  309,\n",
              "  66,\n",
              "  336,\n",
              "  132,\n",
              "  9,\n",
              "  2019,\n",
              "  549,\n",
              "  5664,\n",
              "  313,\n",
              "  1642,\n",
              "  466,\n",
              "  534,\n",
              "  154,\n",
              "  3,\n",
              "  3,\n",
              "  85,\n",
              "  22,\n",
              "  118,\n",
              "  174,\n",
              "  165,\n",
              "  146,\n",
              "  433,\n",
              "  49,\n",
              "  1817,\n",
              "  379,\n",
              "  323,\n",
              "  433,\n",
              "  290,\n",
              "  195,\n",
              "  5665],\n",
              " [161,\n",
              "  5666,\n",
              "  137,\n",
              "  30,\n",
              "  150,\n",
              "  527,\n",
              "  247,\n",
              "  367,\n",
              "  151,\n",
              "  11,\n",
              "  535,\n",
              "  491,\n",
              "  130,\n",
              "  1989,\n",
              "  5667,\n",
              "  535,\n",
              "  1123,\n",
              "  365,\n",
              "  516,\n",
              "  737,\n",
              "  2795,\n",
              "  18,\n",
              "  2625,\n",
              "  2461,\n",
              "  17,\n",
              "  26,\n",
              "  113,\n",
              "  57,\n",
              "  19,\n",
              "  535,\n",
              "  1417,\n",
              "  43,\n",
              "  486,\n",
              "  1650,\n",
              "  198,\n",
              "  41,\n",
              "  3,\n",
              "  861,\n",
              "  189,\n",
              "  5668,\n",
              "  11,\n",
              "  103,\n",
              "  2206,\n",
              "  102,\n",
              "  190,\n",
              "  2571,\n",
              "  91,\n",
              "  571,\n",
              "  115,\n",
              "  18,\n",
              "  2586,\n",
              "  100,\n",
              "  44,\n",
              "  129,\n",
              "  48,\n",
              "  1883,\n",
              "  664,\n",
              "  1145,\n",
              "  374,\n",
              "  157,\n",
              "  673,\n",
              "  126,\n",
              "  197,\n",
              "  2,\n",
              "  14,\n",
              "  950,\n",
              "  1010,\n",
              "  347],\n",
              " [864,\n",
              "  532,\n",
              "  341,\n",
              "  161,\n",
              "  57,\n",
              "  162,\n",
              "  1362,\n",
              "  86,\n",
              "  1837,\n",
              "  175,\n",
              "  570,\n",
              "  412,\n",
              "  2513,\n",
              "  569,\n",
              "  2817,\n",
              "  412,\n",
              "  38,\n",
              "  136,\n",
              "  43,\n",
              "  153,\n",
              "  7,\n",
              "  770,\n",
              "  36,\n",
              "  48,\n",
              "  249,\n",
              "  2817,\n",
              "  878,\n",
              "  412,\n",
              "  77,\n",
              "  363,\n",
              "  5669,\n",
              "  13],\n",
              " [68,\n",
              "  69,\n",
              "  793,\n",
              "  343,\n",
              "  23,\n",
              "  600,\n",
              "  14,\n",
              "  61,\n",
              "  581,\n",
              "  170,\n",
              "  1032,\n",
              "  16,\n",
              "  541,\n",
              "  15,\n",
              "  275,\n",
              "  105,\n",
              "  351,\n",
              "  924,\n",
              "  85,\n",
              "  727,\n",
              "  21,\n",
              "  99,\n",
              "  165,\n",
              "  83,\n",
              "  1361,\n",
              "  170,\n",
              "  45,\n",
              "  191,\n",
              "  42,\n",
              "  204,\n",
              "  354,\n",
              "  5670,\n",
              "  536,\n",
              "  116,\n",
              "  351,\n",
              "  924,\n",
              "  275,\n",
              "  131,\n",
              "  47,\n",
              "  920,\n",
              "  114,\n",
              "  2340,\n",
              "  1387,\n",
              "  638,\n",
              "  70,\n",
              "  638,\n",
              "  998,\n",
              "  45],\n",
              " [91,\n",
              "  144,\n",
              "  610,\n",
              "  5671,\n",
              "  37,\n",
              "  65,\n",
              "  102,\n",
              "  581,\n",
              "  1654,\n",
              "  105,\n",
              "  5672,\n",
              "  20,\n",
              "  46,\n",
              "  2720,\n",
              "  482,\n",
              "  192,\n",
              "  1695,\n",
              "  8,\n",
              "  113,\n",
              "  127,\n",
              "  60,\n",
              "  135,\n",
              "  1273,\n",
              "  337,\n",
              "  5673,\n",
              "  5674,\n",
              "  5675,\n",
              "  163,\n",
              "  5676,\n",
              "  130],\n",
              " [244,\n",
              "  5,\n",
              "  1553,\n",
              "  1850,\n",
              "  991,\n",
              "  40,\n",
              "  45,\n",
              "  5677,\n",
              "  628,\n",
              "  1850,\n",
              "  2818,\n",
              "  628,\n",
              "  775,\n",
              "  815,\n",
              "  667,\n",
              "  5678,\n",
              "  99,\n",
              "  1306,\n",
              "  24,\n",
              "  5679,\n",
              "  775,\n",
              "  202,\n",
              "  775,\n",
              "  815,\n",
              "  2819,\n",
              "  5680,\n",
              "  5681,\n",
              "  24,\n",
              "  76,\n",
              "  5682,\n",
              "  292,\n",
              "  173,\n",
              "  775,\n",
              "  815,\n",
              "  667,\n",
              "  1850,\n",
              "  2818,\n",
              "  2819,\n",
              "  292,\n",
              "  173,\n",
              "  775,\n",
              "  815,\n",
              "  667,\n",
              "  173],\n",
              " [3,\n",
              "  743,\n",
              "  502,\n",
              "  9,\n",
              "  121,\n",
              "  3,\n",
              "  187,\n",
              "  90,\n",
              "  133,\n",
              "  2192,\n",
              "  2,\n",
              "  1,\n",
              "  399,\n",
              "  5683,\n",
              "  146,\n",
              "  502,\n",
              "  314,\n",
              "  90,\n",
              "  338,\n",
              "  143,\n",
              "  411,\n",
              "  622,\n",
              "  35,\n",
              "  6,\n",
              "  10,\n",
              "  9,\n",
              "  67,\n",
              "  5684,\n",
              "  106,\n",
              "  1830,\n",
              "  5685,\n",
              "  105,\n",
              "  404,\n",
              "  194,\n",
              "  786,\n",
              "  16,\n",
              "  163,\n",
              "  87,\n",
              "  157,\n",
              "  85,\n",
              "  51,\n",
              "  6,\n",
              "  17,\n",
              "  719,\n",
              "  117,\n",
              "  234],\n",
              " [1,\n",
              "  40,\n",
              "  62,\n",
              "  2573,\n",
              "  72,\n",
              "  5686,\n",
              "  143,\n",
              "  723,\n",
              "  2789,\n",
              "  1476,\n",
              "  1,\n",
              "  285,\n",
              "  5687,\n",
              "  105,\n",
              "  634,\n",
              "  5688,\n",
              "  762,\n",
              "  105,\n",
              "  2820,\n",
              "  53,\n",
              "  2,\n",
              "  1,\n",
              "  920,\n",
              "  124,\n",
              "  1637,\n",
              "  178,\n",
              "  5689,\n",
              "  51,\n",
              "  6,\n",
              "  116,\n",
              "  944,\n",
              "  535,\n",
              "  249,\n",
              "  5690,\n",
              "  45,\n",
              "  191,\n",
              "  288,\n",
              "  5691,\n",
              "  2052,\n",
              "  5692,\n",
              "  178,\n",
              "  245,\n",
              "  437,\n",
              "  72,\n",
              "  4,\n",
              "  2,\n",
              "  1,\n",
              "  24,\n",
              "  342,\n",
              "  6,\n",
              "  1012,\n",
              "  1,\n",
              "  2802,\n",
              "  1,\n",
              "  490,\n",
              "  6,\n",
              "  265,\n",
              "  295,\n",
              "  1,\n",
              "  84,\n",
              "  730,\n",
              "  730,\n",
              "  2821,\n",
              "  2821,\n",
              "  2626,\n",
              "  43,\n",
              "  2820,\n",
              "  449,\n",
              "  5693,\n",
              "  105,\n",
              "  5694,\n",
              "  178,\n",
              "  954]]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(seq) for seq in (train_text_vec + test_text_vec)])\n",
        "from keras.preprocessing import sequence\n",
        "max_words = max_length\n",
        "X_train = keras.utils.pad_sequences(train_text_vec, maxlen=max_words)\n",
        "X_test = keras.utils.pad_sequences(test_text_vec, maxlen=max_words)\n",
        "modelRNN = None\n",
        "modelLSTM = None\n",
        "print(\"After Padding x[train[0]=\\n\" , X_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzRdm-lF8s7J",
        "outputId": "b5d0ee51-9456-4f95-fde7-b337fa652eeb"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Padding x[train[0]=\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0  172  794 2173    2  287\n",
            "  155  172   50 5429    9  154  479  289   36   84   66  954   43  211\n",
            "  204    6  287]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelling**"
      ],
      "metadata": {
        "id": "zTcQUwY3-LOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXi3wnTY931E",
        "outputId": "8734326c-a2d5-4ec1-87af-71eebe2b36f6"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5694 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = len((train_text_vec + test_text_vec))*2\n",
        "vocabulary_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO8I41Rc-Ose",
        "outputId": "80a4a53c-4820-4e8d-e9e2-a54451c28129"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1430"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Glove Embeddings**"
      ],
      "metadata": {
        "id": "mt89vPL4-Ve7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open('/content/glove.6B.100d.txt',encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4jfPYEZ-RPQ",
        "outputId": "c2a57733-d0c2-4b88-a8bd-292e7893df7f"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "c1NetEk--iSA"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recurrent Neural Network(RNN)**"
      ],
      "metadata": {
        "id": "jSGy2krD_LBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "rDWCjv3q-zB_"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size=100\n",
        "\n",
        "\n",
        "modelRNN=Sequential()\n",
        "modelRNN.add(Embedding(len(word_index) + 1,embedding_size,weights = [embedding_matrix],input_length=max_words)) #embdsize\n",
        "# modelRNN.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "modelRNN.add(Dropout(0.70))\n",
        "modelRNN.add(SimpleRNN(150,activation = \"tanh\",kernel_regularizer=regularizers.l2(0.01))) \n",
        "modelRNN.add(Dropout(0.15))\n",
        "modelRNN.add(Dense(10, activation='softmax'))\n",
        "print(modelRNN.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GprU_wh0_OoQ",
        "outputId": "f062e363-d81d-488b-e7fa-1713cee264f6"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 129, 100)          569500    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 129, 100)          0         \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 150)               37650     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 150)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1510      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 608,660\n",
            "Trainable params: 608,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelRNN.compile(loss='categorical_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'],run_eagerly=True)"
      ],
      "metadata": {
        "id": "xypMQwcl_f6D"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "num_epochs = 200\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "callback_listRNN  = [#early1\n",
        "                keras.callbacks.ModelCheckpoint(filepath=\"my_modRNN_BestValAcc.h5\", monitor=\"val_acc\",\n",
        "                                               save_best_only=True),\n",
        "                #keras.callbacks.TerminateOnNaN()\n",
        "                ]"
      ],
      "metadata": {
        "id": "_kEB2htp_odH"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "MRmR9tznEnEx",
        "outputId": "4af96bb2-346b-4957-e01d-a9e566ce8daa"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     almosthomeless  anxiety  assistance  domesticviolence  food_pantry  \\\n",
              "591               0        1           0                 0            0   \n",
              "302               0        0           0                 1            0   \n",
              "101               0        1           0                 0            0   \n",
              "526               0        0           0                 0            0   \n",
              "192               0        0           0                 0            0   \n",
              "..              ...      ...         ...               ...          ...   \n",
              "71                0        0           0                 1            0   \n",
              "106               0        0           0                 0            0   \n",
              "270               0        0           0                 0            0   \n",
              "435               0        0           0                 0            0   \n",
              "102               0        0           0                 0            0   \n",
              "\n",
              "     homeless  ptsd  relationships  stress  survivorsofabuse  \n",
              "591         0     0              0       0                 0  \n",
              "302         0     0              0       0                 0  \n",
              "101         0     0              0       0                 0  \n",
              "526         0     0              1       0                 0  \n",
              "192         0     1              0       0                 0  \n",
              "..        ...   ...            ...     ...               ...  \n",
              "71          0     0              0       0                 0  \n",
              "106         0     0              0       0                 1  \n",
              "270         0     1              0       0                 0  \n",
              "435         0     0              1       0                 0  \n",
              "102         0     0              0       0                 1  \n",
              "\n",
              "[643 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d93b5a44-ad02-4d52-a4ef-81ca13a62243\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>almosthomeless</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>assistance</th>\n",
              "      <th>domesticviolence</th>\n",
              "      <th>food_pantry</th>\n",
              "      <th>homeless</th>\n",
              "      <th>ptsd</th>\n",
              "      <th>relationships</th>\n",
              "      <th>stress</th>\n",
              "      <th>survivorsofabuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>643 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d93b5a44-ad02-4d52-a4ef-81ca13a62243')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d93b5a44-ad02-4d52-a4ef-81ca13a62243 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d93b5a44-ad02-4d52-a4ef-81ca13a62243');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "history = modelRNN.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs, \n",
        "             callbacks=callback_listRNN)\n",
        "modelRNN.save_weights(\"my_modRNN_Latest\")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrfFwjZJ_rzA",
        "outputId": "9da3b775-53d3-4632-f501-19a836096f3c"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - ETA: 0s - loss: 3.9171 - accuracy: 0.0793"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 728ms/step - loss: 3.9171 - accuracy: 0.0793 - val_loss: 3.5912 - val_accuracy: 0.1446\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.9102 - accuracy: 0.0731"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 657ms/step - loss: 3.9102 - accuracy: 0.0731 - val_loss: 3.4806 - val_accuracy: 0.1664\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7273 - accuracy: 0.1322"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 772ms/step - loss: 3.7273 - accuracy: 0.1322 - val_loss: 3.3984 - val_accuracy: 0.1820\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6453 - accuracy: 0.1477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 3.6453 - accuracy: 0.1477 - val_loss: 3.3386 - val_accuracy: 0.1851\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5804 - accuracy: 0.1400"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 618ms/step - loss: 3.5804 - accuracy: 0.1400 - val_loss: 3.2977 - val_accuracy: 0.1851\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5507 - accuracy: 0.1820"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 589ms/step - loss: 3.5507 - accuracy: 0.1820 - val_loss: 3.2694 - val_accuracy: 0.2037\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.4935 - accuracy: 0.1633"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 609ms/step - loss: 3.4935 - accuracy: 0.1633 - val_loss: 3.2519 - val_accuracy: 0.2240\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.4477 - accuracy: 0.2053"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 563ms/step - loss: 3.4477 - accuracy: 0.2053 - val_loss: 3.2390 - val_accuracy: 0.2317\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.4469 - accuracy: 0.1804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 599ms/step - loss: 3.4469 - accuracy: 0.1804 - val_loss: 3.2257 - val_accuracy: 0.2333\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3871 - accuracy: 0.1820"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 593ms/step - loss: 3.3871 - accuracy: 0.1820 - val_loss: 3.2036 - val_accuracy: 0.2519\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3219 - accuracy: 0.1991"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 571ms/step - loss: 3.3219 - accuracy: 0.1991 - val_loss: 3.1753 - val_accuracy: 0.2659\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2769 - accuracy: 0.2240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 620ms/step - loss: 3.2769 - accuracy: 0.2240 - val_loss: 3.1425 - val_accuracy: 0.2846\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3097 - accuracy: 0.2037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 707ms/step - loss: 3.3097 - accuracy: 0.2037 - val_loss: 3.1097 - val_accuracy: 0.2908\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1954 - accuracy: 0.2162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 685ms/step - loss: 3.1954 - accuracy: 0.2162 - val_loss: 3.0794 - val_accuracy: 0.2893\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2067 - accuracy: 0.2193"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 632ms/step - loss: 3.2067 - accuracy: 0.2193 - val_loss: 3.0528 - val_accuracy: 0.2939\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2048 - accuracy: 0.2037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 599ms/step - loss: 3.2048 - accuracy: 0.2037 - val_loss: 3.0297 - val_accuracy: 0.3033\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1528 - accuracy: 0.2317"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 606ms/step - loss: 3.1528 - accuracy: 0.2317 - val_loss: 3.0077 - val_accuracy: 0.3110\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1461 - accuracy: 0.2177"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 593ms/step - loss: 3.1461 - accuracy: 0.2177 - val_loss: 2.9880 - val_accuracy: 0.3110\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1182 - accuracy: 0.2255"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 608ms/step - loss: 3.1182 - accuracy: 0.2255 - val_loss: 2.9691 - val_accuracy: 0.3095\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1418 - accuracy: 0.2193"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 683ms/step - loss: 3.1418 - accuracy: 0.2193 - val_loss: 2.9506 - val_accuracy: 0.3173\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0811 - accuracy: 0.2364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 830ms/step - loss: 3.0811 - accuracy: 0.2364 - val_loss: 2.9324 - val_accuracy: 0.3126\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0682 - accuracy: 0.2068"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 798ms/step - loss: 3.0682 - accuracy: 0.2068 - val_loss: 2.9147 - val_accuracy: 0.3048\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0422 - accuracy: 0.2426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 712ms/step - loss: 3.0422 - accuracy: 0.2426 - val_loss: 2.8965 - val_accuracy: 0.3002\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0268 - accuracy: 0.2426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 632ms/step - loss: 3.0268 - accuracy: 0.2426 - val_loss: 2.8764 - val_accuracy: 0.3002\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9812 - accuracy: 0.2659"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 586ms/step - loss: 2.9812 - accuracy: 0.2659 - val_loss: 2.8506 - val_accuracy: 0.3017\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9839 - accuracy: 0.2348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 591ms/step - loss: 2.9839 - accuracy: 0.2348 - val_loss: 2.8228 - val_accuracy: 0.3219\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9632 - accuracy: 0.2271"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 588ms/step - loss: 2.9632 - accuracy: 0.2271 - val_loss: 2.7951 - val_accuracy: 0.3406\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9203 - accuracy: 0.2659"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 594ms/step - loss: 2.9203 - accuracy: 0.2659 - val_loss: 2.7669 - val_accuracy: 0.3561\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9129 - accuracy: 0.2582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 688ms/step - loss: 2.9129 - accuracy: 0.2582 - val_loss: 2.7382 - val_accuracy: 0.3748\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8969 - accuracy: 0.2862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 592ms/step - loss: 2.8969 - accuracy: 0.2862 - val_loss: 2.7093 - val_accuracy: 0.3888\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9182 - accuracy: 0.2582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 615ms/step - loss: 2.9182 - accuracy: 0.2582 - val_loss: 2.6824 - val_accuracy: 0.3904\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9021 - accuracy: 0.2862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 626ms/step - loss: 2.9021 - accuracy: 0.2862 - val_loss: 2.6582 - val_accuracy: 0.3935\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8408 - accuracy: 0.2659"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 588ms/step - loss: 2.8408 - accuracy: 0.2659 - val_loss: 2.6348 - val_accuracy: 0.3904\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8627 - accuracy: 0.2628"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 683ms/step - loss: 2.8627 - accuracy: 0.2628 - val_loss: 2.6121 - val_accuracy: 0.3950\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8273 - accuracy: 0.2799"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 671ms/step - loss: 2.8273 - accuracy: 0.2799 - val_loss: 2.5910 - val_accuracy: 0.3935\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7833 - accuracy: 0.2784"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 593ms/step - loss: 2.7833 - accuracy: 0.2784 - val_loss: 2.5698 - val_accuracy: 0.3888\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8001 - accuracy: 0.2908"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 676ms/step - loss: 2.8001 - accuracy: 0.2908 - val_loss: 2.5470 - val_accuracy: 0.3841\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7808 - accuracy: 0.3079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 587ms/step - loss: 2.7808 - accuracy: 0.3079 - val_loss: 2.5218 - val_accuracy: 0.3888\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7492 - accuracy: 0.2830"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 789ms/step - loss: 2.7492 - accuracy: 0.2830 - val_loss: 2.4959 - val_accuracy: 0.4075\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7054 - accuracy: 0.2924"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.7054 - accuracy: 0.2924 - val_loss: 2.4715 - val_accuracy: 0.4292\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7151 - accuracy: 0.3157"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 730ms/step - loss: 2.7151 - accuracy: 0.3157 - val_loss: 2.4457 - val_accuracy: 0.4355\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6905 - accuracy: 0.3142"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 592ms/step - loss: 2.6905 - accuracy: 0.3142 - val_loss: 2.4212 - val_accuracy: 0.4495\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6436 - accuracy: 0.3110"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 621ms/step - loss: 2.6436 - accuracy: 0.3110 - val_loss: 2.3992 - val_accuracy: 0.4666\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6843 - accuracy: 0.2924"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 688ms/step - loss: 2.6843 - accuracy: 0.2924 - val_loss: 2.3789 - val_accuracy: 0.4743\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6295 - accuracy: 0.3250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 688ms/step - loss: 2.6295 - accuracy: 0.3250 - val_loss: 2.3610 - val_accuracy: 0.4712\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6463 - accuracy: 0.3095"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 600ms/step - loss: 2.6463 - accuracy: 0.3095 - val_loss: 2.3449 - val_accuracy: 0.4790\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6036 - accuracy: 0.3235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 670ms/step - loss: 2.6036 - accuracy: 0.3235 - val_loss: 2.3294 - val_accuracy: 0.4837\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5787 - accuracy: 0.3266"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 600ms/step - loss: 2.5787 - accuracy: 0.3266 - val_loss: 2.3149 - val_accuracy: 0.4914\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5833 - accuracy: 0.3235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 670ms/step - loss: 2.5833 - accuracy: 0.3235 - val_loss: 2.2985 - val_accuracy: 0.4868\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5583 - accuracy: 0.3266"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 608ms/step - loss: 2.5583 - accuracy: 0.3266 - val_loss: 2.2850 - val_accuracy: 0.4868\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5087 - accuracy: 0.3359"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 613ms/step - loss: 2.5087 - accuracy: 0.3359 - val_loss: 2.2706 - val_accuracy: 0.4883\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5369 - accuracy: 0.3499"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 652ms/step - loss: 2.5369 - accuracy: 0.3499 - val_loss: 2.2532 - val_accuracy: 0.4883\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4946 - accuracy: 0.3639"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 585ms/step - loss: 2.4946 - accuracy: 0.3639 - val_loss: 2.2300 - val_accuracy: 0.4930\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4992 - accuracy: 0.3530"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 594ms/step - loss: 2.4992 - accuracy: 0.3530 - val_loss: 2.2050 - val_accuracy: 0.4992\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5133 - accuracy: 0.3250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 585ms/step - loss: 2.5133 - accuracy: 0.3250 - val_loss: 2.1794 - val_accuracy: 0.5210\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4541 - accuracy: 0.3779"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 693ms/step - loss: 2.4541 - accuracy: 0.3779 - val_loss: 2.1553 - val_accuracy: 0.5412\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4412 - accuracy: 0.3624"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 809ms/step - loss: 2.4412 - accuracy: 0.3624 - val_loss: 2.1293 - val_accuracy: 0.5583\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4544 - accuracy: 0.3453"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.4544 - accuracy: 0.3453 - val_loss: 2.1040 - val_accuracy: 0.5677\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4147 - accuracy: 0.3717"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 651ms/step - loss: 2.4147 - accuracy: 0.3717 - val_loss: 2.0790 - val_accuracy: 0.5785\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4096 - accuracy: 0.3670"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 669ms/step - loss: 2.4096 - accuracy: 0.3670 - val_loss: 2.0561 - val_accuracy: 0.5770\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3840 - accuracy: 0.3810"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 678ms/step - loss: 2.3840 - accuracy: 0.3810 - val_loss: 2.0331 - val_accuracy: 0.5770\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3603 - accuracy: 0.3779"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 677ms/step - loss: 2.3603 - accuracy: 0.3779 - val_loss: 2.0138 - val_accuracy: 0.5816\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3499 - accuracy: 0.3701"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 679ms/step - loss: 2.3499 - accuracy: 0.3701 - val_loss: 1.9962 - val_accuracy: 0.5832\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3248 - accuracy: 0.3795"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 621ms/step - loss: 2.3248 - accuracy: 0.3795 - val_loss: 1.9765 - val_accuracy: 0.5816\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2862 - accuracy: 0.4075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 608ms/step - loss: 2.2862 - accuracy: 0.4075 - val_loss: 1.9604 - val_accuracy: 0.5832\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2728 - accuracy: 0.4044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 594ms/step - loss: 2.2728 - accuracy: 0.4044 - val_loss: 1.9411 - val_accuracy: 0.5879\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3211 - accuracy: 0.3981"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 584ms/step - loss: 2.3211 - accuracy: 0.3981 - val_loss: 1.9156 - val_accuracy: 0.5910\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2944 - accuracy: 0.4044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 593ms/step - loss: 2.2944 - accuracy: 0.4044 - val_loss: 1.8876 - val_accuracy: 0.6065\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2519 - accuracy: 0.4339"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 679ms/step - loss: 2.2519 - accuracy: 0.4339 - val_loss: 1.8551 - val_accuracy: 0.6299\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2179 - accuracy: 0.3919"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 684ms/step - loss: 2.2179 - accuracy: 0.3919 - val_loss: 1.8265 - val_accuracy: 0.6252\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1959 - accuracy: 0.4432"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 674ms/step - loss: 2.1959 - accuracy: 0.4432 - val_loss: 1.8053 - val_accuracy: 0.6299\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2084 - accuracy: 0.4370"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 587ms/step - loss: 2.2084 - accuracy: 0.4370 - val_loss: 1.7807 - val_accuracy: 0.6439\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2053 - accuracy: 0.4168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 591ms/step - loss: 2.2053 - accuracy: 0.4168 - val_loss: 1.7427 - val_accuracy: 0.6610\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1690 - accuracy: 0.4090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 682ms/step - loss: 2.1690 - accuracy: 0.4090 - val_loss: 1.7089 - val_accuracy: 0.6750\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2009 - accuracy: 0.4230"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 2.2009 - accuracy: 0.4230 - val_loss: 1.6805 - val_accuracy: 0.6641\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1433 - accuracy: 0.4308"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 839ms/step - loss: 2.1433 - accuracy: 0.4308 - val_loss: 1.6673 - val_accuracy: 0.6610\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0935 - accuracy: 0.4619"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 630ms/step - loss: 2.0935 - accuracy: 0.4619 - val_loss: 1.6534 - val_accuracy: 0.6625\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1051 - accuracy: 0.4588"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 624ms/step - loss: 2.1051 - accuracy: 0.4588 - val_loss: 1.6430 - val_accuracy: 0.6594\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1202 - accuracy: 0.4323"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 690ms/step - loss: 2.1202 - accuracy: 0.4323 - val_loss: 1.6381 - val_accuracy: 0.6750\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1099 - accuracy: 0.4603"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 679ms/step - loss: 2.1099 - accuracy: 0.4603 - val_loss: 1.6437 - val_accuracy: 0.6594\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0492 - accuracy: 0.4526"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 610ms/step - loss: 2.0492 - accuracy: 0.4526 - val_loss: 1.6058 - val_accuracy: 0.6812\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0454 - accuracy: 0.4946"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 705ms/step - loss: 2.0454 - accuracy: 0.4946 - val_loss: 1.5528 - val_accuracy: 0.6936\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0345 - accuracy: 0.4495"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 686ms/step - loss: 2.0345 - accuracy: 0.4495 - val_loss: 1.5217 - val_accuracy: 0.6936\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0350 - accuracy: 0.4650"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 677ms/step - loss: 2.0350 - accuracy: 0.4650 - val_loss: 1.5028 - val_accuracy: 0.6967\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9757 - accuracy: 0.4790"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 621ms/step - loss: 1.9757 - accuracy: 0.4790 - val_loss: 1.4579 - val_accuracy: 0.7372\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9688 - accuracy: 0.4837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 596ms/step - loss: 1.9688 - accuracy: 0.4837 - val_loss: 1.4437 - val_accuracy: 0.7496\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9626 - accuracy: 0.4837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 606ms/step - loss: 1.9626 - accuracy: 0.4837 - val_loss: 1.4364 - val_accuracy: 0.7543\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9844 - accuracy: 0.4837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 693ms/step - loss: 1.9844 - accuracy: 0.4837 - val_loss: 1.3981 - val_accuracy: 0.7667\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9170 - accuracy: 0.5039"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 674ms/step - loss: 1.9170 - accuracy: 0.5039 - val_loss: 1.3638 - val_accuracy: 0.7714\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9078 - accuracy: 0.4977"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 673ms/step - loss: 1.9078 - accuracy: 0.4977 - val_loss: 1.3416 - val_accuracy: 0.7683\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8888 - accuracy: 0.5023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 604ms/step - loss: 1.8888 - accuracy: 0.5023 - val_loss: 1.3263 - val_accuracy: 0.7745\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8851 - accuracy: 0.5086"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 826ms/step - loss: 1.8851 - accuracy: 0.5086 - val_loss: 1.2967 - val_accuracy: 0.7760\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8202 - accuracy: 0.5459"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 795ms/step - loss: 1.8202 - accuracy: 0.5459 - val_loss: 1.2652 - val_accuracy: 0.7885\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8605 - accuracy: 0.5163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 809ms/step - loss: 1.8605 - accuracy: 0.5163 - val_loss: 1.2414 - val_accuracy: 0.7932\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8391 - accuracy: 0.5070"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 632ms/step - loss: 1.8391 - accuracy: 0.5070 - val_loss: 1.2468 - val_accuracy: 0.7947\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8112 - accuracy: 0.5365"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 698ms/step - loss: 1.8112 - accuracy: 0.5365 - val_loss: 1.2903 - val_accuracy: 0.7683\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8120 - accuracy: 0.5334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 698ms/step - loss: 1.8120 - accuracy: 0.5334 - val_loss: 1.2090 - val_accuracy: 0.7978\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7637 - accuracy: 0.5350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 619ms/step - loss: 1.7637 - accuracy: 0.5350 - val_loss: 1.3900 - val_accuracy: 0.6439\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7724 - accuracy: 0.5350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 691ms/step - loss: 1.7724 - accuracy: 0.5350 - val_loss: 1.4574 - val_accuracy: 0.5801\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8080 - accuracy: 0.5226"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 674ms/step - loss: 1.8080 - accuracy: 0.5226 - val_loss: 1.2194 - val_accuracy: 0.7558\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7659 - accuracy: 0.5381"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 604ms/step - loss: 1.7659 - accuracy: 0.5381 - val_loss: 1.2044 - val_accuracy: 0.7760\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7218 - accuracy: 0.5505"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 677ms/step - loss: 1.7218 - accuracy: 0.5505 - val_loss: 1.1592 - val_accuracy: 0.7869\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7219 - accuracy: 0.5739"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 584ms/step - loss: 1.7219 - accuracy: 0.5739 - val_loss: 1.1071 - val_accuracy: 0.8025\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6116 - accuracy: 0.5910"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 584ms/step - loss: 1.6116 - accuracy: 0.5910 - val_loss: 1.1339 - val_accuracy: 0.7869\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6583 - accuracy: 0.5816"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 602ms/step - loss: 1.6583 - accuracy: 0.5816 - val_loss: 1.0566 - val_accuracy: 0.8227\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6484 - accuracy: 0.5723"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 682ms/step - loss: 1.6484 - accuracy: 0.5723 - val_loss: 1.0927 - val_accuracy: 0.7900\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6418 - accuracy: 0.5785"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 683ms/step - loss: 1.6418 - accuracy: 0.5785 - val_loss: 1.0747 - val_accuracy: 0.7947\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5860 - accuracy: 0.5894"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 676ms/step - loss: 1.5860 - accuracy: 0.5894 - val_loss: 0.9829 - val_accuracy: 0.8600\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5848 - accuracy: 0.6081"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 704ms/step - loss: 1.5848 - accuracy: 0.6081 - val_loss: 0.9636 - val_accuracy: 0.8709\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6401 - accuracy: 0.5770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.6401 - accuracy: 0.5770 - val_loss: 0.9897 - val_accuracy: 0.8383\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5511 - accuracy: 0.6143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 865ms/step - loss: 1.5511 - accuracy: 0.6143 - val_loss: 1.0277 - val_accuracy: 0.8072\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5415 - accuracy: 0.6128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 615ms/step - loss: 1.5415 - accuracy: 0.6128 - val_loss: 0.9776 - val_accuracy: 0.8336\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5238 - accuracy: 0.6159"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 707ms/step - loss: 1.5238 - accuracy: 0.6159 - val_loss: 0.9326 - val_accuracy: 0.8523\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4850 - accuracy: 0.6423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 629ms/step - loss: 1.4850 - accuracy: 0.6423 - val_loss: 0.9529 - val_accuracy: 0.8476\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4726 - accuracy: 0.6221"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 675ms/step - loss: 1.4726 - accuracy: 0.6221 - val_loss: 0.9592 - val_accuracy: 0.8320\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4394 - accuracy: 0.6361"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 680ms/step - loss: 1.4394 - accuracy: 0.6361 - val_loss: 0.9884 - val_accuracy: 0.8212\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4771 - accuracy: 0.6423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 623ms/step - loss: 1.4771 - accuracy: 0.6423 - val_loss: 1.0018 - val_accuracy: 0.8072\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5148 - accuracy: 0.6034"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 664ms/step - loss: 1.5148 - accuracy: 0.6034 - val_loss: 0.9572 - val_accuracy: 0.8258\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4013 - accuracy: 0.6563"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 693ms/step - loss: 1.4013 - accuracy: 0.6563 - val_loss: 0.9487 - val_accuracy: 0.8336\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.6299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 695ms/step - loss: 1.4634 - accuracy: 0.6299 - val_loss: 0.8755 - val_accuracy: 0.8585\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3904 - accuracy: 0.6547"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 594ms/step - loss: 1.3904 - accuracy: 0.6547 - val_loss: 0.9560 - val_accuracy: 0.7947\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3878 - accuracy: 0.6423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 613ms/step - loss: 1.3878 - accuracy: 0.6423 - val_loss: 0.8513 - val_accuracy: 0.8787\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3398 - accuracy: 0.6765"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 600ms/step - loss: 1.3398 - accuracy: 0.6765 - val_loss: 0.9930 - val_accuracy: 0.7869\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3437 - accuracy: 0.6501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 590ms/step - loss: 1.3437 - accuracy: 0.6501 - val_loss: 1.2159 - val_accuracy: 0.6672\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3969 - accuracy: 0.6439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 700ms/step - loss: 1.3969 - accuracy: 0.6439 - val_loss: 0.9865 - val_accuracy: 0.7869\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3483 - accuracy: 0.6501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 674ms/step - loss: 1.3483 - accuracy: 0.6501 - val_loss: 0.8344 - val_accuracy: 0.8523\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3720 - accuracy: 0.6610"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 808ms/step - loss: 1.3720 - accuracy: 0.6610 - val_loss: 0.7571 - val_accuracy: 0.8865\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3334 - accuracy: 0.6439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 831ms/step - loss: 1.3334 - accuracy: 0.6439 - val_loss: 0.7072 - val_accuracy: 0.9160\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2886 - accuracy: 0.6734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 764ms/step - loss: 1.2886 - accuracy: 0.6734 - val_loss: 0.6716 - val_accuracy: 0.9285\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2383 - accuracy: 0.6998"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 579ms/step - loss: 1.2383 - accuracy: 0.6998 - val_loss: 0.6601 - val_accuracy: 0.9253\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2822 - accuracy: 0.6781"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 654ms/step - loss: 1.2822 - accuracy: 0.6781 - val_loss: 0.6639 - val_accuracy: 0.9285\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2702 - accuracy: 0.6858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 603ms/step - loss: 1.2702 - accuracy: 0.6858 - val_loss: 0.6642 - val_accuracy: 0.9285\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2452 - accuracy: 0.6936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 597ms/step - loss: 1.2452 - accuracy: 0.6936 - val_loss: 0.6659 - val_accuracy: 0.9269\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2302 - accuracy: 0.6967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 600ms/step - loss: 1.2302 - accuracy: 0.6967 - val_loss: 0.6697 - val_accuracy: 0.9253\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1897 - accuracy: 0.7045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 692ms/step - loss: 1.1897 - accuracy: 0.7045 - val_loss: 0.6945 - val_accuracy: 0.9176\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2183 - accuracy: 0.7045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 676ms/step - loss: 1.2183 - accuracy: 0.7045 - val_loss: 0.7117 - val_accuracy: 0.9067\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1898 - accuracy: 0.7309"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 593ms/step - loss: 1.1898 - accuracy: 0.7309 - val_loss: 0.8300 - val_accuracy: 0.8196\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2039 - accuracy: 0.7201"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 606ms/step - loss: 1.2039 - accuracy: 0.7201 - val_loss: 0.8374 - val_accuracy: 0.8040\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1057 - accuracy: 0.7341"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 699ms/step - loss: 1.1057 - accuracy: 0.7341 - val_loss: 0.7481 - val_accuracy: 0.8616\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1482 - accuracy: 0.7185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 684ms/step - loss: 1.1482 - accuracy: 0.7185 - val_loss: 0.7098 - val_accuracy: 0.8834\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1534 - accuracy: 0.7341"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 689ms/step - loss: 1.1534 - accuracy: 0.7341 - val_loss: 0.7285 - val_accuracy: 0.8569\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1473 - accuracy: 0.7201"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 597ms/step - loss: 1.1473 - accuracy: 0.7201 - val_loss: 0.6808 - val_accuracy: 0.8927\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1173 - accuracy: 0.7216"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 679ms/step - loss: 1.1173 - accuracy: 0.7216 - val_loss: 0.5910 - val_accuracy: 0.9456\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1470 - accuracy: 0.7201"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 694ms/step - loss: 1.1470 - accuracy: 0.7201 - val_loss: 0.5609 - val_accuracy: 0.9440\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0555 - accuracy: 0.7558"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 822ms/step - loss: 1.0555 - accuracy: 0.7558 - val_loss: 0.5272 - val_accuracy: 0.9565\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0625 - accuracy: 0.7496"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 1.0625 - accuracy: 0.7496 - val_loss: 0.5349 - val_accuracy: 0.9456\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0439 - accuracy: 0.7776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 691ms/step - loss: 1.0439 - accuracy: 0.7776 - val_loss: 0.6575 - val_accuracy: 0.8787\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0520 - accuracy: 0.7589"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 700ms/step - loss: 1.0520 - accuracy: 0.7589 - val_loss: 0.6496 - val_accuracy: 0.8740\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0211 - accuracy: 0.7683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 691ms/step - loss: 1.0211 - accuracy: 0.7683 - val_loss: 0.5740 - val_accuracy: 0.9222\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0321 - accuracy: 0.7667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 687ms/step - loss: 1.0321 - accuracy: 0.7667 - val_loss: 0.6953 - val_accuracy: 0.8709\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9877 - accuracy: 0.7823"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 685ms/step - loss: 0.9877 - accuracy: 0.7823 - val_loss: 0.7205 - val_accuracy: 0.8554\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0292 - accuracy: 0.7527"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 690ms/step - loss: 1.0292 - accuracy: 0.7527 - val_loss: 0.4774 - val_accuracy: 0.9642\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.7387"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 631ms/step - loss: 1.0860 - accuracy: 0.7387 - val_loss: 0.4649 - val_accuracy: 0.9658\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9888 - accuracy: 0.7776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 711ms/step - loss: 0.9888 - accuracy: 0.7776 - val_loss: 0.4822 - val_accuracy: 0.9518\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9386 - accuracy: 0.8040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 609ms/step - loss: 0.9386 - accuracy: 0.8040 - val_loss: 0.5052 - val_accuracy: 0.9362\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9613 - accuracy: 0.7745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 673ms/step - loss: 0.9613 - accuracy: 0.7745 - val_loss: 0.4595 - val_accuracy: 0.9549\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9118 - accuracy: 0.8103"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 596ms/step - loss: 0.9118 - accuracy: 0.8103 - val_loss: 0.4292 - val_accuracy: 0.9720\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9411 - accuracy: 0.7792"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 591ms/step - loss: 0.9411 - accuracy: 0.7792 - val_loss: 0.4457 - val_accuracy: 0.9720\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9286 - accuracy: 0.8134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 585ms/step - loss: 0.9286 - accuracy: 0.8134 - val_loss: 0.5246 - val_accuracy: 0.9440\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8940 - accuracy: 0.7916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 690ms/step - loss: 0.8940 - accuracy: 0.7916 - val_loss: 0.5549 - val_accuracy: 0.9238\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9112 - accuracy: 0.7838"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 656ms/step - loss: 0.9112 - accuracy: 0.7838 - val_loss: 0.5404 - val_accuracy: 0.9300\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9188 - accuracy: 0.7932"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 823ms/step - loss: 0.9188 - accuracy: 0.7932 - val_loss: 0.5540 - val_accuracy: 0.9222\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8913 - accuracy: 0.7963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 838ms/step - loss: 0.8913 - accuracy: 0.7963 - val_loss: 0.5474 - val_accuracy: 0.9176\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8895 - accuracy: 0.8072"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 837ms/step - loss: 0.8895 - accuracy: 0.8072 - val_loss: 0.4080 - val_accuracy: 0.9751\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8745 - accuracy: 0.7869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 691ms/step - loss: 0.8745 - accuracy: 0.7869 - val_loss: 0.3990 - val_accuracy: 0.9767\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8650 - accuracy: 0.8118"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 588ms/step - loss: 0.8650 - accuracy: 0.8118 - val_loss: 0.3832 - val_accuracy: 0.9813\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8770 - accuracy: 0.7932"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 606ms/step - loss: 0.8770 - accuracy: 0.7932 - val_loss: 0.3816 - val_accuracy: 0.9782\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9079 - accuracy: 0.8025"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 668ms/step - loss: 0.9079 - accuracy: 0.8025 - val_loss: 0.4168 - val_accuracy: 0.9580\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8787 - accuracy: 0.7900"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 571ms/step - loss: 0.8787 - accuracy: 0.7900 - val_loss: 0.3979 - val_accuracy: 0.9673\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8752 - accuracy: 0.7994"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 671ms/step - loss: 0.8752 - accuracy: 0.7994 - val_loss: 0.3700 - val_accuracy: 0.9798\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8705 - accuracy: 0.7978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 686ms/step - loss: 0.8705 - accuracy: 0.7978 - val_loss: 0.3670 - val_accuracy: 0.9829\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8484 - accuracy: 0.8009"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 609ms/step - loss: 0.8484 - accuracy: 0.8009 - val_loss: 0.4103 - val_accuracy: 0.9736\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8719 - accuracy: 0.7869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 677ms/step - loss: 0.8719 - accuracy: 0.7869 - val_loss: 0.4035 - val_accuracy: 0.9705\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8089 - accuracy: 0.8258"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 614ms/step - loss: 0.8089 - accuracy: 0.8258 - val_loss: 0.5055 - val_accuracy: 0.9222\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7671 - accuracy: 0.8429"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 674ms/step - loss: 0.7671 - accuracy: 0.8429 - val_loss: 0.5405 - val_accuracy: 0.9051\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7875 - accuracy: 0.8429"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 594ms/step - loss: 0.7875 - accuracy: 0.8429 - val_loss: 0.4465 - val_accuracy: 0.9425\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.8398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 610ms/step - loss: 0.7679 - accuracy: 0.8398 - val_loss: 0.3734 - val_accuracy: 0.9767\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8205 - accuracy: 0.8227"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 669ms/step - loss: 0.8205 - accuracy: 0.8227 - val_loss: 0.3534 - val_accuracy: 0.9829\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7320 - accuracy: 0.8709"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 677ms/step - loss: 0.7320 - accuracy: 0.8709 - val_loss: 0.3397 - val_accuracy: 0.9844\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7377 - accuracy: 0.8538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 806ms/step - loss: 0.7377 - accuracy: 0.8538 - val_loss: 0.3139 - val_accuracy: 0.9938\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7701 - accuracy: 0.8274"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 1s/step - loss: 0.7701 - accuracy: 0.8274 - val_loss: 0.3087 - val_accuracy: 0.9907\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.8336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 708ms/step - loss: 0.7626 - accuracy: 0.8336 - val_loss: 0.3369 - val_accuracy: 0.9844\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7856 - accuracy: 0.8072"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 596ms/step - loss: 0.7856 - accuracy: 0.8072 - val_loss: 0.4562 - val_accuracy: 0.9316\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7631 - accuracy: 0.8289"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 573ms/step - loss: 0.7631 - accuracy: 0.8289 - val_loss: 0.3771 - val_accuracy: 0.9658\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.8538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 668ms/step - loss: 0.7387 - accuracy: 0.8538 - val_loss: 0.3150 - val_accuracy: 0.9876\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7115 - accuracy: 0.8569"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 624ms/step - loss: 0.7115 - accuracy: 0.8569 - val_loss: 0.3265 - val_accuracy: 0.9860\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7463 - accuracy: 0.8367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 684ms/step - loss: 0.7463 - accuracy: 0.8367 - val_loss: 0.3133 - val_accuracy: 0.9922\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6976 - accuracy: 0.8445"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 606ms/step - loss: 0.6976 - accuracy: 0.8445 - val_loss: 0.3426 - val_accuracy: 0.9751\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.8802"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 698ms/step - loss: 0.6597 - accuracy: 0.8802 - val_loss: 0.3635 - val_accuracy: 0.9565\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.8663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 626ms/step - loss: 0.6982 - accuracy: 0.8663 - val_loss: 0.3211 - val_accuracy: 0.9798\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.8491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 598ms/step - loss: 0.6921 - accuracy: 0.8491 - val_loss: 0.3331 - val_accuracy: 0.9751\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.8569"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 605ms/step - loss: 0.6707 - accuracy: 0.8569 - val_loss: 0.3550 - val_accuracy: 0.9596\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6751 - accuracy: 0.8569"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 594ms/step - loss: 0.6751 - accuracy: 0.8569 - val_loss: 0.3537 - val_accuracy: 0.9611\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.8491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 672ms/step - loss: 0.6931 - accuracy: 0.8491 - val_loss: 0.3021 - val_accuracy: 0.9844\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.8476"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 686ms/step - loss: 0.6913 - accuracy: 0.8476 - val_loss: 0.2986 - val_accuracy: 0.9938\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.8585"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 664ms/step - loss: 0.6579 - accuracy: 0.8585 - val_loss: 0.3094 - val_accuracy: 0.9860\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.8554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 720ms/step - loss: 0.6768 - accuracy: 0.8554 - val_loss: 0.3141 - val_accuracy: 0.9844\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.8834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 793ms/step - loss: 0.6290 - accuracy: 0.8834 - val_loss: 0.2950 - val_accuracy: 0.9876\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.8476"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 800ms/step - loss: 0.6668 - accuracy: 0.8476 - val_loss: 0.2865 - val_accuracy: 0.9891\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.8740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 700ms/step - loss: 0.6225 - accuracy: 0.8740 - val_loss: 0.3148 - val_accuracy: 0.9767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy-RNN')\n",
        "plt.legend()\n",
        " \n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss-RNN')\n",
        "plt.legend()\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "OOn7Q1Cn_0Fi",
        "outputId": "ef7a5f1f-3081-4bf9-98af-1d3596db5d5f"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=['It was not a good day in my life']\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_test  = np.array( tokenizer.texts_to_sequences(test_data))\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)\n",
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RErR6_afHKYB",
        "outputId": "490ab595-bdec-40d4-bb24-82d8a08c45d1"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 71, 32,\n",
              "        22]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(test_data)):\n",
        "  print('Test sentence:-',test_data[i])\n",
        "  \n",
        "  res=modelRNN.predict(x_test)\n",
        "  labels = ['almosthomeless', 'anxiety', 'assistance', 'domesticviolence',\n",
        "       'food_pantry', 'homeless', 'ptsd', 'relationships', 'stress',\n",
        "       'survivorsofabuse']\n",
        "  print(res, labels[np.argmax(res)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pthvffauHadM",
        "outputId": "e6643ccd-7d10-4e32-adac-e86f2d945755"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sentence:- It was not a good day in my life\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 25s 25s/step\n",
            "[[0.19472535 0.00054695 0.35611495 0.02639586 0.03465292 0.32063195\n",
            "  0.00913568 0.04657808 0.00350915 0.00770909]] assistance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=['I need a new home , my current home is almost broke']\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_test  = np.array( tokenizer.texts_to_sequences(test_data))\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)\n",
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH8O2GF4HlrU",
        "outputId": "6bc58859-849e-4b19-dc8f-2b0c923d5395"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  34,  74,  57, 488,  57, 138, 216]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(test_data)):\n",
        "  print('Test sentence:-',test_data[i])\n",
        "  \n",
        "  res=modelRNN.predict(x_test)\n",
        "  labels = ['almosthomeless', 'anxiety', 'assistance', 'domesticviolence',\n",
        "       'food_pantry', 'homeless', 'ptsd', 'relationships', 'stress',\n",
        "       'survivorsofabuse']\n",
        "  print(res, labels[np.argmax(res)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfx6qHXLMw6K",
        "outputId": "c97a89a6-9375-4202-a7e6-57bc90a9b61e"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sentence:- I need a new home , my current home is almost broke\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 210ms/step\n",
            "[[0.02332318 0.05794984 0.31706443 0.00972511 0.05653831 0.3684562\n",
            "  0.04195517 0.07634965 0.04108967 0.00754836]] homeless\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The End**"
      ],
      "metadata": {
        "id": "tWrqaKiLQA8F"
      }
    }
  ]
}